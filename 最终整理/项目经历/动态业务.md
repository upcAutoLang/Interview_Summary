# 一. 动态模板

## 1. 业务简要说明

用户有上下级数据的上报体系，所以需要所有数据是有一套数据标准的，标准由甲方定制。然而在实际使用中，用户反映，一方面我们提供的数据不符合他们实际使用情况的内容，另一方面他们实际需要进行记录的数据有一定的可变性，所以用户提出需要根据他们需要，可以动态制定模板的功能。换句话说，就是类似于动态报表，但又与用户信息紧密结合的业务。所以动态模板业务就有了。

## 2. 业务主线流程

业务主要流程分七步。

### 2.1 前台填写模板信息

数据表信息包含表本身的信息，以及各个字段的信息。表本身的信息，基本就是表的名称。字段的信息，有三个是必填字段，数据时间用来记录填入数据的事件、记录 ID 是 UUID 用作主键记录、数据来源 ID 标识了这条数据的来源单位。此外的字段需要用户的需要进行填充，填充的内容包括数据的类型（字符串、数字、时间、数据源、关联表），是否允许筛选，是否允许排序（筛选和排序即对对应的字段建立索引）。比如今天是**<font color=red>蚂蚁金服</font>**的面试，那么新建的表名称就叫做【蚂蚁金服面试】，里面的字段会有时间类型的面试时间、下拉树类型的面试者、字符串形式的面试结果等字段信息。

### 2.2 后台服务接收模板消息

该步骤是后续过程的预操作，主要为后面的几步做辅助。因为后面几步是要求原子性的，所以用 Kafka 实现了分布式事务。  
前台将用户构建的模板信息传递到后台，后台简单处理后，发送一个**半消息**到 Kafka 的创建动态模板主题中，此时并不提交，等待后面的操作执行完毕后再提交。  
后续的所有 RPC 远程方法调用，都存在**正常调用**和**异常回滚调用**的接口。用一个 CountDownLatch 拦截，需要所有 RPC 远程方法调用都在限定时间内全部正确返回，如果有一个错误，都要调用所有远程 RPC 方法的回滚方法，恢复到方法调用之前的状态。

### 2.3 创建数据表

提交半消息到 Kafka 主题后，开始第一步，创建数据表。通过 RPC 的负载均衡找到一个数据服务节点，调用创建数据表的方法。  

#### 2.3.1 正常调用

数据服务根据传入的动态模板信息，用 FreeMarker 渲染 SQL 的 create 语句，用 Mybatis 打开一个 SqlSession，执行 create 数据库表的语句；

#### 2.3.2 异常调用

用同样的方式，通过 FreeMarker 模板渲染一个 drop 语句，将要创建的动态模板数据表删除。执行过程无视异常（比如不存在该表的异常）。

### 2.4 服务端动态加载类

服务是一个集群，需要对集群中所有服务都进行调用。

#### 2.4.1 正常调用

1. 服务传入动态模板信息，用 FreeMarker 渲染 Java 文件，用系统编译器编译出 .class 文件；
2. 新建一个 ClassLoader，把编译完成的类加载到新的 ClassLoader 中；
3. 修改服务配置信息，比如服务的模板列表中添加该新建的动态模板；
4. 丢弃旧的 ClassLoader，修改指针到新的 ClassLoader；

#### 2.4.2 异常回滚调用

1. 不执行最后一步，即不修改 ClassLoader 的指针；
2. 将该动态模板从服务的模板菜单中删除；

### 2.5 数据服务动态加载类与 Mybatis 映射

数据服务是一个集群，需要对集群中所有数据服务都进行调用。

#### 2.5.1 正常调用

1. 同上一步的 1 - 4，完成类的动态加载；
2. 通过 FreeMarker 模板输入消息内容，动态生成 Mybatis 接口与 XML 文件；
3. 用反射的方式，将 Mybatis 的 Configuration 中重要数据信息清除，然后重新加载，就会把动态生成的 Mybatis 加载到 Mybatis 中；

#### 2.5.2 异常回滚调用

1. 不修改 ClassLoader 的指针；
2. Mapper 的 Configuration 不进行重置；

### 2.6 完成动态模板的创建

上述 3, 4, 5 步中所有集群操作全部完成且成功后，第 2 步中的半消息即可提交位移。如果上述所有集群操作有一个超时或不成功，则再次远程调用所有服务的回滚方法。

### 2.7 远程传输动态模板

可以将新建的动态模板，通过我们集团自己的传输服务传给其他的单位。其他单位的服务受到该动态模板数据后，也开始执行上述的操作。成功后，两个单位就同时拥有了同样的数据模板，接下来就可以执行数据上报操作了。

## 3. 动态模板业务修改字段的实现

### (1) 后端方面

问题所在：如果修改字节码中生成类的字段的话，在调用虚拟机方法 virtualMechine.redefineClasses 时，会抛出异常 "Schema change not implemented"。

### (2) 前端方面

- **作用**：另外，主题服务需要用 JAXB 技术生成 XML，<font color=red>用于网络数据层的前台显示（仅有此作用？）</font>。
- **限制**：
	- 主题端不是我们开发的，他们在生成 XML 的工具使用的是 JAXB，并不是我们经常使用的 DOM4J, XStream 等，所以需要使用他们常用的 JAXB；
	- 需要克服 @XmlSeeAlso 的问题：然而 @XmlSeeAlso 的注解在第一次动态生成 Class 文件的时候就已经生成过了。加载到 ClassLoader 中会出现问题：爆出 "@XmlSeeAlso 已经存在 @XmlSeeAlso" 的错误。克服这个问题的方式，就是重新 new MyClassLoader。
		- 注：@XmlSeeAlso 的作用在后文中。

### (3) 解决方法

解决方法是新建一个 MyClassLoader。  

- 在后端方面，这样绕开了使用同一个 ClassLoader 会令同一个类抛"字段发生改变的异常"的问题；
- 在前端方面，用新的类加载器读取新生成的 Class 数据流，也绕开了前端 @XmlSeeAlso 不能二次生成的问题；

> 如果用户修改了字段（即增删改字段），使用**<font color=red>委托机制，利用 MyClassLoader, HotSwapperClassLoader </font>**判断时间，如果后者的创建时间较之前者更新，则 new MyClassLoader，用新的 ClassLoader 生成新修改字段后的 Class 文件。

### (4) @XmlSeeAlso 的作用

由于主题端代码中有泛型继承的内容，所以由于泛型擦除的特性，JAXB 提供了 @XmlSeeAlso 的 Class 级别注解，用于标注说明该泛型类型应该在 @XmlSeeAlso 的 Class[] 列表中。即 @XmlSeeAlso 是用来记录主题端 DataSet\<T> 的泛型内容。

## 4. 业务并发量与数据量



# 二. 动态汇总统计

## 1. 业务简要说明

前面的动态模板只是负责数据的来源，动态汇总统计业务负责的是对数据的动态统计。这个业务诞生的原因也比较类似。甲方给的统计也是按照一定标准的，实际使用的用户认为标准给的统计内容并不符合他们的期望，所以希望我们有一种动态汇总统计的能力，用于他们的统计、文本导出、数据展现。

## 2. 业务设计

这个项目我负责的是全部设计，以及核心功能的后端实现。

首先，我们的业务统计面向的主要是表格。表格统计的内容主要有什么呢？主要有两部分：一部分是表格本身的数据内容，另一部分是对表格数据进行一段话的概述信息统计。

- **表格数据的内容主要是按照数据列进行处理**，所有数据行的所有列处理完毕后，就拼成了一个汇总表格。这里面，对数据列进行处理的方式有简单有复杂。
  - 简单处理方式比如提取字段，无需处理，直接从一条数据中获取对应的字段，结果就是一个数据列；
  - 复杂处理方式比如对一条数据的物资信息进行统计，物资信息是数据行对应数据的子表信息，那么就要遍历物资子列表，统计信息串成字符串。
- **一段话的概述统计主要是对表格数据进行处理**，遍历所有表格的所有行列，统计得出一段话来总结说明数据列表的内容。

在上面的业务情景的前提下，我定义了一个**维度**的概念：表格是二维，对应 JSONArray；数据行是一维，对应 JSONObject；一个字符串（字符串、整数、浮点数）是零维，对应 String。所以，无论是对一条一维行数据按照字段进行处理，结果产出一个字段的字符串内容，还是对二维表格进行汇总处理，结果产出一段总结性的统计信息，本质上都是高维向零维的处理过程。处理的过程，通常是对输入进行<font color=red>**顺序的、链式的**</font>方式进行的，这条处理链的每个处理单元，输入和输出都是有严格限定的维度。举两个例子：

- 比如从数据行中提取一个 key-value 作为输出的处理单元，就是一维输入，零维输出；
- 比如从数据行中提取出其子表信息的处理单元，就是一维输入，二维输出；

其他还有筛选、排序、累加计算等处理单元，都有自己允许的输入输出维度。一串<font color=red>**匹配输入输出维度的**</font>处理单元串联起来就构成了一条处理链。

上面就是动态汇总统计业务整个**设计层面**的思路。

## 3. 具体实现

那么用户如何进行配置，来实现对几张数据表进行自定义的报表统计呢？**实现思路与 Dubbo 的条件路由、脚本路由是有一些相似之处的。**

在配置中心的前台页面，构建一个报表统计项，并为该统计项选择对应的若干张数据表。一个报表统计项就初始化完成了。然后开始进行各字段的配置。每添加一个数据列，为其构建处理链，然后向处理链中逐个添加处理单元。添加处理单元有一定的限制，其中最大的限制就是前后处理单元的匹配，**前一个单元的输出必须和后一个单元的输入匹配**。这样构建结束一个数据列后，再逐个构建其他数据列，就形成了一个报表统计项。同理对于一个报表统计项的一段话统计，也是用处理链的形式进行的。和前面不同的是，构建字段的处理链输入是一维，输出是零维；而表格的一段话统计，输入二维，输出是零维。

报表统计项构建完毕后，将配置信息传到后台服务，对配置信息的可用性和安全性进行检查后，将配置信息入库。入库是以字符串的形式进行的，具体的方法在后面再解释。

用户实际查询报表统计项内容的时候：

1. 首先，发起查询请求，后台一方面从数据库中查数据表的数据，另一方面查询配置信息；
2. 然后，后台将字符串形式的配置信息转成处理单元列表；
3. 最后，将数据输入处理链，最后生成一个 JSONArray 类型的处理结果，交给前台渲染，即为用户所得。

至于字符串形式的配置信息，转成处理单元的思路，整体与 Dubbo 的条件路由 ConditionRouter 比较相似，是使用我自定义的一套严格的表达式匹配规则实现的。主要实现方式是借助了 Google 的一个开源表达式处理引擎完成的（名为 Aviator），这个表达式引擎有一个全局静态的方法注册中心，用来存储一些处理方法。我们的服务启动的时候，我将一系列自定义的提取、筛选、排序等处理方法注册到表达式引擎中。然后使用过程中，用户添加一个新的报表统计项时，后台将配置信息适配成表达式引擎的字符串格式，存入数据库。用户在访问该报表统计项时，对表达式进行解析，然后匹配表达式中已经被注册的方法，提取方法进行处理。

上面就是动态汇总统计的主线流程实现。

------

**性能处理：**  

当然用户实际使用的时候，为了保证汇总服务的性能，主要还是依托于 Kafka 的订阅还有 Redis 缓存。对于一个报表统计项，一旦触发了其中涉及的某一数据表的增删改操作，我们的数据服务会同时发布订阅消息，通知我们的汇总服务，然后汇总服务将与该数据表相关的所有统计项的缓存清除。用户在访问报表统计项时，后台将会处理汇总前端前三页的数据内容，并存入 Redis，提高访问性能。