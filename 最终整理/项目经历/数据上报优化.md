# 一. 业务内容

简要叙述整个业务流程：下级部队要向上级部队上报数据，要求每天数据上报一份数据，这一份数据中包含多个数据表的今日所有信息，如果有哪个表数据第一次传错了，那就让该下级部队将错误表的数据修改后，将所有表的数据同样方式打包后，发送给上级部队。这种每天发送一次数据的情况，业务上叫做日报。  
针对这样的业务流程，之前业务实现时，比较简单的使用对一个表先删后增的方式进行日报数据的录入与更新，这样第一次录入错误，第二次用来修改的录入时，先将该表的数据删除，再将该表的数据更新，这样在用户视角上看，就实现了对这个表数据的更新。  
但是这样简单的逻辑处理有两个问题：

1. 安全性问题。假如下级部队的用户手滑了，瞬间点了两次确定按钮，后台接受了两次内容重复的报文，这两份报文都会各自完成先删后增的逻辑，但由于没有任何限制，他们整体的逻辑可能会变成【删删增增】的情况，这样就变成两倍数量的数据，数据肯定是错误的；
2. 性能问题。一开始下级部队不多，数据可以处理。但通常上报的时候，上级都会给一个时间节点，下级部队都会在这个时间节点进行上报。随着下级部队越来越多，在上报时间点的并发也越来越多，这样会对性能有一定的影响；

主要针对这些问题，我进行了一些优化工作。

# 二. 优化内容

优化主要借助了 Kafka 与 Redis 的特性，Kafka 是主要的组件，用来保证顺序性与削峰限流；Redis 起辅助作用，主要用来保证消息的幂等性，以及消息消费错误时重复队列的信息。  
首先针对安全性问题，主要有几点优化：

## 2.1 事务化

之前的处理逻辑先删后增，这是两个分别独立的事务，所以我首先做的就是将这两个操作放到一个事务中，保证这两个操作的原子性。

## 2.2 Kafka 队列化

第二使用 Kafka 进行优化，进行了削峰限流与顺序性保证。引入 Kafka 后，我将消费报文的逻辑，用 Kafka 拆分成了两个 Topic：  
第一个主题是消费主题，用于正常的消息消费，接受到原始报文后，将报文进行转换，投递到主题中，在消费者端，拉取消息，进行入库、转换等业务逻辑。使用 Kafka 消息队列的模型进行数据的处理，可以保证数据处理是按照消息存入队列的顺序进行的。  
此外向消费主题中存入数据时，我也利用了 Kafka 的分区顺序性。因为刚才说到业务场景，每个部队数据的修改不会影响到其他部队，所以只要保证每个部队的数据操作是有序的就行了。Kafka 的顺序性是分区保证的，所以我将每个部队的 ID 设为消息的 Key，这样分区器对部队 ID 进行 hashCode 计算与取余，每个部队都会有指定的分区，也就保证了部队数据处理的顺序性，也保证了整体上数据处理的并发。

## 2.3 容错处理

另外一个主题是重试主题，用于异常报文的处理。容错处理过程中主要使用了 Kafka 与 Redis。

首先，接受到报文处理过程中可能会遇到异常，在消费过程中如果抛出了异常，我就把错误的消息与重试信息包装起来作为报文，投到 Kafka 重试主题中。然后后续处理过程中，我设置了两个任务，作为后续处理的主要逻辑。  
第一个任务就是重试队列的循环拉取线程，它的主要作用是**拉取投递到 Kafka 中的重试消息，把重试消息的内容放到 Redis 中**。放到 Redis 中的内容都是从重试消息中获取的，分为两部分存入 Redis，一部分是错误消息的原始报文信息，还有一部分是该错误报文信息的下一次重试时间。这样，线程拉取到重试消息后，就把报文信息存到 Redis Hash 中（Key 是消息 ID，value 是报文信息），下一次重试时间存到 Redis ZSet 中（Key 是下一次重试时间的 Long 值，value 是消息 ID）。这个过程也就把 Kafka 的消息转到了 Redis 中。
第二个任务是一个定时任务，它的主要作用是**重新把 Redis 中的重试消息重新推到正常的 Kafka 消费主题中**。定时任务会轮询 Redis 的 ZSet，如果里面有内容，说明是有重试任务的，那么就拿出 ZSet 的 Key 值，也就是下一次的重试时间，与当前时间进行比较，如果这个重试时间已经过去了，就把这个消息重新推入 Kafka 消费主题中。

重试如果成功就不会再触发该消息的重试操作，但如果依旧失败，那么还是会重新执行上面的任务，每次重试都会记录该消息的重试次数，最多重试大概五次，如果还是失败，那就应该是有逻辑问题，或者是有问题的报文，就把这个报文记录下来。如果遇到一些网络波动导致的错误，一般五次重试也就够了。  

## 2.4 记录追溯

在上述内容的基础之上，我也在每次消息消费成功、重试、失败的时候插入了记录上报的数据解析的流程，这样就可以提供给用户了解整个数据链路，或者自行检查错误的报文出现了什么问题。