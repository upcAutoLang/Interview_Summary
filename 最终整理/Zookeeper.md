# 分布式相关知识点总结

# 一. Zookeeper 相关知识

> [《Zookeeper面试题》](https://www.cnblogs.com/lanqiu5ge/p/9405601.html)  
> [《随笔分类 - Zookeeper学习》](http://www.cnblogs.com/sunddenly/category/620563.html)

## 1. ZooKeeper是什么？

ZooKeeper 是一个分布式协调管理的服务，是集群的管理者。

ZooKeeper 的特性：

- 顺序一致性：即有序性，每次更新都会有一个时间戳信息，被称为 zxid，每次读请求都会包含 zxid 信息；
- 原子性：一个更新操作要么全部服务器节点都完成，要么全都失败；
- 单一视图：
- 可靠性：ZooKeeper 的 Leader/Follower 机制，保证了 ZooKeeper 的稳定性；
- 最终一致性：

## 2. ZooKeeper 提供了什么？

ZooKeeper 提供了**文件系统**和**通知机制**。文件系统即仿 Unix 文件系统结构的 ZNode 数据结构，通知机制即**<font color=red>？？？</font>**

## 3. Zookeeper 文件系统

ZK 文件系统的节点命名为 ZNode，与文件系统一样，树状多层级。与文件系统不同的是，文件系统只有叶子节点才有数据内容，而 ZNode 所有节点都可以有关联数据。只是 ZK 为了保证系统的实时性和可靠性，<font color=red>**每个节点的数据量很小，要求不能超过 1M**</font>。

## 4. ZAB协议？

ZooKeeper 的核心机制是原子传播机制。这个机制保证了各个服务器之间的同步。实现原子传播机制的协议称为 ZAB 协议。  
ZAB 协议有两种模式，<font color=red>**恢复模式**</font>和<font color=red>**广播模式**</font>。

- **恢复模式**：
	- 发生条件如下：
		- (1) ZooKeeper 集群刚刚重启；
		- (2) 有 Leader 节点故障；
		- (3) 超过半数的 Follower 无法与 Leader 正常通信（Follower 节点故障，或者网络问题），需要重新选举 Leader；
	- 如果出现上述情况，集群则会开始选举新的节点作为集群 Leader。选举完毕后，Followers 会与 Leader 进行更新同步。当同步完成的 Followers 数量超过集群节点总数的一半后，恢复完毕，转入广播模式。
- **广播模式**：恢复模式之外的模式，接受客户端请求，并进行事务请求处理。步骤如下：
	1. 服务集群中任意一个节点 node 接受客户端的更新请求；
	2. node 将消息传递给 Leader；
	3. Leader 再向各个 Follower 进行提议 (Propose)；
	4. Follower 收到 Propose 后，向 Leader 返回一个应答 ack；
	5. Leader 收到半数以上 Follower 的 ack 后，将结果通知 (commit) 给各个 Follower，进行更新。

## 5. 四种类型的数据节点 Znode

四种节点类型：

- **临时节点 (EPHEMERAL)**：客户端请求的临时节点。建立后客户端与 ZK 集群的会话失效（客户端与 ZK 连接断开，并不一定是会话失效），则会将该客户端创建的所有临时节点删除（当然包括该节点及下面的子节点）；
- **永久节点 (PERSISTENT)**：一旦建立，除非手动删除，否则就会永久存在的节点。
- **临时顺序节点 (EPHEMERAL SEQUENTIAL)**：与临时节点的生命周期相同，只是添加了一个顺序编号（自增整形数字），由父节点管理；
- **永久顺序节点 (PERSISTENT SEQUENTIAL)**：与永久节点的生命周期相同，添加了一个由父节点管理的顺序编号（自增整形数字）。

## 6. Zookeeper Watcher 机制 -- 数据变更通知

ZooKeeper 的 Watcher 有三个步骤：

1. 客户端注册 (Register) Watcher；
2. 服务端处理 Watcher；
3. 客户端回调 Watcher；

ZooKeeper 的 Watcher 有特性如下：

1. **一次性**：不管是客户端注册还是服务端处理，Watcher 回调只有一次。这样避免了某些 ZK 节点频繁的变更而带来的巨大网络开销。
2. 客户端、服务端事件：
	- 客户端：**getData**, **getChildren**, **exists**，几个方法都在 ZooKeeper.java 中；
	- 服务端：**setData**, **create**, **delete**，几个方法都在 ZooKeeper.java 中。


## 7. 客户端注册 Watcher 实现

步骤如下：

1. 客户端调用 getData / getChildren / exists 方法；
2. 

## 8. 服务端处理Watcher实现


## 9. 客户端回调Watcher

## 10. ACL权限控制机制

- **UGO (User/Group/Others)**: 目前在Linux/Unix文件系统中使用，也是使用最广泛的权限控制方式。是一种粗粒度的文件系统权限控制模式。
- **ACL（Access Control List）访问控制列表**，包括三个方面：
  - **权限模式 (Scheme)**
    - **IP**：从IP地址粒度进行权限控制；
    - **Digest**：最常用，用类似于 username:password 的权限标识来进行权限配置，便于区分不同应用来进行权限控制；
    - **World**：最开放的权限控制方式，是一种特殊的digest模式，只有一个权限标识“world:anyone”；
    - **Super**：超级用户；
  - **授权对象**：授权对象指的是权限赋予的用户或一个指定实体，例如IP地址或是机器灯。
  - **权限 Permission**
    - **CREATE**：数据节点创建权限，允许授权对象在该Znode下创建子节点；
    - **DELETE**：子节点删除权限，允许授权对象删除该数据节点的子节点；
    - **READ**：数据节点的读取权限，允许授权对象访问该数据节点并读取其数据内容或子节点列表等；
    - **WRITE**：数据节点更新权限，允许授权对象对该数据节点进行更新操作；
    - **ADMIN**：数据节点管理权限，允许授权对象对该数据节点进行ACL相关设置操作；

## 11. Chroot特性
## 12. 会话管理

- **分桶策略**：将类似的会话放在同一区块中进行管理，以便于Zookeeper对会话进行不同区块的隔离处理以及同一区块的统一处理。
- **分配原则**：每个会话的“下次超时时间点”（ExpirationTime）

计算公式：

```java
ExpirationTime_ = currentTime + sessionTimeout
ExpirationTime = (ExpirationTime_ / ExpirationInrerval + 1) * ExpirationInterval , ExpirationInterval 是指 Zookeeper 会话超时检查时间间隔，默认 tickTime
```

## 13. 服务器角色
- **Leader**: 
  - 事务请求的唯一调度和处理者，保证集群事务处理的顺序性；
  - 集群内部各服务的调度者；
- **Follower**
  - 处理客户端的非事务请求，转发事务请求给 Leader 服务器；
  - 参与事务请求 Proposal 的投票；
  - 参与Leader选举投票；
- **Observer**：3.3.0 版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础上提升集群的非事务处理能力；
  - 处理客户端的非事务请求，转发事务请求给 Leader 服务器；
  - 不参与任何形式的投票；

## 14. Zookeeper 下 Server工作状态

服务器具有四种状态，分别是LOOKING、FOLLOWING、LEADING、OBSERVING。

- **LOOKING**：寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有Leader，因此需要进入Leader选举状态。
- **FOLLOWING**：跟随者状态。表明当前服务器角色是Follower。
- **LEADING**：领导者状态。表明当前服务器角色是Leader。
- **OBSERVING**：观察者状态。表明当前服务器角色是Observer。

## 15. Leader 选举

Leader选举是保证分布式数据一致性的关键所在。当 Zookeeper 集群中的一台服务器出现以下两种情况之一时，需要进入 Leader 选举。

1. 服务器初始化启动；
2. 服务器运行期间无法和 Leader 保持连接；

下面就两种情况进行分析讲解。

### 服务器启动时期的 Leader 选举

　　若进行Leader选举，则至少需要两台机器，这里选取3台机器组成的服务器集群为例。在集群初始化阶段，当有一台服务器Server1启动时，其单独无法进行和完成Leader选举，当第二台服务器Server2启动时，此时两台机器可以相互通信，每台机器都试图找到Leader，于是进入Leader选举过程。选举过程如下：

1. 每个Server发出一个投票。由于是初始情况，Server1和Server2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时Server1的投票为(1, 0)，Server2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。
2. 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。
3. 处理投票。
   - 针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK规则如下
     - 优先检查ZXID。ZXID比较大的服务器优先作为Leader。
     - 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。
   - 对于Server1而言，它的投票是(1, 0)，接收Server2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时Server2的myid最大，于是更新自己的投票为(2, 0)，然后重新投票，对于Server2而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。
4. 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于Server1、Server2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了Leader。
5. 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。

### 服务器运行时期的Leader选举

在Zookeeper运行期间，Leader与非Leader服务器各司其职，即便当有非Leader服务器宕机或新加入，此时也不会影响Leader，但是一旦Leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮Leader选举，其过程和启动时期的Leader选举过程基本一致。假设正在运行的有Server1、Server2、Server3三台服务器，当前Leader是Server2，若某一时刻Leader挂了，此时便开始Leader选举。选举过程如下：

1. 变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。
2. 每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定Server1的ZXID为123，Server3的ZXID为122；在第一轮投票中，Server1和Server3都会投自己，产生投票(1, 123)，(3, 122)，然后各自将投票发送给集群中所有机器。
3. 接收来自各个服务器的投票。与启动时过程相同。
4. 处理投票。与启动时过程相同，此时，Server1将会成为Leader。
5. 统计投票。与启动时过程相同。
6. 改变服务器的状态。与启动时过程相同。

----------------------

### Leader选举算法分析

在3.4.0后的Zookeeper的版本只保留了TCP版本的FastLeaderElection选举算法。当一台机器进入Leader选举时，当前集群可能会处于以下两种状态：

- 集群中已经存在Leader。
- 集群中不存在Leader。

对于集群中已经存在Leader而言，此种情况一般都是某台机器启动得较晚，在其启动之前，集群已经在正常工作，对这种情况，该机器试图去选举Leader时，会被告知当前服务器的Leader信息，对于该机器而言，仅仅需要和Leader机器建立起连接，并进行状态同步即可。而在集群中不存在Leader情况下则会相对复杂，其步骤如下：

#### 1. 第一次投票

无论哪种导致进行Leader选举，集群的所有机器都处于试图选举出一个Leader的状态，即LOOKING状态，LOOKING机器会向所有其他机器发送消息，该消息称为投票。投票中包含了SID（服务器的唯一标识）和ZXID（事务ID），(SID, ZXID)形式来标识一次投票信息。假定Zookeeper由5台机器组成，SID分别为1、2、3、4、5，ZXID分别为9、9、9、8、8，并且此时SID为2的机器是Leader机器，某一时刻，1、2所在机器出现故障，因此集群开始进行Leader选举。在第一次投票时，每台机器都会将自己作为投票对象，于是SID为3、4、5的机器投票情况分别为(3, 9)，(4, 8)， (5, 8)。

#### 2. 变更投票

每台机器发出投票后，也会收到其他机器的投票，每台机器会根据一定规则来处理收到的其他机器的投票，并以此来决定是否需要变更自己的投票，这个规则也是整个Leader选举算法的核心所在，其中术语描述如下

- vote_sid：接收到的投票中所推举Leader服务器的SID。
- vote_zxid：接收到的投票中所推举Leader服务器的ZXID。
- self_sid：当前服务器自己的SID。
- self_zxid：当前服务器自己的ZXID。

每次对收到的投票的处理，都是对(vote_sid, vote_zxid)和(self_sid, self_zxid)对比的过程。

- 规则一：如果vote_zxid大于self_zxid，就认可当前收到的投票，并再次将该投票发送出去。
- 规则二：如果vote_zxid小于self_zxid，那么坚持自己的投票，不做任何变更。
- 规则三：如果vote_zxid等于self_zxid，那么就对比两者的SID，如果vote_sid大于self_sid，那么就认可当前收到的投票，并再次将该投票发送出去。
- 规则四：如果vote_zxid等于self_zxid，并且vote_sid小于self_sid，那么坚持自己的投票，不做任何变更。

结合上面规则，给出下面的集群变更过程。

#### 3. 确定Leader

经过第二轮投票后，集群中的每台机器都会再次接收到其他机器的投票，然后开始统计投票，如果一台机器收到了超过半数的相同投票，那么这个投票对应的SID机器即为Leader。此时Server3将成为Leader。  
由上面规则可知，通常那台服务器上的数据越新（ZXID会越大），其成为Leader的可能性越大，也就越能够保证数据的恢复。如果ZXID相同，则SID越大机会越大。

-------------------

### Leader选举实现细节

#### 1. 服务器状态

服务器具有四种状态，分别是LOOKING、FOLLOWING、LEADING、OBSERVING。

- LOOKING：寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有Leader，因此需要进入Leader选举状态。
- FOLLOWING：跟随者状态。表明当前服务器角色是Follower。
- LEADING：领导者状态。表明当前服务器角色是Leader。
- OBSERVING：观察者状态。表明当前服务器角色是Observer。

#### 2. 投票数据结构

每个投票中包含了两个最基本的信息，所推举服务器的SID和ZXID，投票（Vote）在Zookeeper中包含字段如下：

- id：被推举的Leader的SID。
- zxid：被推举的Leader事务ID。
- electionEpoch：逻辑时钟，用来判断多个投票是否在同一轮选举周期中，该值在服务端是一个自增序列，每次进入新一轮的投票后，都会对该值进行加1操作。
- peerEpoch：被推举的Leader的epoch。
- state：当前服务器的状态。

#### 3. QuorumCnxManager：网络I/O

每台服务器在启动的过程中，会启动一个QuorumPeerManager，负责各台服务器之间的底层Leader选举过程中的网络通信。

1. 消息队列。QuorumCnxManager内部维护了一系列的队列，用来保存接收到的、待发送的消息以及消息的发送器，除接收队列以外，其他队列都按照SID分组形成队列集合，如一个集群中除了自身还有3台机器，那么就会为这3台机器分别创建一个发送队列，互不干扰。
   - recvQueue：消息接收队列，用于存放那些从其他服务器接收到的消息。
   - queueSendMap：消息发送队列，用于保存那些待发送的消息，按照SID进行分组。
   - senderWorkerMap：发送器集合，每个SenderWorker消息发送器，都对应一台远程Zookeeper服务器，负责消息的发送，也按照SID进行分组。
   - lastMessageSent：最近发送过的消息，为每个SID保留最近发送过的一个消息。
2. 建立连接。为了能够相互投票，Zookeeper集群中的所有机器都需要两两建立起网络连接。QuorumCnxManager在启动时会创建一个ServerSocket来监听Leader选举的通信端口(默认为3888)。开启监听后，Zookeeper能够不断地接收到来自其他服务器的创建连接请求，在接收到其他服务器的TCP连接请求时，会进行处理。为了避免两台机器之间重复地创建TCP连接，Zookeeper只允许SID大的服务器主动和其他机器建立连接，否则断开连接。在接收到创建连接请求后，服务器通过对比自己和远程服务器的SID值来判断是否接收连接请求，如果当前服务器发现自己的SID更大，那么会断开当前连接，然后自己主动和远程服务器建立连接。一旦连接建立，就会根据远程服务器的SID来创建相应的消息发送器SendWorker和消息接收器RecvWorker，并启动。
3. 消息接收与发送。消息接收：由消息接收器RecvWorker负责，由于Zookeeper为每个远程服务器都分配一个单独的RecvWorker，因此，每个RecvWorker只需要不断地从这个TCP连接中读取消息，并将其保存到recvQueue队列中。消息发送：由于Zookeeper为每个远程服务器都分配一个单独的SendWorker，因此，每个SendWorker只需要不断地从对应的消息发送队列中获取出一个消息发送即可，同时将这个消息放入lastMessageSent中。在SendWorker中，一旦Zookeeper发现针对当前服务器的消息发送队列为空，那么此时需要从lastMessageSent中取出一个最近发送过的消息来进行再次发送，这是为了解决接收方在消息接收前或者接收到消息后服务器挂了，导致消息尚未被正确处理。同时，Zookeeper能够保证接收方在处理消息时，会对重复消息进行正确的处理。

#### 4. FastLeaderElection：选举算法核心

- 外部投票：特指其他服务器发来的投票。
- 内部投票：服务器自身当前的投票。
- 选举轮次：Zookeeper服务器Leader选举的轮次，即logicalclock。
- PK：对内部投票和外部投票进行对比来确定是否需要变更内部投票。

(1) 选票管理

- sendqueue：选票发送队列，用于保存待发送的选票。
- recvqueue：选票接收队列，用于保存接收到的外部投票。
- WorkerReceiver：选票接收器。其会不断地从QuorumCnxManager中获取其他服务器发来的选举消息，并将其转换成一个选票，然后保存到recvqueue中，在选票接收过程中，如果发现该外部选票的选举轮次小于当前服务器的，那么忽略该外部投票，同时立即发送自己的内部投票。
- WorkerSender：选票发送器，不断地从sendqueue中获取待发送的选票，并将其传递到底层QuorumCnxManager中。

(2) 算法核心

![](https://images2018.cnblogs.com/blog/632316/201808/632316-20180803082744195-266416769.png)

上图展示了FastLeaderElection模块是如何与底层网络I/O进行交互的。Leader选举的基本流程如下：

1. 自增选举轮次。Zookeeper规定所有有效的投票都必须在同一轮次中，在开始新一轮投票时，会首先对logicalclock进行自增操作。
2. 初始化选票。在开始进行新一轮投票之前，每个服务器都会初始化自身的选票，并且在初始化阶段，每台服务器都会将自己推举为Leader。
3. 发送初始化选票。完成选票的初始化后，服务器就会发起第一次投票。Zookeeper会将刚刚初始化好的选票放入sendqueue中，由发送器WorkerSender负责发送出去。
4. 接收外部投票。每台服务器会不断地从recvqueue队列中获取外部选票。如果服务器发现无法获取到任何外部投票，那么就会立即确认自己是否和集群中其他服务器保持着有效的连接，如果没有连接，则马上建立连接，如果已经建立了连接，则再次发送自己当前的内部投票。
5. 判断选举轮次。在发送完初始化选票之后，接着开始处理外部投票。在处理外部投票时，会根据选举轮次来进行不同的处理。
   - 外部投票的选举轮次大于内部投票。若服务器自身的选举轮次落后于该外部投票对应服务器的选举轮次，那么就会立即更新自己的选举轮次(logicalclock)，并且清空所有已经收到的投票，然后使用初始化的投票来进行PK以确定是否变更内部投票。最终再将内部投票发送出去。
   - 外部投票的选举轮次小于内部投票。若服务器接收的外选票的选举轮次落后于自身的选举轮次，那么Zookeeper就会直接忽略该外部投票，不做任何处理，并返回步骤4。
   - 外部投票的选举轮次等于内部投票。此时可以开始进行选票PK。
6. 选票PK。在进行选票PK时，符合任意一个条件就需要变更投票。
   - 若外部投票中推举的Leader服务器的选举轮次大于内部投票，那么需要变更投票。
   - 若选举轮次一致，那么就对比两者的ZXID，若外部投票的ZXID大，那么需要变更投票。
   - 若两者的ZXID一致，那么就对比两者的SID，若外部投票的SID大，那么就需要变更投票。
7. 变更投票。经过PK后，若确定了外部投票优于内部投票，那么就变更投票，即使用外部投票的选票信息来覆盖内部投票，变更完成后，再次将这个变更后的内部投票发送出去。
8. 选票归档。无论是否变更了投票，都会将刚刚收到的那份外部投票放入选票集合recvset中进行归档。recvset用于记录当前服务器在本轮次的Leader选举中收到的所有外部投票（按照服务队的SID区别，如{(1, vote1), (2, vote2)...}）。
9. 统计投票。完成选票归档后，就可以开始统计投票，统计投票是为了统计集群中是否已经有过半的服务器认可了当前的内部投票，如果确定已经有过半服务器认可了该投票，则终止投票。否则返回步骤4。
10. 更新服务器状态。若已经确定可以终止投票，那么就开始更新服务器状态，服务器首选判断当前被过半服务器认可的投票所对应的Leader服务器是否是自己，若是自己，则将自己的服务器状态更新为LEADING，若不是，则根据具体情况来确定自己是FOLLOWING或是OBSERVING。

以上 10 个步骤就是 FastLeaderElection 的核心，其中步骤4-9会经过几轮循环，直到有Leader选举产生。

## 16. 数据同步
直接差异化同步（DIFF同步）
先回滚再差异化同步（TRUNC+DIFF同步）
仅回滚同步（TRUNC同步）
全量同步（SNAP同步）
## 17. zookeeper是如何保证事务的顺序一致性的？

整个集群完成Leader选举之后，Learner（Follower和Observer的统称）回向Leader服务器进行注册。当Learner服务器想Leader服务器完成注册后，进入数据同步环节。

数据同步流程：（均以消息传递的方式进行）

- Learner向Learder注册
- 数据同步
- 同步确认

Zookeeper的数据同步通常分为四类：

- 直接差异化同步（DIFF同步）
- 先回滚再差异化同步（TRUNC+DIFF同步）
- 仅回滚同步（TRUNC同步）
- 全量同步（SNAP同步）

在进行数据同步前，Leader服务器会完成数据同步初始化：

- peerLastZxid：从learner服务器注册时发送的ACKEPOCH消息中提取lastZxid（该Learner服务器最后处理的ZXID）
- minCommittedLog：Leader服务器Proposal缓存队列committedLog中最小ZXID
- maxCommittedLog：Leader服务器Proposal缓存队列committedLog中最大ZXID

### 1. 直接差异化同步（DIFF同步）

场景：peerLastZxid介于minCommittedLog和maxCommittedLog之间

![](https://images2018.cnblogs.com/blog/632316/201808/632316-20180803082218708-1373657717.png)

### 2. 先回滚再差异化同步（TRUNC+DIFF同步）

场景：当新的Leader服务器发现某个Learner服务器包含了一条自己没有的事务记录，那么就需要让该Learner服务器进行事务回滚--回滚到Leader服务器上存在的，同时也是最接近于peerLastZxid的ZXID

### 3. 仅回滚同步（TRUNC同步）

场景：peerLastZxid 大于 maxCommittedLog

### 4. 全量同步（SNAP同步）

- 场景一：peerLastZxid 小于 minCommittedLog
- 场景二：Leader服务器上没有Proposal缓存队列且peerLastZxid不等于lastProcessZxid

## 18. 分布式集群中为什么会有Master？

在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader选举。

## 19. zk节点宕机如何处理？

Zookeeper本身也是集群，推荐配置不少于3个服务器。Zookeeper自身也要保证当一个节点宕机时，其他节点会继续提供服务。  
如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失；  
如果是一个Leader宕机，Zookeeper会选举出新的Leader。  
ZK集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。所以：

- 3个节点的cluster可以挂掉1个节点(leader可以得到2票>1.5)
- 2个节点的cluster就不能挂掉任何1个节点了(leader可以得到1票<=1)

## 20. zookeeper负载均衡和nginx负载均衡区别

zk的负载均衡是可以调控，nginx只是能调权重，其他需要可控的都需要自己写插件；但是nginx的吞吐量比zk大很多，应该说按业务选择用哪种方式。

## 21. Zookeeper有哪几种几种部署模式？

部署模式：单机模式、伪集群模式、集群模式。

## 22. 集群最少要几台机器，集群规则是怎样的?

集群规则为2N+1台，N>0，即3台。

## 23. 集群支持动态添加机器吗？

其实就是水平扩容了，Zookeeper在这方面不太好。两种方式：

- 全部重启：关闭所有Zookeeper服务，修改配置之后启动。不影响之前客户端的会话。
- 逐个重启：在过半存活即可用的原则下，一台机器重启不影响整个集群对外提供服务。这是比较常用的方式。

3.5版本开始支持动态扩容。

## 24. Zookeeper对节点的watch监听通知是永久的吗？为什么不是永久的?

不是。官方声明：一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。  

为什么不是永久的，举个例子，如果服务端变动频繁，而监听的客户端很多情况下，每次变动都要通知到所有的客户端，给网络和服务器造成很大压力。  
一般是客户端执行getData(“/节点A”,true)，如果节点A发生了变更或删除，客户端会得到它的watch事件，但是在之后节点A又发生了变更，而客户端又没有设置watch事件，就不再给客户端发送。  
在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，我只要最新的数据即可。  

## 25. Zookeeper的java客户端都有哪些？

java客户端：zk自带的zkclient及Apache开源的Curator。

## 26. chubby是什么，和zookeeper比你怎么看？

chubby是google的，完全实现paxos算法，不开源。zookeeper是chubby的开源实现，使用zab协议，paxos算法的变种。

## 27. 说几个zookeeper常用的命令。

常用命令：ls get set create delete等。

## 28. ZAB和Paxos算法的联系与区别？

- 相同点：
  - 两者都存在一个类似于Leader进程的角色，由其负责协调多个Follower进程的运行；
  - Leader进程都会等待超过半数的Follower做出正确的反馈后，才会将一个提案进行提交；
  - ZAB协议中，每个Proposal中都包含一个 epoch 值来代表当前的Leader周期，Paxos中名字为Ballot；
- 不同点：
  - ZAB用来构建高可用的分布式数据主备系统（Zookeeper），Paxos是用来构建分布式一致性状态机系统。

## 29. Zookeeper的典型应用场景

Zookeeper是一个典型的发布/订阅模式的分布式数据管理与协调框架，开发人员可以使用它来进行分布式数据的发布和订阅。

通过对Zookeeper中丰富的数据节点进行交叉使用，配合Watcher事件通知机制，可以非常方便的构建一系列分布式应用中年都会涉及的核心功能，如：

- 数据发布/订阅
- 负载均衡
- 命名服务
- 分布式协调/通知
- 集群管理
- Master选举
- 分布式锁
- 分布式队列

### 1. 数据发布/订阅

**介绍** 
数据发布/订阅系统，即所谓的配置中心，顾名思义就是发布者发布数据供订阅者进行数据订阅。

**目的**  

- 动态获取数据（配置信息）
- 实现数据（配置信息）的集中式管理和数据的动态更新

**设计模式**

- Push 模式
- Pull 模式

**数据（配置信息）特性：**

- 数据量通常比较小
- 数据内容在运行时会发生动态更新
- 集群中各机器共享，配置一致

如：机器列表信息、运行时开关配置、数据库配置信息等

**基于Zookeeper的实现方式**

1. 数据存储：将数据（配置信息）存储到Zookeeper上的一个数据节点
2. 数据获取：应用在启动初始化节点从Zookeeper数据节点读取数据，并在该节点上注册一个数3. 据变更Watcher
   数据变更：当变更数据时，更新Zookeeper对应节点数据，Zookeeper会将数据变更通知发到各客户端，客户端接到通知后重新读取变更后的数据即可。

### 2. 负载均衡

**zk的命名服务** 
命名服务是指通过指定的名字来获取资源或者服务的地址，利用zk创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。

**分布式通知和协调**  
对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后zk将这些变化发送给注册了这个节点的watcher的所有客户端。
对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。

**zk的配置管理（文件系统、通知机制）**  
程序分布式的部署在不同的机器上，将程序的配置信息放在zk的znode下，当有配置发生改变时，也就是znode发生变化时，可以通过改变zk中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。

**Zookeeper集群管理（文件系统、通知机制）**  
所谓集群管理无在乎两点：是否有机器退出和加入、选举master。  
对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。  
新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。  

**Zookeeper分布式锁（文件系统、通知机制）**  
有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。  
对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。  
对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。  

**获取分布式锁的流程**  
在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。客户端调用createNode方法在locker下创建临时顺序节点，然后调用getChildren(“locker”)来获取locker下面的所有子节点，注意此时不用设置任何Watcher。客户端获取到所有的子节点path之后，如果发现自己创建的节点在所有创建的子节点序号最小，那么就认为该客户端获取到了锁。如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，然后对其调用exist()方法，同时对其注册事件监听器。之后，让这个被关注的节点删除，则客户端的Watcher会收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如果是则获取到了锁，如果不是则重复以上步骤继续获取到比自己小的一个节点并注册监听。当前这个过程中还需要许多的逻辑判断。

代码的实现主要是基于互斥锁，获取分布式锁的重点逻辑在于BaseDistributedLock，实现了基于Zookeeper实现分布式锁的细节。

**Zookeeper队列管理（文件系统、通知机制）**  
两种类型的队列：

1. 同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。
2. 队列按照 FIFO 方式进行入队和出队操作。

第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。  
第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建PERSISTENT_SEQUENTIAL节点，创建成功时Watcher通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper的znode用于消息存储，znode存储的数据就是消息队列中的消息内容，SEQUENTIAL序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。

## 30. Zookeeper 的惊群现象

ZooKeeper 的节点通常可以作为分布式锁来使用。比如可以多个服务对同时竞争申请一个节点 "/test/lock"，创建成功的服务获取到这个锁，其他没创建成功的监听这个锁，等到这个锁释放后再重新申请该锁。这样就实现了简单的分布式锁。
但同时在大量锁的情况下会有**“惊群”**的问题。“惊群”就是在一个节点删除的时候，大量对这个节点的删除动作有订阅Watcher的线程会进行回调，这对Zk集群是十分不利的。所以需要避免这种现象的发生。

为了解决“惊群“问题，我们需要放弃订阅一个节点的策略，那么怎么做呢？

1. 我们将锁抽象成目录，多个线程在此目录下创建瞬时的顺序节点，因为Zk会为我们保证节点的顺序性，所以可以利用节点的顺序进行锁的判断。
2. 首先创建顺序节点，然后获取当前目录下最小的节点，判断最小节点是不是当前节点，如果是那么获取锁成功，如果不是那么获取锁失败。
3. 获取锁失败的节点获取当前节点上一个顺序节点，对此节点注册监听，当节点删除的时候通知当前节点。
4. 当unlock的时候删除节点之后会通知下一个节点。

