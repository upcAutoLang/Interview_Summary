# 一. Redis 分布式锁与延时队列

## 1. Redis 的分布式锁

先拿**setnx**来争抢锁，抢到之后，再用**expire**给锁加一个过期时间防止锁忘记了释放。  

这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？  

set指令有非常复杂的参数，这个应该是可以同时把**setnx**和**expire**合成一条指令来用的。

## 2. Redis 的延时队列

使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 **zrangebyscore** 指令获取N秒之前的数据轮询进行处理。

# 二. 如何实现session共享？用Redis该如何实现？

# 三. 缓存击穿、缓存穿透、缓存雪崩的概念和解决方案?

> 参考地址：  
> [《缓存穿透，缓存击穿，缓存雪崩解决方案分析》](https://blog.csdn.net/zeb_perfect/article/details/54135506)  
> [《缓存穿透、缓存击穿、缓存雪崩区别和解决方案》](https://blog.csdn.net/kongtiao5/article/details/82771694)

# 四. Redis的数据一致性问题，分布式多节点和单节点环境下分别描述

> 参考地址：  
> [《Redis使用总结（二、缓存和数据库双写一致性问题）》](https://blog.csdn.net/hukaijun/article/details/81010475)

首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。

![](https://img-blog.csdn.net/20180531090217582)

但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。目前没有一篇全面的博客，对这几种方案进行解析。于是博主战战兢兢，顶着被大家喷的风险，写了这篇文章。

文章结构

本文由以下三个部分组成

1. 讲解缓存更新策略
2. 对每种策略进行缺点分析
3. 针对缺点给出改进方案

先做一个说明，从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。

在这里，我们讨论三种更新策略：

1. 先更新数据库，再更新缓存
2. 先删除缓存，再更新数据库
3. 先更新数据库，再删除缓存

应该没人问我，为什么没有先更新缓存，再更新数据库这种策略。

(1) 先更新数据库，再更新缓存


这套方案，大家是普遍反对的。为什么呢？有如下两点原因。


- 原因一（线程安全角度）
	- 同时有请求A和请求B进行更新操作，那么会出现
		- 线程A更新了数据库
		- 线程B更新了数据库
		- 线程B更新了缓存
		- 线程A更新了缓存
	- 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
- 原因二（业务场景角度）：
	- 有如下两点：
		- 如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
		- 如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。	- 接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。

(2)先删缓存，再更新数据库

该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

那么，如何解决呢？**采用延时双删策略**。伪代码如下：

```
    public void write(String key,Object data){
        redis.delKey(key);
        db.updateData(data);
        Thread.sleep(1000);
        redis.delKey(key);
    }
```

转化为中文描述就是

1. 先淘汰缓存
2. 再写数据库（这两步和原来一样）
3. 休眠1秒，再次淘汰缓存


这么做，可以将1秒内所造成的缓存脏数据，再次删除。那么，**这个1秒怎么确定的，具体该休眠多久呢？**

针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

**如果你用了mysql的读写分离架构怎么办？**

ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。


1. 请求A进行写操作，删除缓存
2. 请求A将数据写入数据库了，
3. 请求B查询缓存发现，缓存没有值
4. 请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
5. 请求B将旧值写入缓存
6. 数据库完成主从同步，从库变为新值

上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。

**采用这种同步淘汰策略，吞吐量降低怎么办？**

ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。

**第二次删除,如果删除失败怎么办？**

这是个非常好的问题，因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库
6. 请求A试图去删除请求B写入对缓存值，结果失败了。


ok,这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。

**如何解决呢？**具体解决方案，且看博主对第(3)种更新策略的解析。

(3) 先更新数据库，再删缓存

首先，先说一下。老外提出了一个缓存更新套路，名为《Cache-Aside pattern》。其中就指出

- 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- 命中：应用程序从cache中取数据，取到后返回。
- 更新：先把数据存到数据库中，成功后，再让缓存失效。

另外，知名社交网站facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。

**这种情况不存在并发问题么？**

不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：

1. 缓存刚好失效
2. 请求A查询数据库，得一个旧值
3. 请求B将新值写入数据库
4. 请求B删除缓存
5. 请求A将查到的旧值写入缓存


ok，如果发生上述情况，确实是会发生脏数据。

**然而，发生这种情况的概率又有多少呢？**

发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。

假设，有人非要抬杠，有强迫症，一定要解决怎么办？

**如何解决上述并发问题？**

首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。

**还有其他造成不一致的原因么？**

有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。

**如何解决？**

提供一个保障的重试机制即可，这里给出两套方案。

方案一：如下图所示

![](https://img-blog.csdn.net/20180531090248883)

流程如下所示：

1. 更新数据库数据；
2. 缓存因为种种问题删除失败
3. 将需要删除的key发送至消息队列
4. 自己消费消息，获得需要删除的key
5. 继续重试删除操作，直到成功

然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。

方案二：流程如下图所示：

![](https://img-blog.csdn.net/20180531090256490)

1. 更新数据库数据
2. 数据库会将操作信息写入binlog日志当中
3. 订阅程序提取出所需要的数据以及key
4. 另起一段非业务代码，获得该信息
5. 尝试删除缓存操作，发现删除失败
6. 将这些信息发送至消息队列
7. 重新从消息队列中获得该数据，重试操作。

备注说明：上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。至于oracle中，博主目前不知道有没有现成中间件可以使用。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。

总结：本文其实是对目前互联网中已有的一致性方案，进行了一个总结。对于先删缓存，再更新数据库的更新策略，还有方案提出维护一个内存队列的方式，博主看了一下，觉得实现异常复杂，没有必要，因此没有必要在文中给出。最后，希望大家有所收获。

# 五. Redis 的数据结构

> 参考地址：[《【Redis】redis各类型数据存储分析》](https://www.cnblogs.com/weknow619/p/10464139.html)

## 1. 底层数据结构

Redis 常用的数据类型主要有：String, List, Hash, Set, ZSet 五种，它们分别对应的底层数据结构有：

- **String**: sds
- **List**: quicklist (linkedlist + ziplist)
- **Hash**: ziplist 或 hashtable
- **Set**: intset 或 hashtable
- **ZSet**: ziplist 或 skiplist

## 2. redisObject

redisObject 对象非常重要，Redis 对象的**类型、内部编码、内存回收、共享对象**等功能，都需要 redisObject 支持。这样设计的好处是，可以针对不同的使用场景，对五种常用类型设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。

例如当我们执行set hello world命令时，会有以下数据模型：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095551839-1295247166.png)

**dictEntry**：Redis 给每个 key-value 键值对分配一个 dictEntry，里面有着 key 和 val 的指针，next 指向下一个 dictEntry 形成链表，这个指针可以将多个哈希值相同的键值对链接在一起，由此来解决哈希冲突问题(链地址法)。

**sds**：键 key **“hello”** 是以 SDS（简单动态字符串）存储，后面详细介绍。

**redisObject**：值val **“world”** 存储在 redisObject 的 ptr 中。实际上，**redis 常用五种类型都是以 redisObject 来存储的**；而 redisObject 中的 type 字段指明了 Value 对象的类型，ptr 字段则指向对象所在的地址。

> 注：无论是 dictEntry 对象，还是 redisObject、SDS 对象，都需要内存分配器（如jemalloc）分配内存进行存储。jemalloc作为Redis的默认内存分配器，在减小内存碎片方面做的相对比较好。比如jemalloc在64位系统中，将内存空间划分为小、大、巨大三个范围；每个范围内又划分了许多小的内存块单位；当Redis存储数据时，会选择大小最合适的内存块进行存储。

前面说过，Redis 每个对象由一个 redisObject 结构表示，它的 ptr 指针指向底层实现的数据结构，而**数据结构由 encoding 属性决定**。比如我们执行以下命令得到存储“hello”对应的编码：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095630848-129556438.png)

redis所有的数据结构类型如下：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095645664-118641258.png)

## 3. sds

```c
struct sdshdr {
    // buf 中已占用空间的长度
    int len;
    // buf 中剩余可用空间的长度
    int free;
    // 数据空间
    char buf[]; // ’\0’空字符结尾
};
```

### (1) sds 编码

字符串对象的底层实现可以是int、raw、embstr（上面的表对应有名称介绍）。

> embstr编码是通过调用一次内存分配函数来分配一块连续的空间，而raw需要调用两次。

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095701626-213641310.png)

int 编码字符串和 embstr 编码字符串在一定条件下会转化为 raw 编码字符串。

- **embstr**：<= 39 字节；
- **int**：8个字节的长整型；
- **raw**：> 39 个字节的字符串

### (2) 空间分配

如果对一个SDS进行修改，分为一下两种情况：

1. **长度小于1MB**：程序将分配和 len 属性同样大小的未使用空间，这时free和len属性值相同。
   - 举个例子，SDS的len将变成15字节，则程序也会分配15字节的未使用空间，SDS的buf数组的实际长度变成15+15+1=31字节（额外一个字节用户保存空字符）
2. **长度大于等于1MB**：程序会分配 1MB 的未使用空间；
   - 比如进行修改之后，SDS的len变成30MB，那么它的实际长度是30MB+1MB+1byte。

## 4. hashtable

hashtable 又名字典，是 Redis 中应用十分广泛的数据结构。除了基础数据结构 Hash, Set 之外，Redis 的全局字典，过期时间的 Key 集合，ZSet 中 value 与 score 的映射，都是基于 hashtable 完成的。

### (1) Hashtable 源码

Hashtable 可以简化成如下结构：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303100153771-48618251.png)可以看出，HashTable 与 Java 1.7 中的 HashMap 实现原理基本相同。代码如下：

```c
typedef struct dict {
    // 类型特定函数
    dictType *type;
     // 私有数据
    void *privdata;
     // 哈希表
    dictht ht[2];
    // rehash 索引
    // 当 rehash 不在进行时，值为 -1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */
     // 目前正在运行的安全迭代器的数量
    int iterators; /* number of iterators currently running */
 } dict;
```

```c
typedef struct dictht {
    // 哈希表数组
    dictEntry **table;
     // 哈希表大小
    unsigned long size;
    // 哈希表大小掩码，用于计算索引值
    // 总是等于 size - 1
    unsigned long sizemask;
    // 该哈希表已有节点的数量
    unsigned long used;
} dictht;
```

```c
typedef struct dictEntry {
    void *key;
    union {void *val;uint64_t u64;int64_t s64;} v;
    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;
 } dictEntry;
```

在 **dict** 的定义中，可以看出有两个 dictht 字典对象。每个字典会带有两个哈希表，一个平时使用，另一个仅在rehash（重新散列）时使用。随着对哈希表的操作，键会逐渐增多或减少。为了让哈希表的负载因子维持在一个合理范围内，Redis会对哈希表的大小进行**扩展或收缩（rehash）**。只有在扩展与收缩时，ht[0] 里面所有的键值对会多次、渐进式的 rehash 到 ht[1] 里。

### (2) Hash 的 Hashtable

Hash 可以使用 Hashtable 或者 ziplist 结构来实现。Hash对象只有同时满足下面两个条件时，才会使用ziplist（压缩列表）：

1. Hash 中元素数量小于 512 个；
2. Hash 中所有键值对的键和值字符串长度都小于 64 字节。

### (3) Set 的 Hashtable

较大数量的 Set 同样也是 HashTable ，但实现的时候 value 全部置为 NULL。

## 5. 压缩列表 ziplist

当一个列表键只包含少量列表项，且是小整数值或长度比较短的字符串时，那么redis就使用ziplist（压缩列表）来做列表键的底层实现。

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095934916-1182103524.png)

**ziplist是Redis为了节约内存而开发的**，是由一系列特殊编码的连续内存块(而不是像双端链表一样每个节点是指针)组成的顺序型数据结构；具体结构相对比较复杂，有兴趣读者可以看Redis 哈希结构内存模型剖析。

## 6. 双端链表 linkedlist

Redis 的 List 结构就是 linkedList 与 ziplist 结合而成的。LinkedList 结构比较像 Java 的 LinkedList，源码如下：

```c
typedef struct listNode {
     // 前置节点
    struct listNode *prev;
    // 后置节点
    struct listNode *next;
    // 节点的值
    void *value;
 } listNode;

 typedef struct list {
     // 表头节点
    listNode *head;
    // 表尾节点
    listNode *tail;
    // 节点值复制函数
    void *(*dup)(void *ptr);
    // 节点值释放函数
    void (*free)(void *ptr);
     // 节点值对比函数
    int (*match)(void *ptr, void *key);
     // 链表所包含的节点数量
    unsigned long len;
 } list;
```

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095859138-1854838056.png)

从图中可以看出 Redis 的 linkedlist 双端链表有以下特性：

- 节点 (ListNode) 带有 prev, next 指针；

- 列表 (List) 有 head 指针和 tail 指针；


所以获取前置节点、后置节点、表头节点和表尾节点的复杂度都是 O(1)。len属性获取节点数量也为O(1)。

与双端链表相比，压缩列表可以节省内存空间，但是进行修改或增删操作时，复杂度较高；因此当节点数量较少时，可以使用压缩列表；但是节点数量多时，还是使用双端链表划算。



## 7. 快速列表 quicklist

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303100045671-69086709.png)

List 对象的底层实现是 quicklist（快速列表，是 ziplist 压缩列表 和 linkedlist 双端链表的组合）。Redis 中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。

quicklist 将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。因为链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。

quicklist 默认的压缩深度是 0，也就是不压缩。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩。

> 注：通常每个 ziplist 的长度为 8KB，该长度可以通过配置文件进行配置。

## 8. 跳跃列表 zskiplist

> 参考地址：  
>
> [《漫画：什么是跳跃表？》](https://www.jianshu.com/p/ac351674d8eb?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)
>
> [《Redis内部数据结构详解之跳跃表(skiplist)》](https://blog.csdn.net/Acceptedxukai/article/details/17333673)

### (1) 跳跃列表基础说明

跳跃表是一种随机化数据结构，基于并联的链表，其效率可以比拟平衡二叉树，查找、删除、插入等操作都可以在对数期望时间内完成，对比平衡树，跳跃表的实现要简单直观很多。

以下是一个跳跃表的例图(来自维基百科)：

![img](http://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Skip_list.svg/470px-Skip_list.svg.png)

从图中可以看出跳跃表主要有以下几个部分构成：

1. **表头 head**：负责维护跳跃表的节点指针；
2. **节点 node**：实际保存元素值，每个节点有一层或多层；
3. **层 level**：保存着指向该层下一个节点的指针；
4. **表尾 tail**：全部由 null 组成；

跳跃表的遍历总是从高层开始，然后随着元素值范围的缩小，慢慢降低到低层。

### (2) 跳跃列表的基本操作

- **查询**<font color=red>**O(logN)**</font>：在跳跃列表上的操作，就是从高层向低层的**逐层比较、定位**，然后进行查询、插入、删除的过程。

- **插入**<font color=red>**O(logN)**</font>：
  1. 用查询的方法找到待插入位置；<font color=red>**O(logN)**</font>
  2. 然后在最底层链表上执行链表的插入操作；<font color=red>**O(1)**</font>
  3. **概率升级**：在最底层有 50% 的概率进行升级；如果升级成功后，倒数第二层插入该节点，同时又有了 50% 概率插入到上一层节点…… 如此每次向上升级都有 50% 的概率，直到触发 50% 不升级概率；<font color=red>**O(logN)**</font>
- **删除**<font color=red>**O(logN)**</font>：
  1. 用查询的方法找到待插入位置；自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点;<font color=red>**O(logN)**</font>
  2. 除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）；<font color=red>**O(1)**</font>

跳跃表保持平衡使用的是【随机抛硬币】的方法。因为跳跃表删除和添加的节点是不可预测的，很难用一种有效算法保证跳表索引分布始终是均匀的。随机抛硬币的方法虽然不能保证所以的绝对均匀分布，但是随着数据量的增大，该算法可以使跳跳结构大体趋于均匀。

### (3) Redis 跳跃表的修改

Redis 作者为了适合自己功能的需要，对原来的跳跃表进行了一下修改：

1. 允许重复的 score 值：多个不同的元素 (member) 的 score 值可以相同；

2. 进行元素对比的时候，不仅要检查 score 值，还需要检查 member：当 score 值相等时，需要比较 member 域进行比较；

3. 结构保存一个 tail 指针：跳跃表的表尾指针；

4. 每个节点都有一个高度为 1 层的前驱指针，用于从底层表尾向表头方向遍历；


# 六. Redis 线程模型

# 七. Redis 的数据淘汰机制

## 1. Redis 的数据淘汰策略

当 Redis **内存超出物理内存限制**时，为了保持高效的可用性，Redis 需要对内存中部分数据进行淘汰。Redis 早起版本使用的数据淘汰策略是 LRU (Least Recently Used，最近最少使用) 策略，LRU 策略是基于最近访问时间进行排序、淘汰的。后来加入了 LFU (Least Frequency Used，最近最低频率) 策略。  
Redis 主要使用的还是 LRU 策略。

- **noeviction**: 可以继续读请求，不可以进行写请求。
  - 返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但 DEL 和几个例外）；
  - 默认淘汰策略。
- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在**设置了过期时间**的键，使得新添加的数据有空间存放。
- **volatile-random**: 回收**随机的键**使得新添加的数据有空间存放，但仅限于在**设置了过期时间的键**。
- **volatile-ttl**: 回收设置了过期时间的键，淘汰策略是**优先回收剩余时间 (TTL) 较短的键**，使得新添加的数据有空间存放。
- **allkeys-lru**: 对全部集合进行回收，尝试回收最少使用的键 (LRU)，使得新添加的数据有空间存放。
- **allkeys-random**: 对全部集合进行回收，回收随机的键使得新添加的数据有空间存放。
- **volatile-lfu**: 对设置了过期时间的键进行 LFU 策略的过期筛选；
- **allkeys-lfu**: 对全部的键进行 LFU 策略的过期筛选；

## 2. LRU 策略

Redis 的数据都是由 key-value 形式构成的，在实现 LRU 的内存淘汰机制时，除了 key-value，LRU 还需要维护一个列表，链表尾部的数据是最少被访问的数据。列表按照最近访问时间进行排序。当内存达到物理内存限制触发 LRU 回收时，对链表尾部的 k-v 进行回收。

但 Redis 的 LRU 并不是这样执行的，Redis 使用了一种近似 LRU 算法。对于所有 Redis 对象，对象头中包含一个 24bit 的信息，作为**对象热度**的标志。在 LRU 淘汰算法中，该标志是一个**时间戳**，记录了最近一次访问该标志位的时间。  
在触发了 LRU 淘汰时，Redis 会随机抽取若干个（默认是 5 个）key，然后删掉最旧的 key。如果这时候内存依旧超出限制，则再次抽选、删除最旧的 Key 值，直到内存低于最大内存限制为止。

Redis Object 的对象头如下所示：

```c
typedef struct redisObject {
    // 对象类型，如 zset, set, hash 等
    unsigned type: 4; 
    // 对象编码如 ziplist, inset, skiplist 等
    unsigned encoding: 4;
    // 对象的热度
    unsigned lru: 24;
    // 引用计数
    int refcount;
    // 对象的 body
    void *ptr;
}
```

其中，lru 值即为表示热度的值。在 LRU 模式下，该字段存储的时间戳是 Redis 服务器的时钟信息 server.lruclock，单位为毫秒。server.lruclock 持续更新，某对象被访问时，对象头中的 LRU 值被更新为当前 server.lruclock 的值，最后当触发 LRU 内存淘汰时，该对象的 LRU 值会与当前 server.lruclock 进行取模等一系列运算，即可得到 LRU 值。

## 3. LFU 策略

LFU 策略与 LRU 的计算方式大致相同，都是根据 Redis 对象头的 LRU 值与 server.lruclock 值进行计算的。但是 LFU 策略下，24bit 的 lru 值被分为 16+8 两部分。

- **ldt (last decrement time，)**: 前 16 位，记录上一次更新时间，计算单位是分钟。
  - ldt 不是对象被访问的时候被更新，而是在 Redis 触发淘汰逻辑时进行更新；
- **logc (logistic counter，对数计数)**: 后 8 位记录频率信息，且以**对数形式**储存，计算单位是分钟。
  - logc 有**衰减算法**，在 ldt 更新时触发。当前 logc 值减去对象空闲时间，除以一个衰减系数；
  - 由于 logc 的统计的是对数信息，所以它的 +1 策略是基于概率的 +1；于是当对数值越大时，+1 操作概率越小，就越难被更新。大致流程如下：
    1. 计算差值：<code>当前对数值 - 基值 (5)</code>；
    2. 计算更新 +1 操作概率：<code>p = 1 / 差值</code>；

# 八. 当前读和快照读

# 九. Redis

## 1. Redis 管道

## 3. 聊聊 Redis 使用场景

## 4. Redis 持久化机制

> 参考地址：[《Redis持久化机制》](https://www.cnblogs.com/justinli/p/10810297.html)

Redis 有两种持久化机制：**快照 (RDB)** 和 **AOF 日志**。其中快照是一次性全量备份，AOF 是增量备份。

### 4.1 快照 (RDB)

Redis 使用操作系统的多进程 COW (Copy On Write) 机制实现快照持久化。在持久化时，由于要一边要持久化，一边又要满足 Redis 的正常使用，所以 Redis 在持久化的时候，使用了 glibc 的 **fork 函数产生了一个子进程**，在子进程中进行快照持久化操作，主进程满足业务的正常使用。  

RDB的原理是**fork和cow**。fork是指redis通过创建子进程来进行RDB操作，cow指的是**copy on write**，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。  

快照持久化的内存策略是：子进程按照**数据页**进行复制。在持久化过程中，子进程负责持久化过程，它将主进程数据段的数据页复制一份出来，然后对原数据页进行存储；同一时间，主进程对那份复制出来的数据进行操作。通过复制小数据量数据页（通常每个数据页只有 4KB）的方式，保证了主进程修改数据不会影响子进程存储，子进程存储的数据，还是子进程产生一瞬间的数据。

快照触发方式有自动触发与手动触发两种。

- **自动触发**：通过 redis.conf 配置文件进行配置；
- **手动触发**：
	- save: 阻塞式触发，在未完成前，客户端无法进行命令操作；
	- bgsave: 非阻塞式触发，主进程 fork 出子进程进行备份操作；


在恢复文件时，将备份文件 (dump.rdb) 放在 Redis 安装目录，然后启动 Redis，就能把 RDB 中的文件加载到 Redis 服务中。

快照存储的优点缺点：

- **优点**：
	- 数据结构紧凑，保存了 Redis 服务在某个时间点上的数据集，非常适合做备份和灾难恢复；
	- 进行 RDB 快照持久化时，主进程会 fork 出一个子进程进行备份工作，主进程不需要额外的 IO 操作；
	- RDB 恢复大数据集时，速度比 AOF 快；
- **缺点**：
	- 版本兼容问题：Redis 版本更新过程中有多个 RDB 版本，存在老版 RDB 兼容性无法兼容新版的问题；
	- 无法做到实时持久化，因为 bgsave 时的 fork 操作每次都会创建子进程，内存中的数据被克隆了一份，属于重量级操作。

	
### 4.2 AOF

AOF 日志存储的是 **Redis 服务器的顺序指令序列**，它只记录对内存进行修改的指令记录。AOF 使用追加记录的方式，在 Redis 长期运行的过程中，AOF 日志会越来越长，所以一旦宕机重启载入 AOF 日志，将会是一个非常耗时的功能，因此我们需要对 AOF 进行瘦身，即 AOF 重写。  
AOF 重写并不是对原始的 AOF 文件进行重新整理，而是 fork 一个子进程遍历服务器的键值对，转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后，将原来的文件替换为序列化后的文件即可。  
AOF 重写分为两个过程，一个是 fork 子进程重写过程执行的原始数据内容，另一个是在 **fork 过程中主进程修改的指令**。

### 4.3 混合持久化

Redis 4.0 之后加入了新的持久化选项：混合持久化。它将 RDB 和 AOF 内容放在一起，其中 AOF 日志记录的不是全量日志，而是**持久化开始到持久化结束**时间内的 AOF 日志（通常该部分日志很小）。

### 4.4 AOF 的持久化策略

问：**如果突然机器掉电会怎样？**  

**AOF 的持久化策略**：AOF 日志是以文件形式存在的，里面记录的是内存的操作记录，它的实现是将**操作系统内核为文件描述符分配的内存缓存，通过异步的方式刷新到数据磁盘中**。这种操作是 glibc 的 fsync 操作，它是一个很慢的操作，与 Redis 的高性能是相反的。  
AOF 提供了三种持久化策略：

- **no**: 无 fsync，由系统保证数据刷新到磁盘，速度最快，但很不安全（通常不使用）；
- **always**: 每次 fsync，每一个修改内存的 Redis 指令都会执行一次 fsync，速度很慢（通常不使用）；
- **everysec**: 每秒进行一次 fsync，有可能丢失一秒的 fsync 的数据。通常选择 everysec 策略，兼顾安全性和效率。

持久化取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

### 4.5 其他问题

Redis集群的数据同步？AOF 与 RDB 的优缺点？

## 5. Redis 相比 memcached 有哪些优势？

- memcached 所有的值均是简单的字符串，redis 作为其替代者，支持更为丰富的数据类型
- redis 的速度比 memcached 快很多
- redis 可以**持久化**其数据

## 6. Redis 集群方案与实现

问：**Redis集群，集群的高可用怎么保证，集群的原理是什么？**  

- **Redis Sentinal** 着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。   

- **Redis Cluster** 着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。

## 7. Redis IO多路复用技术以及epoll实现原理

> 参考地址：[《Redis IO多路复用技术以及epoll实现原理》](https://blog.csdn.net/wxy941011/article/details/80274233)

redis 是一个单线程却性能非常好的内存数据库， 主要用来作为缓存系统。 redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。
为什么 Redis 中要使用 I/O 多路复用这种技术呢？
首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的。
redis的io模型主要是基于epoll实现的，不过它也提供了 select和kqueue的实现，默认采用epoll。
那么epoll到底是个什么东西呢？ 其实只是众多i/o多路复用技术当中的一种而已，但是相比其他io多路复用技术(select, poll等等)，epoll有诸多优点：

　　1. epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大  ，具体数目可以 cat /proc/sys/fs/file-max 察看。
　　2. 效率提升， Epoll 最大的优点就在于它只管你“活跃”的连接 ，而跟连接总数无关，因此在实际的网络环境中， Epoll 的效率就会远远高于 select 和 poll 。
　　3. 内存拷贝， Epoll 在这点上使用了“共享内存 ”，这个内存拷贝也省略了。

epoll与select/poll的区别
     select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪，能够通知程序进行相应的操作。
     select的本质是采用32个整数的32位，即32*32= 1024来标识，fd值为1-1024。当fd的值超过1024限制时，就必须修改FD_SETSIZE的大小。这个时候就可以标识32*max值范围的fd。
     poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。
     epoll还是poll的一种优化，返回后不需要对所有的fd进行遍历，在内核中维持了fd的列表。select和poll是将这个内核列表维持在用户态，然后传递到内核中。与poll/select不同，epoll不再是一个单独的系统调用，而是由epoll_create/epoll_ctl/epoll_wait三个系统调用组成，后面将会看到这样做的好处。epoll在2.6以后的内核才支持。
select/poll的几大缺点：
1、每次调用select/poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
2、同时每次调用select/poll都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
3、针对select支持的文件描述符数量太小了，默认是1024
4.select返回的是含有整个句柄的数组，应用程序需要遍历整个数组才能发现哪些句柄发生了事件；
5.select的触发方式是水平触发，应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作，那么之后每次select调用还是会将这些文件描述符通知进程。
相比select模型，poll使用链表保存文件描述符，因此没有了监视文件数量的限制，但其他三个缺点依然存在。

epoll IO多路复用模型实现机制
由于epoll的实现机制与select/poll机制完全不同，上面所说的 select的缺点在epoll上不复存在。
epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右
设想一下如下场景：有100万个客户端同时与一个服务器进程保持着TCP连接。而每一时刻，通常只有几百上千个TCP连接是活跃的(事实上大部分场景都是这种情况)。如何实现这样的高并发？
在select/poll时代，服务器进程每次都把这100万个连接告诉操作系统(从用户态复制句柄数据结构到内核态)，让操作系统内核去查询这些套接字上是否有事件发生，轮询完后，再将句柄数据复制到用户态，让服务器应用程序轮询处理已发生的网络事件，这一过程资源消耗较大，因此，select/poll一般只能处理几千的并发连接。
如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。
但是使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，每一次无差别轮询时间就越长
epoll的设计和实现与select完全不同。epoll通过在Linux内核中申请一个简易的文件系统(文件系统一般用什么数据结构实现？B+树)。把原先的select/poll调用分成了3个部分：
1）调用epoll_create()建立一个epoll对象(在epoll文件系统中为这个句柄对象分配资源)
2）调用epoll_ctl向epoll对象中添加这100万个连接的套接字
3）调用epoll_wait收集发生的事件的连接
如此一来，要实现上面说是的场景，只需要在进程启动时建立一个epoll对象，然后在需要的时候向这个epoll对象中添加或者删除连接。同时，epoll_wait的效率也非常高，因为调用epoll_wait时，并没有一股脑的向操作系统复制这100万个连接的句柄数据，内核也不需要去遍历全部的连接。

底层实现：
当某一进程调用epoll_create方法时，Linux内核会创建一个eventpoll结构体，这个结构体中有两个成员与epoll的使用方式密切相关。eventpoll结构体如下所示：


每一个epoll对象都有一个独立的eventpoll结构体，用于存放通过epoll_ctl方法向epoll对象中添加进来的事件。这些事件都会挂载在红黑树中，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是lgn，其中n为树的高度)。
而所有添加到epoll中的事件都会与设备(网卡)驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个回调方法。这个回调方法在内核中叫ep_poll_callback,它会将发生的事件添加到rdlist双链表中。
在epoll中，对于每一个事件，都会建立一个epitem结构体，如下所示：


当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。
优势：
1. 不用重复传递。我们调用epoll_wait时就相当于以往调用select/poll，但是这时却不用传递socket句柄给内核，因为内核已经在epoll_ctl中拿到了要监控的句柄列表。
 2. 在内核里，一切皆文件。所以，epoll向内核注册了一个文件系统，用于存储上述的被监控socket。当你调用epoll_create时，就会在这个虚拟的epoll文件系统里创建一个file结点。当然这个file不是普通文件，它只服务于epoll。
epoll在被内核初始化时（操作系统启动），同时会开辟出epoll自己的内核高速cache区，用于安置每一个我们想监控的socket，这些socket会以红黑树的形式保存在内核cache里，以支持快速的查找、插入、删除。这个内核高速cache区，就是建立连续的物理内存页，然后在之上建立slab层，简单的说，就是物理上分配好你想要的size的内存对象，每次使用时都是使用空闲的已分配好的对象。
 3. 极其高效的原因：
这是由于我们在调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。
   
    这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。（注：好好理解这句话！）
从上面这句可以看出，epoll的基础就是回调呀！ 

    如此，一颗红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。执行epoll_create时，创建了红黑树和就绪链表，执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。执行epoll_wait时立刻返回准备就绪链表里的数据即可。

    最后看看epoll独有的两种模式LT和ET。无论是LT和ET模式，都适用于以上所说的流程。区别是，LT模式下，只要一个句柄上的事件一次没有处理完，会在以后调用epoll_wait时次次返回这个句柄，而ET模式仅在第一次返回。

    关于LT，ET，有一端描述，LT和ET都是电子里面的术语，ET是边缘触发，LT是水平触发，一个表示只有在变化的边际触发，一个表示在某个阶段都会触发。
LT, ET这件事怎么做到的呢？当一个socket句柄上有事件时，内核会把该句柄插入上面所说的准备就绪list链表，这时我们调用epoll_wait，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表，最后，epoll_wait干了件事，就是检查这些socket，如果不是ET模式（就是LT模式的句柄了），并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了。所以，非ET的句柄，只要它上面还有事件，epoll_wait每次都会返回这个句柄。（从上面这段，可以看出，LT还有个回放的过程，低效了）

## 8. 缓存奔溃

## 9. 缓存降级

## 10. 使用缓存的合理性问题

## 12. Redis 的 BloomFilter

> [《Redis-避免缓存穿透的利器之BloomFilter》](https://juejin.im/post/5db69365518825645656c0de)

## 14. Redis 大量 Key 值

**假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？**  

使用**keys**指令可以扫出指定模式的key列表。  

**对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ **  

这个时候你要回答Redis关键的一个特性：Redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用**scan**指令，**scan**指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

**不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。**

## 16. Redis 的同步机制





## 其他问题

### (1) 什么是Redis？

Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个数据库统统加载在内存当中进行操作，定期通过**异步操作**把数据 **flush 到硬盘上**进行保存。  
因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value DB。 Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存**多种数据结构**。  
此外单个 value 的最大限制是 1GB，不像 memcached 只能保存 1MB 的数据，因此 Redis 可以用来实现很多有用的功能（比方说用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性能消息队列服务，用他的 Set 可以做高性能的 tag 系统等等）。另外 Redis 也可以对存入的 Key-Value 设置 expire 时间，因此也可以被当作一个功能加强版的 memcached 来用。  
Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。

### (3) Redis支持哪几种数据类型？

String, List, Set, Sorted Set, hashes



### (8) Redis集群方案应该怎么做？都有哪些方案？

1. codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。
3. redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。

### (9) Redis集群方案什么情况下会导致整个集群不可用？
有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。

### (11) Redis有哪些适合的场景？

- 会话缓存（Session Cache）
	- 最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？
	- 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。
- 队列
	- Redis在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。
	- 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。
- 排行榜/计数器
	- Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：
	- 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：
	- ZRANGE user_scores 0 10 WITHSCORES
	- Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。
- 发布/订阅
	- 最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。

### (14) Jedis与Redisson对比有什么优缺点？
Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。

### (16) 说说Redis哈希槽的概念？

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

### (34) Redis持久化数据和缓存怎么做扩容？

如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。  
如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。

### (35) 分布式Redis是前期做还是后期规模上来了再做好？为什么？

既然Redis是如此的轻量（单实例只使用1M内存）,为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。  
一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。  
这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。

### (39) Redis的内存占用情况怎么样？
给你举个例子： 100万个键值对（键是0到999999值是字符串“hello world”）在我的32位的Mac笔记本上 用了100MB。同样的数据放到一个key里只需要16MB， 这是因为键值有一个很大的开销。 在Memcached上执行也是类似的结果，但是相对Redis的开销要小一点点，因为Redis会记录类型信息引用计数等等。  
当然，大键值对时两者的比例要好很多。  
64位的系统比32位的需要更多的内存开销，尤其是键值对都较小时，这是因为64位的系统里指针占用了8个字节。 但是，当然，64位系统支持更大的内存，所以为了运行大型的Redis服务器或多或少的需要使用64位的系统。

### (40) 都有哪些办法可以降低Redis的内存使用情况呢？

如果你使用的是32位的Redis实例，可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。

### (42) Redis是单线程的，如何提高多核CPU的利用率？
可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。

### (44) Redis常见性能问题和解决方案？

1. Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
2. 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
3. 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
4. 尽量避免在压力很大的主库上增加从库
5. 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...

这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。

### (45) Redis提供了哪几种持久化方式？

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.
- AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.

如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。  
你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。  
最重要的事情是了解RDB和AOF持久化方式的不同,让我们以RDB持久化方式开始。

### (46) 如何选择合适的持久化方式？
一般来说， 如果想达到足以媲美PostgreSQL的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。  
有很多用户都只使用AOF持久化，但并不推荐这种方式：因为定时生成RDB快照（snapshot）非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外， 使用RDB还可以避免之前提到的AOF程序的bug。


