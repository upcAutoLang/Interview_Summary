# 一. Redis 分布式锁与延时队列

## 1. Redis 的分布式锁

先拿**setnx**来争抢锁，抢到之后，再用**expire**给锁加一个过期时间防止锁忘记了释放。  

这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？  

set指令有非常复杂的参数，这个应该是可以同时把**setnx**和**expire**合成一条指令来用的。

## 2. Redis 的延时队列

使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 **zrangebyscore** 指令获取N秒之前的数据轮询进行处理。

# 二. 如何实现session共享？用Redis该如何实现？

# 三. 缓存击穿、缓存穿透、缓存雪崩的概念和解决方案?

> 参考地址：  
> [《缓存穿透，缓存击穿，缓存雪崩解决方案分析》](https://blog.csdn.net/zeb_perfect/article/details/54135506)  
> [《缓存穿透、缓存击穿、缓存雪崩区别和解决方案》](https://blog.csdn.net/kongtiao5/article/details/82771694)

# 四. Redis的数据一致性问题，分布式多节点和单节点环境下分别描述

> 参考地址：  
> [《Redis使用总结（二、缓存和数据库双写一致性问题）》](https://blog.csdn.net/hukaijun/article/details/81010475)

首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。

![](https://img-blog.csdn.net/20180531090217582)

但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。目前没有一篇全面的博客，对这几种方案进行解析。于是博主战战兢兢，顶着被大家喷的风险，写了这篇文章。

文章结构

本文由以下三个部分组成

1. 讲解缓存更新策略
2. 对每种策略进行缺点分析
3. 针对缺点给出改进方案

先做一个说明，从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。

在这里，我们讨论三种更新策略：

1. 先更新数据库，再更新缓存
2. 先删除缓存，再更新数据库
3. 先更新数据库，再删除缓存

应该没人问我，为什么没有先更新缓存，再更新数据库这种策略。

(1) 先更新数据库，再更新缓存


这套方案，大家是普遍反对的。为什么呢？有如下两点原因。


- 原因一（线程安全角度）
	- 同时有请求A和请求B进行更新操作，那么会出现
		- 线程A更新了数据库
		- 线程B更新了数据库
		- 线程B更新了缓存
		- 线程A更新了缓存
	- 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
- 原因二（业务场景角度）：
	- 有如下两点：
		- 如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
		- 如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。	- 接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。

(2)先删缓存，再更新数据库

该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

那么，如何解决呢？**采用延时双删策略**。伪代码如下：

```
    public void write(String key,Object data){
        redis.delKey(key);
        db.updateData(data);
        Thread.sleep(1000);
        redis.delKey(key);
    }
```

转化为中文描述就是

1. 先淘汰缓存
2. 再写数据库（这两步和原来一样）
3. 休眠1秒，再次淘汰缓存


这么做，可以将1秒内所造成的缓存脏数据，再次删除。那么，**这个1秒怎么确定的，具体该休眠多久呢？**

针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

**如果你用了mysql的读写分离架构怎么办？**

ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。


1. 请求A进行写操作，删除缓存
2. 请求A将数据写入数据库了，
3. 请求B查询缓存发现，缓存没有值
4. 请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
5. 请求B将旧值写入缓存
6. 数据库完成主从同步，从库变为新值

上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。

**采用这种同步淘汰策略，吞吐量降低怎么办？**

ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。

**第二次删除,如果删除失败怎么办？**

这是个非常好的问题，因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库
6. 请求A试图去删除请求B写入对缓存值，结果失败了。


ok,这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。

**如何解决呢？**具体解决方案，且看博主对第(3)种更新策略的解析。

(3) 先更新数据库，再删缓存

首先，先说一下。老外提出了一个缓存更新套路，名为《Cache-Aside pattern》。其中就指出

- 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- 命中：应用程序从cache中取数据，取到后返回。
- 更新：先把数据存到数据库中，成功后，再让缓存失效。

另外，知名社交网站facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。

**这种情况不存在并发问题么？**

不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：

1. 缓存刚好失效
2. 请求A查询数据库，得一个旧值
3. 请求B将新值写入数据库
4. 请求B删除缓存
5. 请求A将查到的旧值写入缓存


ok，如果发生上述情况，确实是会发生脏数据。

**然而，发生这种情况的概率又有多少呢？**

发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。

假设，有人非要抬杠，有强迫症，一定要解决怎么办？

**如何解决上述并发问题？**

首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。

**还有其他造成不一致的原因么？**

有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。

**如何解决？**

提供一个保障的重试机制即可，这里给出两套方案。

方案一：如下图所示

![](https://img-blog.csdn.net/20180531090248883)

流程如下所示：

1. 更新数据库数据；
2. 缓存因为种种问题删除失败
3. 将需要删除的key发送至消息队列
4. 自己消费消息，获得需要删除的key
5. 继续重试删除操作，直到成功

然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。

方案二：流程如下图所示：

![](https://img-blog.csdn.net/20180531090256490)

1. 更新数据库数据
2. 数据库会将操作信息写入binlog日志当中
3. 订阅程序提取出所需要的数据以及key
4. 另起一段非业务代码，获得该信息
5. 尝试删除缓存操作，发现删除失败
6. 将这些信息发送至消息队列
7. 重新从消息队列中获得该数据，重试操作。

备注说明：上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。至于oracle中，博主目前不知道有没有现成中间件可以使用。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。

总结：本文其实是对目前互联网中已有的一致性方案，进行了一个总结。对于先删缓存，再更新数据库的更新策略，还有方案提出维护一个内存队列的方式，博主看了一下，觉得实现异常复杂，没有必要，因此没有必要在文中给出。最后，希望大家有所收获。

# 五. Redis 的数据结构

> 参考地址：  
> [《【Redis】redis各类型数据存储分析》](https://www.cnblogs.com/weknow619/p/10464139.html)  
> [《一文深入了解 Redis 内存模型，Redis 的快是有原因的！》](https://mp.weixin.qq.com/s/7pSLPQQyeqRd7SuWGu8oJg)

## 1. 底层数据结构

Redis 常用的数据类型主要有：String, List, Hash, Set, ZSet 五种，它们分别对应的底层数据结构有：

- **String**: sds
- **List**: quicklist (linkedlist + ziplist)
- **Hash**: ziplist 或 hashtable
- **Set**: intset 或 hashtable
- **ZSet**: ziplist 或 skiplist

## 2. redisObject

redisObject 对象非常重要，Redis 对象的**类型、内部编码、内存回收、共享对象**等功能，都需要 redisObject 支持。这样设计的好处是，可以针对不同的使用场景，对五种常用类型设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。

例如当我们执行set hello world命令时，会有以下数据模型：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095551839-1295247166.png)

**dictEntry**：Redis 给每个 key-value 键值对分配一个 dictEntry，里面有着 key 和 val 的指针，next 指向下一个 dictEntry 形成链表，这个指针可以将多个哈希值相同的键值对链接在一起，由此来解决哈希冲突问题(链地址法)。

**sds**：键 key **“hello”** 是以 SDS（简单动态字符串）存储，后面详细介绍。

**redisObject**：值val **“world”** 存储在 redisObject 的 ptr 中。实际上，**redis 常用五种类型都是以 redisObject 来存储的**；而 redisObject 中的 type 字段指明了 Value 对象的类型，ptr 字段则指向对象所在的地址。

> 注：无论是 dictEntry 对象，还是 redisObject、SDS 对象，都需要内存分配器（如jemalloc）分配内存进行存储。jemalloc作为Redis的默认内存分配器，在减小内存碎片方面做的相对比较好。比如jemalloc在64位系统中，将内存空间划分为小、大、巨大三个范围；每个范围内又划分了许多小的内存块单位；当Redis存储数据时，会选择大小最合适的内存块进行存储。

前面说过，Redis 每个对象由一个 redisObject 结构表示，它的 ptr 指针指向底层实现的数据结构，而**数据结构由 encoding 属性决定**。比如我们执行以下命令得到存储“hello”对应的编码：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095630848-129556438.png)

redis所有的数据结构类型如下：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095645664-118641258.png)

## 3. sds

```c
struct sdshdr {
    // buf 中已占用空间的长度
    int len;
    // buf 中剩余可用空间的长度
    int free;
    // 数据空间
    char buf[]; // ’\0’空字符结尾
};
```

### (1) sds 编码

字符串对象的底层实现可以是int、raw、embstr（上面的表对应有名称介绍）。

> embstr编码是通过调用一次内存分配函数来分配一块连续的空间，而raw需要调用两次。

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095701626-213641310.png)

int 编码字符串和 embstr 编码字符串在一定条件下会转化为 raw 编码字符串。

- **embstr**：<= 39 字节；
- **int**：8个字节的长整型；
- **raw**：> 39 个字节的字符串

### (2) 空间分配

如果对一个SDS进行修改，分为一下两种情况：

1. **长度小于1MB**：程序将分配和 len 属性同样大小的未使用空间，这时free和len属性值相同。
   - 举个例子，SDS的len将变成15字节，则程序也会分配15字节的未使用空间，SDS的buf数组的实际长度变成15+15+1=31字节（额外一个字节用户保存空字符）
2. **长度大于等于1MB**：程序会分配 1MB 的未使用空间；
   - 比如进行修改之后，SDS的len变成30MB，那么它的实际长度是30MB+1MB+1byte。

## 4. hashtable

hashtable 又名字典，是 Redis 中应用十分广泛的数据结构。除了基础数据结构 Hash, Set 之外，Redis 的全局字典，过期时间的 Key 集合，ZSet 中 value 与 score 的映射，都是基于 hashtable 完成的。

### (1) Hashtable 源码

Hashtable 可以简化成如下结构：

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303100153771-48618251.png)可以看出，HashTable 与 Java 1.7 中的 HashMap 实现原理基本相同。代码如下：

```c
typedef struct dict {
    // 类型特定函数
    dictType *type;
     // 私有数据
    void *privdata;
     // 哈希表
    dictht ht[2];
    // rehash 索引
    // 当 rehash 不在进行时，值为 -1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */
     // 目前正在运行的安全迭代器的数量
    int iterators; /* number of iterators currently running */
 } dict;
```

```c
typedef struct dictht {
    // 哈希表数组
    dictEntry **table;
     // 哈希表大小
    unsigned long size;
    // 哈希表大小掩码，用于计算索引值
    // 总是等于 size - 1
    unsigned long sizemask;
    // 该哈希表已有节点的数量
    unsigned long used;
} dictht;
```

```c
typedef struct dictEntry {
    void *key;
    union {void *val;uint64_t u64;int64_t s64;} v;
    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;
 } dictEntry;
```

在 **dict** 的定义中，可以看出有两个 dictht 字典对象。每个字典会带有两个哈希表，一个平时使用，另一个仅在rehash（重新散列）时使用。随着对哈希表的操作，键会逐渐增多或减少。为了让哈希表的负载因子维持在一个合理范围内，Redis会对哈希表的大小进行**扩展或收缩（rehash）**。只有在扩展与收缩时，ht[0] 里面所有的键值对会多次、渐进式的 rehash 到 ht[1] 里。

### (2) Hash 的 Hashtable

Hash 可以使用 Hashtable 或者 ziplist 结构来实现。Hash对象只有同时满足下面两个条件时，才会使用ziplist（压缩列表）：

1. Hash 中元素数量小于 512 个；
2. Hash 中所有键值对的键和值字符串长度都小于 64 字节。

### (3) Set 的 Hashtable

较大数量的 Set 同样也是 HashTable ，但实现的时候 value 全部置为 NULL。

>  注：
>  1. Hash 为压缩链表的条件如下，如果其中一个不满足，则会转换为 Hashtable 格式；
>  	- 元素数量少于 512 个；
>  	- 每个元素大小都不足 64bytes；
>  2. Set 为 Intset 的条件如下，如果其中一个不满足，则会转换为 Hashtable 格式；
>  	- 元素数量少于 512 个；
>  	- 每个元素都是整数类型；

## 5. 压缩列表 ziplist

当一个列表键只包含少量列表项，且是小整数值或长度比较短的字符串时，那么redis就使用ziplist（压缩列表）来做列表键的底层实现。

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095934916-1182103524.png)

**ziplist是Redis为了节约内存而开发的**，是由一系列特殊编码的连续内存块(而不是像双端链表一样每个节点是指针)组成的顺序型数据结构；具体结构相对比较复杂，有兴趣读者可以看Redis 哈希结构内存模型剖析。

> 注：
> 1. List 满足以下条件才会使用 ziplist，如果其中之一不满足，则转换为**双端链表**。
> 	- 元素数量少于 512 个；
> 	- 每个元素大小都不足 64bytes；
> 2. ZSet 满足以下条件才会使用 ziplist，如果其中之一不满足，则转换为**跳跃链表**。
> 	- 元素数量小于 128 个；
> 	- 有序集合中所有成员长度都不足 64 字节。

## 6. 双端链表 linkedlist

Redis 的 List 结构就是 linkedList 与 ziplist 结合而成的。LinkedList 结构比较像 Java 的 LinkedList，源码如下：

```c
typedef struct listNode {
     // 前置节点
    struct listNode *prev;
    // 后置节点
    struct listNode *next;
    // 节点的值
    void *value;
 } listNode;

 typedef struct list {
     // 表头节点
    listNode *head;
    // 表尾节点
    listNode *tail;
    // 节点值复制函数
    void *(*dup)(void *ptr);
    // 节点值释放函数
    void (*free)(void *ptr);
     // 节点值对比函数
    int (*match)(void *ptr, void *key);
     // 链表所包含的节点数量
    unsigned long len;
 } list;
```

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303095859138-1854838056.png)

从图中可以看出 Redis 的 linkedlist 双端链表有以下特性：

- 节点 (ListNode) 带有 prev, next 指针；
- 列表 (List) 有 head 指针和 tail 指针；

所以获取前置节点、后置节点、表头节点和表尾节点的复杂度都是 O(1)。len属性获取节点数量也为O(1)。

与双端链表相比，压缩列表可以节省内存空间，但是进行修改或增删操作时，复杂度较高；因此当节点数量较少时，可以使用压缩列表；但是节点数量多时，还是使用双端链表划算。

>  注：
>  1. **双端链表**转换为压缩链表的条件：
>  	- 元素数量少于 512 个；
>  	- 每个元素大小都不足 64bytes；

## 7. 快速列表 quicklist

![img](https://img2018.cnblogs.com/blog/1044046/201903/1044046-20190303100045671-69086709.png)

List 对象的底层实现是 quicklist（快速列表，是 ziplist 压缩列表 和 linkedlist 双端链表的组合）。Redis 中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。

quicklist 将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。因为链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。

quicklist 默认的压缩深度是 0，也就是不压缩。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩。

> 注：通常每个 ziplist 的长度为 8KB，该长度可以通过配置文件进行配置。

## 8. 跳跃列表 zskiplist

> 参考地址：  
>
> [《漫画：什么是跳跃表？》](https://www.jianshu.com/p/ac351674d8eb?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)
>
> [《Redis内部数据结构详解之跳跃表(skiplist)》](https://blog.csdn.net/Acceptedxukai/article/details/17333673)

### (1) 跳跃列表基础说明

跳跃表是一种随机化数据结构，基于并联的链表，其效率可以比拟平衡二叉树，查找、删除、插入等操作都可以在对数期望时间内完成，对比平衡树，跳跃表的实现要简单直观很多。

以下是一个跳跃表的例图(来自维基百科)：

![img](http://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Skip_list.svg/470px-Skip_list.svg.png)

从图中可以看出跳跃表主要有以下几个部分构成：

1. **表头 head**：负责维护跳跃表的节点指针；
2. **节点 node**：实际保存元素值，每个节点有一层或多层；
3. **层 level**：保存着指向该层下一个节点的指针；
4. **表尾 tail**：全部由 null 组成；

跳跃表的遍历总是从高层开始，然后随着元素值范围的缩小，慢慢降低到低层。

### (2) 跳跃列表的基本操作

- **查询**<font color=red>**O(logN)**</font>：在跳跃列表上的操作，就是从高层向低层的**逐层比较、定位**，然后进行查询、插入、删除的过程。

- **插入**<font color=red>**O(logN)**</font>：
  1. 用查询的方法找到待插入位置；<font color=red>**O(logN)**</font>
  2. 然后在最底层链表上执行链表的插入操作；<font color=red>**O(1)**</font>
  3. **概率升级**：在最底层有 50% 的概率进行升级；如果升级成功后，倒数第二层插入该节点，同时又有了 50% 概率插入到上一层节点…… 如此每次向上升级都有 50% 的概率，直到触发 50% 不升级概率；<font color=red>**O(logN)**</font>
- **删除**<font color=red>**O(logN)**</font>：
  1. 用查询的方法找到待插入位置；自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点;<font color=red>**O(logN)**</font>
  2. 除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）；<font color=red>**O(1)**</font>

跳跃表保持平衡使用的是【随机抛硬币】的方法。因为跳跃表删除和添加的节点是不可预测的，很难用一种有效算法保证跳表索引分布始终是均匀的。随机抛硬币的方法虽然不能保证所以的绝对均匀分布，但是随着数据量的增大，该算法可以使跳跳结构大体趋于均匀。

### (3) Redis 跳跃表的修改

Redis 作者为了适合自己功能的需要，对原来的跳跃表进行了一下修改：

1. 允许重复的 score 值：多个不同的元素 (member) 的 score 值可以相同；
2. 进行元素对比的时候，不仅要检查 score 值，还需要检查 member：当 score 值相等时，需要比较 member 域进行比较；
3. 结构保存一个 tail 指针：跳跃表的表尾指针；
4. 每个节点都有一个高度为 1 层的前驱指针，用于从底层表尾向表头方向遍历；


# 六. Redis 线程模型

> 参考地址：  
> [《Redis线程模型》](https://www.cnblogs.com/barrywxx/p/8570821.html)  
> [《Redis线程模型》简书](https://www.jianshu.com/p/8f2fb61097b8)

redis 内部使用**文件事件处理器 (File Event Handler)**，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 **IO 多路复用机制**，同时监听多个 socket，根据被监听 socket 上的事件（如连接应答 accept、读取 read、写入 write、关闭 close）等操作时，与操作相对应的事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。  
文件事件处理器由四部分组成，如下图所示：

![Redis 文件事件处理器组成](./pic/Redis/文件事件处理器组成.png)

- **套接字**
- **IO 多路复用程序**
- **文件事件分发器**
- **事件处理器**
	- 事件处理器包括各种类型，如命令请求处理器、命令响应处理器、连接应答处理器、复制处理器等；

多个 socket 可能会并发产生不同的操作，每个操作对应不同的事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，然后通过这个队列， 以**有序、同步、且每次一个套接字的方式**向文件事件分派器传送套接字。当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I/O 多路复用程序才会继续向事件分派器传送下一个套接字。如图所示：

![Redis 多路复用队列](./pic/Redis/Redis多路复用队列.png)

客户端与 redis 服务器的一次通信过程如下：

1. 客户端向 Redis Server 的 socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件；
2. Redis Server 的 IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中；
3. 文件事件分派器从队列中获取该事件，交给连接应答处理器；
4. 连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联；
5. 假设此时客户端发送了一个 <code>set key value</code> 请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将事件压入队列；
6. 事件分派器从队列中获取到该事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理；
7. 命令请求处理器读取 socket01 的 key value，并在自己内存中完成 key value 的设置；
8. 操作完成后，它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。
9. 如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中；
10. 事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。

由上面完成了一次通信的过程可以看出，Redis 效率高的原因在于一是**纯内存操作**，二是核心是基于**非阻塞的 IO 多路复用机制**，此外，单线程反而避免了多线程的频繁上下文切换问题。

# 七. Redis 的数据淘汰机制

## 1. Redis 的数据淘汰策略

当 Redis **内存超出物理内存限制**时，为了保持高效的可用性，Redis 需要对内存中部分数据进行淘汰。Redis 早起版本使用的数据淘汰策略是 LRU (Least Recently Used，最近最少使用) 策略，LRU 策略是基于最近访问时间进行排序、淘汰的。后来加入了 LFU (Least Frequency Used，最近最低频率) 策略。  
Redis 主要使用的还是 LRU 策略。

- **noeviction**: 可以继续读请求，不可以进行写请求。
  - 返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但 DEL 和几个例外）；
  - 默认淘汰策略。
- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在**设置了过期时间**的键，使得新添加的数据有空间存放。
- **volatile-random**: 回收**随机的键**使得新添加的数据有空间存放，但仅限于在**设置了过期时间的键**。
- **volatile-ttl**: 回收设置了过期时间的键，淘汰策略是**优先回收剩余时间 (TTL) 较短的键**，使得新添加的数据有空间存放。
- **allkeys-lru**: 对全部集合进行回收，尝试回收最少使用的键 (LRU)，使得新添加的数据有空间存放。
- **allkeys-random**: 对全部集合进行回收，回收随机的键使得新添加的数据有空间存放。
- **volatile-lfu**: 对设置了过期时间的键进行 LFU 策略的过期筛选；
- **allkeys-lfu**: 对全部的键进行 LFU 策略的过期筛选；

## 2. LRU 策略

Redis 的数据都是由 key-value 形式构成的，在实现 LRU 的内存淘汰机制时，除了 key-value，LRU 还需要维护一个列表，链表尾部的数据是最少被访问的数据。列表按照最近访问时间进行排序。当内存达到物理内存限制触发 LRU 回收时，对链表尾部的 k-v 进行回收。

但 Redis 的 LRU 并不是这样执行的，Redis 使用了一种近似 LRU 算法。对于所有 Redis 对象，对象头中包含一个 24bit 的信息，作为**对象热度**的标志。在 LRU 淘汰算法中，该标志是一个**时间戳**，记录了最近一次访问该标志位的时间。  
在触发了 LRU 淘汰时，Redis 会随机抽取若干个（默认是 5 个）key，然后删掉最旧的 key。如果这时候内存依旧超出限制，则再次抽选、删除最旧的 Key 值，直到内存低于最大内存限制为止。

Redis Object 的对象头如下所示：

```c
typedef struct redisObject {
    // 对象类型，如 zset, set, hash 等
    unsigned type: 4; 
    // 对象编码如 ziplist, inset, skiplist 等
    unsigned encoding: 4;
    // 对象的热度
    unsigned lru: 24;
    // 引用计数
    int refcount;
    // 对象的 body
    void *ptr;
}
```

其中，lru 值即为表示热度的值。在 LRU 模式下，该字段存储的时间戳是 Redis 服务器的时钟信息 server.lruclock，单位为毫秒。server.lruclock 持续更新，某对象被访问时，对象头中的 LRU 值被更新为当前 server.lruclock 的值，最后当触发 LRU 内存淘汰时，该对象的 LRU 值会与当前 server.lruclock 进行取模等一系列运算，即可得到 LRU 值。

## 3. LFU 策略

LFU 策略与 LRU 的计算方式大致相同，都是根据 Redis 对象头的 LRU 值与 server.lruclock 值进行计算的。但是 LFU 策略下，24bit 的 lru 值被分为 16+8 两部分。

- **ldt (last decrement time，)**: 前 16 位，记录上一次更新时间，计算单位是分钟。
  - ldt 不是对象被访问的时候被更新，而是在 Redis 触发淘汰逻辑时进行更新；
- **logc (logistic counter，对数计数)**: 后 8 位记录频率信息，且以**对数形式**储存，计算单位是分钟。
  - logc 有**衰减算法**，在 ldt 更新时触发。当前 logc 值减去对象空闲时间，除以一个衰减系数；
  - 由于 logc 的统计的是对数信息，所以它的 +1 策略是基于概率的 +1；于是当对数值越大时，+1 操作概率越小，就越难被更新。大致流程如下：
    1. 计算差值：<code>当前对数值 - 基值 (5)</code>；
    2. 计算更新 +1 操作概率：<code>p = 1 / 差值</code>；

# 八. 当前读和快照读

# 九. Redis 内存优化

> 参考地址：[《一文深入了解 Redis 内存模型，Redis 的快是有原因的！》](https://mp.weixin.qq.com/s/7pSLPQQyeqRd7SuWGu8oJg)

了解 redis 的内存模型，对优化 redis 内存占用有很大帮助。下面介绍几种优化场景。

1. 利用 jemalloc 特性进行优化
	- 由于 jemalloc 分配内存时数值是不连续的，因此 key/value 字符串变化一个字节，可能会引起占用内存很大的变动（比如两个 SDS 分别占据 32/33Bytes，实际占用值是 32/64Bytes）；在设计时可以利用这一点。
		- 例如，如果 Key 的长度如果是 8 个字节，则 SDS 为 17 字节，jemalloc 分配 32 字节；此时将 key 长度缩减为 7 个字节，则 SDS 为 16 字节，jemalloc 分配 16 字节；则每个key所占用的空间都可以缩小一半。
	- 使用整型/长整型：如果是整型/长整型，Redis 会使用 int 类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。
2. 共享对象
	- 利用共享对象，可以减少对象的创建（同时减少了 redisObject 的创建），节省内存空间。
	- 目前 Redis 中的共享对象只包括 10000 个整数（0-9999）；可以通过调整 REDIS_SHARED_INTEGERS 参数提高共享对象的个数；例如将 REDIS_SHARED_INTEGERS 调整到 20000，则 0-19999 之间的对象都可以共享。
		- 例：论坛网站在 redis 中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在 0-20000 之间，这时候通过适当增大 REDIS_SHARED_INTEGERS 参数，便可以利用共享对象节省内存空间。
3. 避免过度设计
	- 需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡；而设计复杂度会影响到代码的复杂度、可维护性。如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算；例如如果只有 90000 个键值对，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。
4. 关注内存碎片率
	- 内存碎片率是一个重要的参数，对 Redis 内存的优化有重要意义。定义如下：
	- <code>mem_fragmentation_ratio = used_memory_rs / used_memory</code>，即 Redis 进程占据内存大小，与 Redis 分配器分配内存大小的比值；
	- 内存碎片率越高（ 在 1.03 左右比较正常），说明内存碎片越多，内存浪费越严重；这时便可以考虑重启 redis 服务，在内存中对数据进行重排，减少内存碎片。
	- 如果内存碎片率小于 1，说明 redis 内存不足，部分数据使用了**虚拟内存**（即 swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时 redis 的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加服务器节点数量，或提高单机内存），或减少 redis 中的数据。
5. 回收策略
	- 设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。

# 十. Redis 集群模式

> 参考地址：  
> [《redis三种模式对比》](https://blog.csdn.net/selectgoodboy/article/details/86377861?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

Redis 集群模式有三种：主从模式（Redis 2.8 版本之前）、哨兵模式（Redis 3.0 之前）、集群模式（Redis 3.0 之后）。

## 10.1 主从模式

同 Mysql 主从复制的原因一样，Redis 虽然读取写入的速度都特别快，但是也会产生读压力特别大的情况。为了分担读压力，Redis 支持主从复制，Redis 的主从结构可以采用一主多从，或者级联结构，Redis 主从复制可以根据是否是全量分为全量同步和增量同步。下图为级联结构。

![Redis 主从模式级联](./pic/Redis/Redis主从模式级联.png)

Redis 全量复制一般发生在 Slave 初始化阶段，这是 Slave 需要将 Master 上的所有数据都复制一份。具体步骤如下：

1. Slave 服务器连接 Master 服务器，发送 SYNC 指令；
2. Master 服务器接收到 SYNC 指令后，开始执行 BGSAVE 指令，生成 RDB 文件，并使用缓冲区**记录生成 RDB 文件的这段时间里执行的所有写命令**；
3. Master 服务器 BGSAVE 执行完毕，想所有 Slave 服务器发送快照文件，并在发送期间**继续记录被执行的写命令**；
4. Slave 服务器收到快照文件后，丢弃所有旧数据，载入收到的快照；
5. Master 服务器快照发送完毕后，开始向 Slave 服务器发送缓冲区的写命令；
6. Slave 服务器完成对快照的载入，开始接受发来的写命令请求，并执行来自 Master 缓冲区的写命令。

- 优点：
	- 用比较简便的方式实现了读写分离，解决了备份问题，提高了服务器的性能；
- 缺点：
	- 所有 Master, Slave 节点都是用 IP 和端口配置的，如果有节点故障下线，不能主动通知其他节点，只能手动修改配置的方式修复；
	- 如果 Master 节点故障，无法做到自动选举 Master 节点，需要手动修复；
	- 无法动态扩容；

## 10.2 哨兵模式

哨兵 (Sentinal) 的作用是监控 Redis 服务器的状态，可以实现在 Master 节点下线时，将其他 Slave 节点升级为 Master 节点的功能。多个哨兵可以监控同一个 Redis 节点，哨兵与哨兵之间也可以相互监视。

### 10.2.1 哨兵的工作原理

哨兵进程启动后，会读取配置文件内容，查找到 Master 服务器的 IP 与端口，与 Master 服务器建立两条连接。此外，只要给哨兵提供多个 Master 服务器的信息，就能实现一个哨兵监控多个 Master 服务器。  
与 Master 服务器建立连接后，哨兵会按照一定频率执行三个操作：

1. 定期向 Master 节点发送 INFO 命令；
	- 用于发现 Master 及其 Slave 节点信息，实现节点加入的自动发现；
2. 定期向 Master 和其 Slave 节点的**哨兵频道**发送自己的信息；
	- 向 Master, Slave 共享自己的信息，用来让其他哨兵通过这些信息发现自己，这样就可以接收到其他哨兵给自己发的 PING 信息；此外，其他哨兵可以通过该信息判断 master 版本，如果当前哨兵的版本更高，则进行更新；
3. 定期向 Master, Slave 和其他哨兵发送 PING 信息，监控它们是否已经停止服务；
	- 如果 PING 的节点超时没有回复，则哨兵认为该节点**主观下线**；
	- 如果被哨兵认为主观下线的节点是 Master 节点，则会向其他哨兵进行询问，是否它们认为该 Master 节点主观下线。如果有半数以上的哨兵认为 Master 节点主观下线，则哨兵会认为该 Master 节点客观下线，并开始执行选举。

认为 Master 节点客观下线后，故障恢复的操作需要一个领头的哨兵执行。选举采用 RAFT 算法：

1. 发现 master 下线的哨兵节点（我们称他为 A），向每个哨兵发送命令，要求对方选自己为领头哨兵；
2. 如果目标哨兵节点没有选过其他人，则会同意选举 A 为领头哨兵；
3. 如果有超过一半的哨兵同意选举 A 为领头，则 A 当选；
4. 如果有多个哨兵节点同时参选领头，此时有可能存在一轮投票无竞选者胜出，此时每个参选的节点等待一个随机时间后再次发起参选请求，进行下一轮投票精选，直至选举出领头哨兵；

选出领头哨兵后，领头者开始对进行故障恢复，从出现故障的 master 的从数据库中挑选一个来当选新的 master，选择规则如下：

1. 所有在线的 slave 中选择优先级最高的，优先级可以通过 slave-priority 配置；
2. 如果有多个最高优先级的 slave，则选取复制偏移量最大（即复制越完整）的当选；
3. 如果以上条件都一样，选取 id 最小的 slave；

挑选出需要继任的 slave 后，领头哨兵向该数据库发送命令使其升格为 master，然后再向其他 slave 发送命令接受新的 master，最后更新数据。将已经停止的旧的 master 更新为新的 master 的从数据库，使其恢复服务后以 slave 的身份继续运行。

优点：

1. Master 状态监测
2. 如果 Master 异常，则会进行 Master-slave 转换，将其中一个 Slave 作为 Master，将之前的 Master 作为 Slave；
3. Master-Slave 切换后，master_redis.conf、slave_redis.conf 和sentinel.conf 的内容都会发生改变，即 master_redis.conf 中会多一行 slaveof 的配置，sentinel.conf 的监控目标会随之调换；

缺点：

1. 如果是从节点下线了，sentinel 是不会对其进行故障转移的，连接从节点的客户端也无法获取到新的可用从节点；
2. 无法实现动态扩容；

## 10.3 集群模式

# 十一. Redis

## 1. Redis 管道

## 3. 聊聊 Redis 使用场景

## 4. Redis 持久化机制

> 参考地址：[《Redis持久化机制》](https://www.cnblogs.com/justinli/p/10810297.html)

Redis 有两种持久化机制：**快照 (RDB)** 和 **AOF 日志**。其中快照是一次性全量备份，AOF 是增量备份。

### 4.1 快照 (RDB)

Redis 使用操作系统的多进程 COW (Copy On Write) 机制实现快照持久化。在持久化时，由于要一边要持久化，一边又要满足 Redis 的正常使用，所以 Redis 在持久化的时候，使用了 glibc 的 **fork 函数产生了一个子进程**，在子进程中进行快照持久化操作，主进程满足业务的正常使用。  

RDB的原理是**fork和cow**。fork是指redis通过创建子进程来进行RDB操作，cow指的是**copy on write**，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。  

快照持久化的内存策略是：子进程按照**数据页**进行复制。在持久化过程中，子进程负责持久化过程，它将主进程数据段的数据页复制一份出来，然后对原数据页进行存储；同一时间，主进程对那份复制出来的数据进行操作。通过复制小数据量数据页（通常每个数据页只有 4KB）的方式，保证了主进程修改数据不会影响子进程存储，子进程存储的数据，还是子进程产生一瞬间的数据。

快照触发方式有自动触发与手动触发两种。

- **自动触发**：通过 redis.conf 配置文件进行配置；
- **手动触发**：
	- save: 阻塞式触发，在未完成前，客户端无法进行命令操作；
	- bgsave: 非阻塞式触发，主进程 fork 出子进程进行备份操作；


在恢复文件时，将备份文件 (dump.rdb) 放在 Redis 安装目录，然后启动 Redis，就能把 RDB 中的文件加载到 Redis 服务中。

快照存储的优点缺点：

- **优点**：
	- 数据结构紧凑，保存了 Redis 服务在某个时间点上的数据集，非常适合做备份和灾难恢复；
	- 进行 RDB 快照持久化时，主进程会 fork 出一个子进程进行备份工作，主进程不需要额外的 IO 操作；
	- RDB 恢复大数据集时，速度比 AOF 快；
- **缺点**：
	- 版本兼容问题：Redis 版本更新过程中有多个 RDB 版本，存在老版 RDB 兼容性无法兼容新版的问题；
	- 无法做到实时持久化，因为 bgsave 时的 fork 操作每次都会创建子进程，内存中的数据被克隆了一份，属于重量级操作。

	
### 4.2 AOF

AOF 日志存储的是 **Redis 服务器的顺序指令序列**，它只记录对内存进行修改的指令记录。AOF 使用追加记录的方式，在 Redis 长期运行的过程中，AOF 日志会越来越长，所以一旦宕机重启载入 AOF 日志，将会是一个非常耗时的功能，因此我们需要对 AOF 进行瘦身，即 AOF 重写。  
AOF 重写并不是对原始的 AOF 文件进行重新整理，而是 fork 一个子进程遍历服务器的键值对，转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后，将原来的文件替换为序列化后的文件即可。  
AOF 重写分为两个过程，一个是 fork 子进程重写过程执行的原始数据内容，另一个是在 **fork 过程中主进程修改的指令**。

### 4.3 混合持久化

Redis 4.0 之后加入了新的持久化选项：混合持久化。它将 RDB 和 AOF 内容放在一起，其中 AOF 日志记录的不是全量日志，而是**持久化开始到持久化结束**时间内的 AOF 日志（通常该部分日志很小）。

### 4.4 AOF 的持久化策略

问：**如果突然机器掉电会怎样？**  

**AOF 的持久化策略**：AOF 日志是以文件形式存在的，里面记录的是内存的操作记录，它的实现是将**操作系统内核为文件描述符分配的内存缓存，通过异步的方式刷新到数据磁盘中**。这种操作是 glibc 的 fsync 操作，它是一个很慢的操作，与 Redis 的高性能是相反的。  
AOF 提供了三种持久化策略：

- **no**: 无 fsync，由系统保证数据刷新到磁盘，速度最快，但很不安全（通常不使用）；
- **always**: 每次 fsync，每一个修改内存的 Redis 指令都会执行一次 fsync，速度很慢（通常不使用）；
- **everysec**: 每秒进行一次 fsync，有可能丢失一秒的 fsync 的数据。通常选择 everysec 策略，兼顾安全性和效率。

持久化取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

### 4.5 其他问题

Redis集群的数据同步？AOF 与 RDB 的优缺点？

## 5. Redis 相比 memcached 有哪些优势？

- memcached 所有的值均是简单的字符串，redis 作为其替代者，支持更为丰富的数据类型
- redis 的速度比 memcached 快很多
- redis 可以**持久化**其数据

## 6. Redis 集群方案与实现

问：**Redis集群，集群的高可用怎么保证，集群的原理是什么？**  

- **Redis Sentinal** 着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。   

- **Redis Cluster** 着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。

## 7. Redis IO多路复用技术以及epoll实现原理

> 参考地址：[《Redis IO多路复用技术以及epoll实现原理》](https://blog.csdn.net/wxy941011/article/details/80274233)

redis 是一个单线程却性能非常好的内存数据库， 主要用来作为缓存系统。 redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。
为什么 Redis 中要使用 I/O 多路复用这种技术呢？
首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的。
redis的io模型主要是基于epoll实现的，不过它也提供了 select和kqueue的实现，默认采用epoll。
那么epoll到底是个什么东西呢？ 其实只是众多i/o多路复用技术当中的一种而已，但是相比其他io多路复用技术(select, poll等等)。  

### 7.1 epoll 与 select/poll 的区别

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪，能够通知程序进行相应的操作。  
select 的本质是采用 32 个整数的 32 位，即 <code>32*32= 1024</code> 来标识，fd值为 1-1024。当 fd 的值超过 1024 限制时，就必须修改 FD_SETSIZE 的大小。这个时候就可以标识<code>32*max</code> 值范围的 fd。  
poll 与 select 不同，通过一个 pollfd 数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd 中的 events 字段和 revents 分别用于标识关注的事件和发生的事件，故 pollfd 数组只需要被初始化一次。  
epoll 还是 poll 的一种优化，返回后不需要对所有的 fd 进行遍历，在内核中维持了 fd 的列表。select 和 poll 是将这个内核列表维持在用户态，然后传递到内核中；而与 poll/select 不同，epoll 不再是一个单独的系统调用，而是由 **epoll_create/epoll_ctl/epoll_wait** 三个系统调用组成，后面将会看到这样做的好处。

> 注：epoll 在 2.6 以后的内核才支持。

### 7.2 Epoll 的优点

**epoll 有诸多优点**：

1. epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大  ，具体数目可以 cat /proc/sys/fs/file-max 察看。
2. 效率提升， Epoll 最大的优点就在于它只管你“活跃”的连接 ，而跟连接总数无关，因此 IO 效率不随 FD 数目增加而线性下降，在实际的网络环境中， Epoll 的效率就会远远高于 select 和 poll 。
3. 内存拷贝， Epoll 在这点上使用了“共享内存 ”，这个内存拷贝也省略了。
	- Epoll 使用了 mmap 加速内核与用户空间的消息传递。这点涉及了 epoll 的具体实现。无论是select, poll，还是 epoll，都需要内核把 FD 消息通知给用户空间，如何避免不必要的内存拷贝就很 重要。在这点上，Epoll 是通过内核与用户空间 mmap 同一块内存实现的。

**select/poll的几大缺点**：

1. 每次调用 select/poll，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多的时候会很大；
2. 同时每次调用 select/poll 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大；
3. 针对 select 支持的文件描述符数量太小了，默认是 1024；
4. select 返回的是含有整个句柄的数组，应用程序需要遍历整个数组才能发现哪些句柄发生了事件；
5. select 的触发方式是水平触发，应用程序如果没有完成对一个已经就绪的文件描述符进行 IO 操作，那么之后每次 select 调用还是会将这些文件描述符通知进程。

相比 select模型，poll使用链表保存文件描述符，因此没有了监视文件数量的限制，但其他三个缺点依然存在。

### 7.3 epoll IO 多路复用模型实现机制

由于 epoll 的实现机制与 select/poll 机制完全不同，上面所说的 select 的缺点在 epoll 上不复存在。  
Epoll 没有这个限制，它所支持的 FD 上限是最大可以打开文件的数目，这个数字一般远大于 2048。举个例子，在 1GB 内存的机器上大约是 10万左右，设想一下如下场景：有 100 万个客户端同时与一个服务器进程保持着 TCP 连接。而每一时刻，通常只有几百上千个 TCP 连接是活跃的（事实上大部分场景都是这种情况）。如何实现这样的高并发？  
在 **select/poll** 时代，主要实现方式是**从用户态复制句柄数据结构到内核态**。服务器进程每次都把这 100 万个连接告诉操作系统，让操作系统内核去查询这些套接字上是否有事件发生。轮询完后，再将句柄数据复制到用户态，让服务器应用程序轮询处理已发生的网络事件，这一过程资源消耗较大，因此，select/poll一般只能处理几千的并发连接。  
此外，如果没有 I/O 事件产生，我们的程序就会阻塞在 select 处。但是依然有个问题，我们从 select 那里仅仅知道了，有 I/O 事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。但是使用 select，我们有 O(n) 的无差别轮询复杂度，同时处理的流越多，每一次无差别轮询时间就越长。  
Epoll 的设计和实现与 select 完全不同。Epoll 通过在 Linux 内核中申请一个简易的文件系统（文件系统一般用 B+树实现），把原先的 select/poll 调用分成了3个部分：

1. **epoll_create()**：建立一个 epoll对象（在 Epoll 文件系统中，为这个句柄对象分配资源）；
2. **epoll_ctl()**：向 epoll 对象中添加这100万个连接的套接字；
3. **epoll_wait()**：收集发生的事件的连接；

如此一来，要实现上面所说的场景，只需要在进程启动时建立一个 epoll 对象，然后在需要的时候向这个 epoll 对象中添加或者删除连接。同时，epoll_wait 的效率也非常高，因为调用 epoll_wait 时，并没有一股脑的向操作系统复制这100万个连接的句柄数据，内核也不需要去遍历全部的连接。

### 7.4 Epoll 底层实现

底层实现：
当某一进程调用 epoll_create 方法时，Linux 内核会创建一个 **eventpoll 结构体**，这个结构体中有两个成员与 epoll 的使用方式密切相关。eventpoll 结构体如下所示：

```c
struct eventpoll {
  //....
  // 红黑树的根节点，这棵树中存储着所有添加到 epoll 中的需要监控的事件
  struct rb_root rbr;
  // 双链表中存放着将要通过 epoll_wait 返回给用户的满足条件的事件
  struct list_head rdlist;
  //....
}
```

#### 7.4.1 socket 红黑树

每一个 epoll 对象都有一个独立的 eventpoll 结构体，用于存放通过 **epoll_ctl 方法**向 epoll 对象中添加进来的事件，这些事件都会挂载在用于**存储上述的被监控 socket 的红黑树**上，即上面源码的  **rb_root**。当你调用 epoll_create 时，就会在 epoll 注册的一个文件系统中创建一个 file 节点，这个 file 不是普通文件，它只服务于 epoll。epoll 在被内核初始化时（操作系统启动），同时会开辟出 epoll 自己的内核高速缓存区，用于安置每一个我们想监控的 socket，**这些 socket 会以红黑树的形式保存在内核缓存里**，红黑树的插入时间效率很高，对于高度为 n 的红黑树，查找、插入、删除的效率都是 lgn。如此重复添加的事件就可以通过红黑树高效的识别出来。

- 注：这个内核高速缓存区，就是建立连续的物理内存页，然后在之上建立 slab 层，简单的说，就是物理上分配好你想要的 size 的内存对象，每次使用时都是使用空闲的已分配好的对象。

#### 7.4.2 事件双链表

所有添加到 epoll 中的事件都会与设备（网卡）驱动程序**<font color=red>建立回调关系</font>**，也就是说当相应的事件发生时，会调用这个回调方法。这个回调方法在内核中叫 ep_poll_callback，它会将发生的事件添加到 rdlist 双链表中。  
这个事件双链表是怎么维护的呢？当我们执行 epoll_ctl 时，除了把 socket 放到 epoll 文件系统里 file 对象对应的红黑树上之外，还会**给内核中断处理程序注册一个回调函数**。告诉内核，如果这个句柄的中断到了，就把它放到准备就绪 list 链表里。所以，当一个 socket 上有数据到了，内核在把网卡上的数据 copy 到内核中，然后就把 socket 插入到准备就绪链表里了。由此可见，**epoll 的基础就是回调**。  
epoll 的每一个事件都会包含一个 epitem 结构体，如下所示：

```c
struct epitem {
  // 红黑树节点
  struct rb_node rbn; 
  // 双向链表节点
  struct list_head rdllink;
  // 事件句柄信息
  struct epoll_filefd ffd;
  // 指向所属的 eventpoll 对象
  struct eventpoll *ep;
  // 期待发生的事件类型
  struct epoll_event event;
}
```

当调用 epoll_wait **检查是否有事件发生**时，只需要**检查 eventpoll 对象中的 rdlist 双链表中是否有 epitem 元素即可**。如果 rdlist 不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。

------------

综上所述，epoll 的执行过程：

1. 调用 epoll_create 时，内核帮我们在 epoll 文件系统里**建立 file 结点**，**内核缓存中建立 socket 红黑树**，除此之外，还会再**建立一个用于存储准备就绪事件的 list 链表**。
2. 执行 epoll_ctl 时，如果增加就绪事件的 socket 句柄，则需要：
	- 检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上；
	- 然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。
3. epoll_wait 调用时，仅仅观察这个 list 链表里有没有数据即可，有数据就返回，没有数据就 sleep，等到 timeout 时间到后，即使链表没数据也返回。
  - epoll_wait 的执行过程相当于以往调用 select/poll，但 epoll 的效率高得多。

> 注：  
> epoll 独有的两种模式 LT 和 ET。无论是 LT 和 ET 模式，都适用于以上所说的流程。区别是，LT 模式下只要一个句柄上的事件一次没有处理完，会在以后调用 epoll_wait 时次次返回这个句柄。而ET模式仅在第一次返回。  
> 关于 LT 和 ET 有一端描述，LT 和 ET 都是电子里面的术语，ET 是边缘触发，LT 是水平触发，一个表示只有在变化的边际触发，一个表示在某个阶段都会触发。  
> 对于 epoll 而言，当一个 socket 句柄上有事件时，内核会把该句柄插入上面所说的准备就绪链表，这时我们调用 epoll_wait，会把准备就绪的 socket 拷贝到用户态内存，然后清空准备就绪链表。最后，epoll_wait 检查这些 socket，如果不是 ET 模式（就是LT模式的句柄了），并且这些 socket 上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了。所以，非 ET 的句柄，只要它上面还有事件，epoll_wait 每次都会返回这个句柄。

## 8. 缓存奔溃

## 9. 缓存降级

## 10. 使用缓存的合理性问题

## 12. Redis 的 BloomFilter

> [《Redis-避免缓存穿透的利器之BloomFilter》](https://juejin.im/post/5db69365518825645656c0de)

## 14. Redis 大量 Key 值

**假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？**  

使用**keys**指令可以扫出指定模式的key列表。  

**对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ **  

这个时候你要回答Redis关键的一个特性：Redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用**scan**指令，**scan**指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

**不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。**

## 16. Redis 的同步机制





## 其他问题

### (1) 什么是Redis？

Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个数据库统统加载在内存当中进行操作，定期通过**异步操作**把数据 **flush 到硬盘上**进行保存。  
因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value DB。 Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存**多种数据结构**。  
此外单个 value 的最大限制是 1GB，不像 memcached 只能保存 1MB 的数据，因此 Redis 可以用来实现很多有用的功能（比方说用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性能消息队列服务，用他的 Set 可以做高性能的 tag 系统等等）。另外 Redis 也可以对存入的 Key-Value 设置 expire 时间，因此也可以被当作一个功能加强版的 memcached 来用。  
Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。

### (3) Redis支持哪几种数据类型？

String, List, Set, Sorted Set, hashes



### (8) Redis集群方案应该怎么做？都有哪些方案？

1. codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。
3. redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。

### (9) Redis集群方案什么情况下会导致整个集群不可用？
有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。

### (11) Redis有哪些适合的场景？

- 会话缓存（Session Cache）
	- 最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？
	- 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。
- 队列
	- Redis在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。
	- 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。
- 排行榜/计数器
	- Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：
	- 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：
	- ZRANGE user_scores 0 10 WITHSCORES
	- Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。
- 发布/订阅
	- 最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。

### (14) Jedis与Redisson对比有什么优缺点？
Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。

### (16) 说说Redis哈希槽的概念？

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

### (34) Redis持久化数据和缓存怎么做扩容？

如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。  
如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。

### (35) 分布式Redis是前期做还是后期规模上来了再做好？为什么？

既然Redis是如此的轻量（单实例只使用1M内存）,为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。  
一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。  
这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。

### (39) Redis的内存占用情况怎么样？
给你举个例子： 100万个键值对（键是0到999999值是字符串“hello world”）在我的32位的Mac笔记本上 用了100MB。同样的数据放到一个key里只需要16MB， 这是因为键值有一个很大的开销。 在Memcached上执行也是类似的结果，但是相对Redis的开销要小一点点，因为Redis会记录类型信息引用计数等等。  
当然，大键值对时两者的比例要好很多。  
64位的系统比32位的需要更多的内存开销，尤其是键值对都较小时，这是因为64位的系统里指针占用了8个字节。 但是，当然，64位系统支持更大的内存，所以为了运行大型的Redis服务器或多或少的需要使用64位的系统。

### (40) 都有哪些办法可以降低Redis的内存使用情况呢？

如果你使用的是32位的Redis实例，可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。

### (42) Redis是单线程的，如何提高多核CPU的利用率？
可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。

### (44) Redis常见性能问题和解决方案？

1. Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
2. 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
3. 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
4. 尽量避免在压力很大的主库上增加从库
5. 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...

这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。

### (45) Redis提供了哪几种持久化方式？

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.
- AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.

如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。  
你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。  
最重要的事情是了解RDB和AOF持久化方式的不同,让我们以RDB持久化方式开始。

### (46) 如何选择合适的持久化方式？
一般来说， 如果想达到足以媲美PostgreSQL的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。  
有很多用户都只使用AOF持久化，但并不推荐这种方式：因为定时生成RDB快照（snapshot）非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外， 使用RDB还可以避免之前提到的AOF程序的bug。


