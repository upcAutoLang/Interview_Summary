# 分布式相关知识点总结

# 一. Zookeeper 相关知识

> [《Zookeeper面试题》](https://www.cnblogs.com/lanqiu5ge/p/9405601.html)  
> [《随笔分类 - Zookeeper学习》](http://www.cnblogs.com/sunddenly/category/620563.html)

## 1. ZooKeeper是什么？

ZooKeeper 是一个分布式协调管理的服务，是集群的管理者。

ZooKeeper 的特性：

- 顺序一致性：即有序性，每次更新都会有一个时间戳信息，被称为 zxid，每次读请求都会包含 zxid 信息；
- 原子性：一个更新操作要么全部服务器节点都完成，要么全都失败；
- 单一视图：
- 可靠性：ZooKeeper 的 Leader/Follower 机制，保证了 ZooKeeper 的稳定性；
- 最终一致性：

## 2. ZooKeeper 提供了什么？

ZooKeeper 提供了**文件系统**和**通知机制**。文件系统即仿 Unix 文件系统结构的 ZNode 数据结构，通知机制即**<font color=red>？？？</font>**

## 3. Zookeeper 文件系统

ZK 文件系统的节点命名为 ZNode，与文件系统一样，树状多层级。与文件系统不同的是，文件系统只有叶子节点才有数据内容，而 ZNode 所有节点都可以有关联数据。只是 ZK 为了保证系统的实时性和可靠性，<font color=red>**每个节点的数据量很小，要求不能超过 1M**</font>。

## 4. ZAB协议？

ZooKeeper 的核心机制是原子传播机制。这个机制保证了各个服务器之间的同步。实现原子传播机制的协议称为 ZAB 协议。  
ZAB 协议有两种模式，<font color=red>**恢复模式**</font>和<font color=red>**广播模式**</font>。

- **恢复模式**：
	- 发生条件如下：
		- (1) ZooKeeper 集群刚刚重启；
		- (2) 有 Leader 节点故障；
		- (3) 超过半数的 Follower 无法与 Leader 正常通信（Follower 节点故障，或者网络问题），需要重新选举 Leader；
	- 如果出现上述情况，集群则会开始选举新的节点作为集群 Leader。选举完毕后，Followers 会与 Leader 进行更新同步。当同步完成的 Followers 数量超过集群节点总数的一半后，恢复完毕，转入广播模式。
- **广播模式**：恢复模式之外的模式，接受客户端请求，并进行事务请求处理。步骤如下：
	1. 服务集群中任意一个节点 node 接受客户端的更新请求；
	2. node 将消息传递给 Leader；
	3. Leader 再向各个 Follower 进行提议 (Propose)；
	4. Follower 收到 Propose 后，向 Leader 返回一个应答 ack；
	5. Leader 收到半数以上 Follower 的 ack 后，将结果通知 (commit) 给各个 Follower，进行更新。

## 5. 四种类型的数据节点 Znode

四种节点类型：

- **临时节点 (EPHEMERAL)**：客户端请求的临时节点。建立后客户端与 ZK 集群的会话失效（客户端与 ZK 连接断开，并不一定是会话失效），则会将该客户端创建的所有临时节点删除（当然包括该节点及下面的子节点）；
- **永久节点 (PERSISTENT)**：一旦建立，除非手动删除，否则就会永久存在的节点。
- **临时顺序节点 (EPHEMERAL SEQUENTIAL)**：与临时节点的生命周期相同，只是添加了一个顺序编号（自增整形数字），由父节点管理；
- **永久顺序节点 (PERSISTENT SEQUENTIAL)**：与永久节点的生命周期相同，添加了一个由父节点管理的顺序编号（自增整形数字）。

## 6. Zookeeper Watcher 机制 -- 数据变更通知

ZooKeeper 的 Watcher 有三个步骤：

1. 客户端注册 (Register) Watcher；
2. 服务端处理 Watcher；
3. 客户端回调 Watcher；

ZooKeeper 的 Watcher 有特性如下：

1. **一次性**：不管是客户端注册还是服务端处理，Watcher 回调只有一次。这样避免了某些 ZK 节点频繁的变更而带来的巨大网络开销。
2. 客户端、服务端事件：
	- 客户端：**getData**, **getChildren**, **exists**，几个方法都在 ZooKeeper.java 中；
	- 服务端：**setData**, **create**, **delete**，几个方法都在 ZooKeeper.java 中。


## 7. 客户端注册 Watcher 实现

步骤如下：

1. 客户端调用 getData / getChildren / exists 方法；
2. 

## 8. 服务端处理Watcher实现


## 9. 客户端回调Watcher

## 10. ACL权限控制机制

UGO（User/Group/Others）
ACL（Access Control List）访问控制列表

## 11. Chroot特性
## 12. 会话管理
## 13. 服务器角色
Leader
Follower
Observer
## 14. Zookeeper 下 Server工作状态
## 15. Leader 选举
## 16. 数据同步
直接差异化同步（DIFF同步）
先回滚再差异化同步（TRUNC+DIFF同步）
仅回滚同步（TRUNC同步）
全量同步（SNAP同步）
## 17. zookeeper是如何保证事务的顺序一致性的？
## 18. 分布式集群中为什么会有Master？
## 19. zk节点宕机如何处理？
## 20. zookeeper负载均衡和nginx负载均衡区别
## 21. Zookeeper有哪几种几种部署模式？
## 22. 集群最少要几台机器，集群规则是怎样的?
## 23. 集群支持动态添加机器吗？
## 24. Zookeeper对节点的watch监听通知是永久的吗？为什么不是永久的?
## 25. Zookeeper的java客户端都有哪些？
## 26. chubby是什么，和zookeeper比你怎么看？
## 27. 说几个zookeeper常用的命令。
## 28. ZAB和Paxos算法的联系与区别？
## 29. Zookeeper的典型应用场景
1. 数据发布/订阅
2. 负载均衡

# 二. Kafka 相关知识点

> [《Kafka面试题参考》](https://blog.csdn.net/linke1183982890/article/details/83303003)

## 1. Kafka的设计是什么样的呢？

Kafka将消息以topic为单位进行归纳
将向Kafka topic发布消息的程序成为producers.
将预订topics并消费消息的程序成为consumer.
Kafka以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个broker.
producers通过网络将消息发送到Kafka集群，集群向消费者提供消息

## 2. 数据传输的事物定义有哪三种？

数据传输的事务定义通常有以下三种级别：
（1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输
（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.
（3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的

## 3. Kafka判断一个节点是否还活着有那两个条件？

（1）节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接
（2）如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久

## 4. producer是否直接将数据发送到broker的leader(主节点)？

producer直接将数据发送到broker的leader(主节点)，不需要在多个节点进行分发，为了帮助producer做到这点，所有的Kafka节点都可以及时的告知:哪些节点是活动的，目标topic目标分区的leader在哪。这样producer就可以直接将消息发送到目的地了

## 5. Kafka consumer是否可以消费指定分区消息？

Kafa consumer消费消息时，向broker发出"fetch"请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的

## 6. Kafka消息是采用Pull模式，还是Push模式？

Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息

一些消息系统比如Scribe和Apache Flume采用了push模式，将消息推送到下游的consumer。这样做有好处也有坏处：由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。消息系统都致力于让consumer以最大的速率最快速的消费消息，但不幸的是，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。最终Kafka还是选取了传统的pull模式

Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。Push模式必须在不知道下游consumer消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。如果为了避免consumer崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。Pull模式下，consumer就可以根据自己的消费能力去决定这些策略

Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发

## 7. Kafka存储在硬盘上的消息格式是什么？

消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和CRC32校验码。

- 消息长度: 4 bytes (value: 1+4+n)
- 版本号: 1 byte
- CRC校验码: 4 bytes
- 具体的消息: n bytes

## 8. Kafka高效文件存储设计特点：

(1).Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。
(2).通过索引信息可以快速定位message和确定response的最大大小。
(3).通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。
(4).通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。

## 9. Kafka 与传统消息系统之间有三个关键区别

(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留
(2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性
(3).Kafka 支持实时的流式处理

## 10. Kafka创建Topic时如何将分区放置到不同的Broker中

- 副本因子不能大于 Broker 的个数；
- 第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；
- 其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；
- 剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的

## 11. Kafka新建的分区会在哪个目录下创建

在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录，这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘上用于提高读写性能。  
当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。  
如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个目录下创建文件夹用于存放数据。  
但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢？答案是：Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为 Topic名+分区ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录！也就是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。

## 12. partition的数据如何保存到硬盘
topic中的多个partition以文件夹的形式保存到broker，每个分区序号从0递增，
且消息有序
Partition文件下有多个segment（xxx.index，xxx.log）
segment 文件里的 大小和配置文件大小一致可以根据要求修改 默认为1g
如果大小大于1g时，会滚动一个新的segment并且以上一个segment最后一条消息的偏移量命名

## 13. kafka的ack机制
request.required.acks有三个值 0 1 -1  
0:生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱当server挂掉的时候就会丢数据  
1：服务端会等待ack值 leader副本确认接收到消息后发送ack但是如果leader挂掉后他不确保是否复制完成新leader也会导致数据丢失  
-1：同样在1的基础上 服务端会等所有的follower的副本受到数据后才会受到leader发出的ack，这样数据不会丢失

## 14. Kafka的消费者如何消费数据
消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置  
等到下次消费时，他会接着上次位置继续消费

## 15. 消费者负载均衡策略
一个消费者组中的一个分片对应一个消费者成员，他能保证每个消费者成员都能访问，如果组中成员太多会有空闲的成员

## 16. 数据有序
一个消费者组里它的内部是有序的
消费者组与消费者组之间是无序的

## 17. kafka生产数据时数据的分组策略
生产者决定数据产生到集群的哪个partition中
每一条消息都是以（key，value）格式
Key是由生产者发送数据传入
所以生产者（key）决定了数据产生到集群的哪个partition

# 三. Memcache 相关问题

> [《memcached面试题集锦》](https://blog.csdn.net/ywh147/article/details/47837955)

这里收集了经常被问到的关于memcached的问题 

* memcached是怎么工作的？ 
* memcached最大的优势是什么？ 
* memcached和MySQL的query cache相比，有什么优缺点？ 
* memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？ 
* memcached的cache机制是怎样的？ 
* memcached如何实现冗余机制？ 
* memcached如何处理容错的？ 
* 如何将memcached中item批量导入导出？ 
* 但是我确实需要把memcached中的item都dump出来，确实需要把数据load到memcached中，怎么办？ 
* memcached是如何做身份验证的？ 
* 如何使用memcached的多线程是什么？如何使用它们？ 
* memcached能接受的key的最大长度是多少？（250bytes） 
* memcached对item的过期时间有什么限制？（为什么有30天的限制？） 
* memcached最大能存储多大的单个item？（1M byte） 
* 为什么单个item的大小被限制在1M byte之内？ 
* 为了让memcached更有效地使用服务器的内存，可以在各个服务器上配置大小不等的缓存空间吗？ 
* 什么是binary协议？它值得关注吗？ 
* memcached是如何分配内存的？为什么不用malloc/free！？究竟为什么使用slab呢？ 
* memcached能保证数据存储的原子性吗？ 



集群架构方面的问题 

## 1. memcached是怎么工作的？ 

Memcached的神奇来自两阶段哈希（two-stage hash）。Memcached就像一个巨大的、存储了很多<key,value>对的哈希表。通过key，可以存储或查询任意的数据。 

客户端可以把数据存储在多台memcached上。当查询数据时，客户端首先参考节点列表计算出key的哈希值（阶段一哈希），进而选中一个节点；客户端将请求发送给选中的节点，然后memcached节点通过一个内部的哈希算法（阶段二哈希），查找真正的数据（item）。 

举个列子，假设有3个客户端1, 2, 3，3台memcached A, B, C： 
Client 1想把数据”barbaz”以key “foo”存储。Client 1首先参考节点列表（A, B, C），计算key “foo”的哈希值，假设memcached B被选中。接着，Client 1直接connect到memcached B，通过key “foo”把数据”barbaz”存储进去。　　Client 2使用与Client 1相同的客户端库（意味着阶段一的哈希算法相同），也拥有同样的memcached列表（A, B, C）。 
于是，经过相同的哈希计算（阶段一），Client 2计算出key “foo”在memcached B上，然后它直接请求memcached B，得到数据”barbaz”。 

各种客户端在memcached中数据的存储形式是不同的（perl Storable, php serialize, java hibernate, JSON等）。一些客户端实现的哈希算法也不一样。但是，memcached服务器端的行为总是一致的。 

最后，从实现的角度看，memcached是一个非阻塞的、基于事件的服务器程序。这种架构可以很好地解决C10K problem ，并具有极佳的可扩展性。 

可以参考A Story of Caching ，这篇文章简单解释了客户端与memcached是如何交互的。 

## 2. memcached最大的优势是什么？ 

请仔细阅读上面的问题（即memcached是如何工作的）。Memcached最大的好处就是它带来了极佳的水平可扩展性，特别是在一个巨大的系统中。由于客户端自己做了一次哈希，那么我们很容易增加大量memcached到集群中。memcached之间没有相互通信，因此不会增加 memcached的负载；没有多播协议，不会网络通信量爆炸（implode）。memcached的集群很好用。内存不够了？增加几台 memcached吧；CPU不够用了？再增加几台吧；有多余的内存？在增加几台吧，不要浪费了。 

基于memcached的基本原则，可以相当轻松地构建出不同类型的缓存架构。除了这篇FAQ，在其他地方很容易找到详细资料的。 

看看下面的几个问题吧，它们在memcached、服务器的local cache和MySQL的query cache之间做了比较。这几个问题会让您有更全面的认识。 

## 3. memcached和MySQL的query cache相比，有什么优缺点？ 

把memcached引入应用中，还是需要不少工作量的。MySQL有个使用方便的query cache，可以自动地缓存SQL查询的结果，被缓存的SQL查询可以被反复地快速执行。Memcached与之相比，怎么样呢？MySQL的query cache是集中式的，连接到该query cache的MySQL服务器都会受益。 

* 当您修改表时，MySQL的query cache会立刻被刷新（flush）。存储一个memcached item只需要很少的时间，但是当写操作很频繁时，MySQL的query cache会经常让所有缓存数据都失效。 

* 在多核CPU上，MySQL的query cache会遇到扩展问题（scalability issues）。在多核CPU上，query cache会增加一个全局锁（global lock）, 由于需要刷新更多的缓存数据，速度会变得更慢。 

* 在 MySQL的query cache中，我们是不能存储任意的数据的（只能是SQL查询结果）。而利用memcached，我们可以搭建出各种高效的缓存。比如，可以执行多个独立的查询，构建出一个用户对象（user object），然后将用户对象缓存到memcached中。而query cache是SQL语句级别的，不可能做到这一点。在小的网站中，query cache会有所帮助，但随着网站规模的增加，query cache的弊将大于利。 

* query cache能够利用的内存容量受到MySQL服务器空闲内存空间的限制。给数据库服务器增加更多的内存来缓存数据，固然是很好的。但是，有了memcached，只要您有空闲的内存，都可以用来增加memcached集群的规模，然后您就可以缓存更多的数据。 

## 4. memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？ 

首先，local cache有许多与上面(query cache)相同的问题。local cache能够利用的内存容量受到（单台）服务器空闲内存空间的限制。不过，local cache有一点比memcached和query cache都要好，那就是它不但可以存储任意的数据，而且没有网络存取的延迟。 

* local cache的数据查询更快。考虑把highly common的数据放在local cache中吧。如果每个页面都需要加载一些数量较少的数据，考虑把它们放在local cached吧。 

* local cache缺少集体失效（group invalidation）的特性。在memcached集群中，删除或更新一个key会让所有的观察者觉察到。但是在local cache中, 我们只能通知所有的服务器刷新cache（很慢，不具扩展性），或者仅仅依赖缓存超时失效机制。 

* local cache面临着严重的内存限制，这一点上面已经提到。 

## 5. memcached的cache机制是怎样的？ 

Memcached主要的cache机制是LRU（最近最少用）算法+超时失效。当您存数据到memcached中，可以指定该数据在缓存中可以呆多久Which is forever, or some time in the future。如果memcached的内存不够用了，过期的slabs会优先被替换，接着就轮到最老的未被使用的slabs。 

## 6. memcached如何实现冗余机制？ 
不实现！我们对这个问题感到很惊讶。Memcached应该是应用的缓存层。它的设计本身就不带有任何冗余机制。如果一个memcached节点失去了所有数据，您应该可以从数据源（比如数据库）再次获取到数据。您应该特别注意，您的应用应该可以容忍节点的失效。不要写一些糟糕的查询代码，寄希望于 memcached来保证一切！如果您担心节点失效会大大加重数据库的负担，那么您可以采取一些办法。比如您可以增加更多的节点（来减少丢失一个节点的影响），热备节点（在其他节点down了的时候接管IP），等等。 

## 7. memcached如何处理容错的？ 
不处理！:) 在memcached节点失效的情况下，集群没有必要做任何容错处理。如果发生了节点失效，应对的措施完全取决于用户。节点失效时，下面列出几种方案供您选择： 

* 忽略它！ 在失效节点被恢复或替换之前，还有很多其他节点可以应对节点失效带来的影响。 

* 把失效的节点从节点列表中移除。做这个操作千万要小心！在默认情况下（余数式哈希算法），客户端添加或移除节点，会导致所有的缓存数据不可用！因为哈希参照的节点列表变化了，大部分key会因为哈希值的改变而被映射到（与原来）不同的节点上。 

* 启动热备节点，接管失效节点所占用的IP。这样可以防止哈希紊乱（hashing chaos）。 

* 如果希望添加和移除节点，而不影响原先的哈希结果，可以使用一致性哈希算法（consistent hashing）。您可以百度一下一致性哈希算法。支持一致性哈希的客户端已经很成熟，而且被广泛使用。去尝试一下吧！ 

* 两次哈希（reshing）。当客户端存取数据时，如果发现一个节点down了，就再做一次哈希（哈希算法与前一次不同），重新选择另一个节点（需要注意的时，客户端并没有把down的节点从节点列表中移除，下次还是有可能先哈希到它）。如果某个节点时好时坏，两次哈希的方法就有风险了，好的节点和坏的节点上都可能存在脏数据（stale data）。 

## 8. 如何将memcached中item批量导入导出？ 

您不应该这样做！Memcached是一个非阻塞的服务器。任何可能导致memcached暂停或瞬时拒绝服务的操作都应该值得深思熟虑。向 memcached中批量导入数据往往不是您真正想要的！想象看，如果缓存数据在导出导入之间发生了变化，您就需要处理脏数据了；如果缓存数据在导出导入之间过期了，您又怎么处理这些数据呢？ 

因此，批量导出导入数据并不像您想象中的那么有用。不过在一个场景倒是很有用。如果您有大量的从不变化的数据，并且希望缓存很快热（warm）起来，批量导入缓存数据是很有帮助的。虽然这个场景并不典型，但却经常发生，因此我们会考虑在将来实现批量导出导入的功能。 

Steven Grimm，一如既往地,，在邮件列表中给出了另一个很好的例子：http://lists.danga.com/pipermail/memcached/2007-July/004802.html 。 

但是我确实需要把memcached中的item批量导出导入，怎么办？？ 

好吧好吧。如果您需要批量导出导入，最可能的原因一般是重新生成缓存数据需要消耗很长的时间，或者数据库坏了让您饱受痛苦。 

如果一个memcached节点down了让您很痛苦，那么您还会陷入其他很多麻烦。您的系统太脆弱了。您需要做一些优化工作。比如处理”惊群”问题（比如 memcached节点都失效了，反复的查询让您的数据库不堪重负…这个问题在FAQ的其他提到过），或者优化不好的查询。记住，Memcached 并不是您逃避优化查询的借口。 

如果您的麻烦仅仅是重新生成缓存数据需要消耗很长时间（15秒到超过5分钟），您可以考虑重新使用数据库。这里给出一些提示： 

* 使用MogileFS（或者CouchDB等类似的软件）在存储item。把item计算出来并dump到磁盘上。MogileFS可以很方便地覆写 item，并提供快速地访问。您甚至可以把MogileFS中的item缓存在memcached中，这样可以加快读取速度。 MogileFS+Memcached的组合可以加快缓存不命中时的响应速度，提高网站的可用性。 
* 重新使用MySQL。MySQL的InnoDB主键查询的速度非常快。如果大部分缓存数据都可以放到VARCHAR字段中，那么主键查询的性能将更好。从 memcached中按key查询几乎等价于MySQL的主键查询：将key 哈希到64-bit的整数，然后将数据存储到MySQL中。您可以把原始（不做哈希）的key存储都普通的字段中，然后建立二级索引来加快查询…key被动地失效，批量删除失效的key，等等。 

上面的方法都可以引入memcached，在重启memcached的时候仍然提供很好的性能。由于您不需要当心”hot”的item被 memcached LRU算法突然淘汰，用户再也不用花几分钟来等待重新生成缓存数据（当缓存数据突然从内存中消失时），因此上面的方法可以全面提高性能。 

关于这些方法的细节，详见博客：http://dormando.livejournal.com/495593.html 。 

## 9. memcached是如何做身份验证的？ 
没有身份认证机制！memcached是运行在应用下层的软件（身份验证应该是应用上层的职责）。memcached的客户端和服务器端之所以是轻量级的，部分原因就是完全没有实现身份验证机制。这样，memcached可以很快地创建新连接，服务器端也无需任何配置。 

如果您希望限制访问，您可以使用防火墙，或者让memcached监听unix domain socket。 

## 10. memcached的多线程是什么？如何使用它们？ 
线程就是定律（threads rule）！在Steven Grimm和Facebook的努力下，memcached 1.2及更高版本拥有了多线程模式。多线程模式允许memcached能够充分利用多个CPU，并在CPU之间共享所有的缓存数据。memcached使用一种简单的锁机制来保证数据更新操作的互斥。相比在同一个物理机器上运行多个memcached实例，这种方式能够更有效地处理multi gets。 

如果您的系统负载并不重，也许您不需要启用多线程工作模式。如果您在运行一个拥有大规模硬件的、庞大的网站，您将会看到多线程的好处。 

更多信息请参见：http://code.sixapart.com/svn/memcached/trunk/server/doc/threads.txt 。 

简单地总结一下：命令解析（memcached在这里花了大部分时间）可以运行在多线程模式下。memcached内部对数据的操作是基于很多全局锁的（因此这部分工作不是多线程的）。未来对多线程模式的改进，将移除大量的全局锁，提高memcached在负载极高的场景下的性能。 

## 11. memcached能接受的key的最大长度是多少？ 
key的最大长度是250个字符。需要注意的是，250是memcached服务器端内部的限制，如果您使用的客户端支持”key的前缀”或类似特性，那么key（前缀+原始key）的最大长度是可以超过250个字符的。我们推荐使用使用较短的key，因为可以节省内存和带宽。 

## 12. memcached对item的过期时间有什么限制？ 
过期时间最大可以达到30天。memcached把传入的过期时间（时间段）解释成时间点后，一旦到了这个时间点，memcached就把item置为失效状态。这是一个简单但obscure的机制。 

## 13. memcached最大能存储多大的单个item？ 
1MB。如果你的数据大于1MB，可以考虑在客户端压缩或拆分到多个key中。 

## 14. 为什么单个item的大小被限制在1M byte之内？ 
啊…这是一个大家经常问的问题！ 

简单的回答：因为内存分配器的算法就是这样的。 

详细的回答：Memcached的内存存储引擎（引擎将来可插拔…），使用slabs来管理内存。内存被分成大小不等的slabs chunks（先分成大小相等的slabs，然后每个slab被分成大小相等chunks，不同slab的chunk大小是不相等的）。chunk的大小依次从一个最小数开始，按某个因子增长，直到达到最大的可能值。 

如果最小值为400B，最大值是1MB，因子是1.20，各个slab的chunk的大小依次是：slab1 – 400B slab2 – 480B slab3 – 576B … 

slab中chunk越大，它和前面的slab之间的间隙就越大。因此，最大值越大，内存利用率越低。Memcached必须为每个slab预先分配内存，因此如果设置了较小的因子和较大的最大值，会需要更多的内存。 

还有其他原因使得您不要这样向memcached中存取很大的数据…不要尝试把巨大的网页放到mencached中。把这样大的数据结构load和unpack到内存中需要花费很长的时间，从而导致您的网站性能反而不好。 

如果您确实需要存储大于1MB的数据，你可以修改slabs.c:POWER_BLOCK的值，然后重新编译memcached；或者使用低效的malloc/free。其他的建议包括数据库、MogileFS等。 

## 15. 我可以在不同的memcached节点上使用大小不等的缓存空间吗？这么做之后，memcached能够更有效地使用内存吗？ 
Memcache客户端仅根据哈希算法来决定将某个key存储在哪个节点上，而不考虑节点的内存大小。因此，您可以在不同的节点上使用大小不等的缓存。但是一般都是这样做的：拥有较多内存的节点上可以运行多个memcached实例，每个实例使用的内存跟其他节点上的实例相同。 

## 16. 什么是二进制协议，我该关注吗？ 

关于二进制最好的信息当然是二进制协议规范：http://code.google.com/p/memcached/wiki/MemcacheBinaryProtocol 。 

二进制协议尝试为端提供一个更有效的、可靠的协议，减少客户端/服务器端因处理协议而产生的CPU时间。 
根据Facebook的测试，解析ASCII协议是memcached中消耗CPU时间最多的环节。所以，我们为什么不改进ASCII协议呢？ 

在这个邮件列表的thread中可以找到一些旧的信息：http://lists.danga.com/pipermail/memcached/2007-July/004636.html 。 

memcached的内存分配器是如何工作的？为什么不适用malloc/free！？为何要使用slabs？ 
实际上，这是一个编译时选项。默认会使用内部的slab分配器。您确实确实应该使用内建的slab分配器。最早的时候，memcached只使用 malloc/free来管理内存。然而，这种方式不能与OS的内存管理以前很好地工作。反复地malloc/free造成了内存碎片，OS最终花费大量的时间去查找连续的内存块来满足malloc的请求，而不是运行memcached进程。如果您不同意，当然可以使用malloc！只是不要在邮件列表中抱怨啊:) 

slab分配器就是为了解决这个问题而生的。内存被分配并划分成chunks，一直被重复使用。因为内存被划分成大小不等的slabs，如果item 的大小与被选择存放它的slab不是很合适的话，就会浪费一些内存。Steven Grimm正在这方面已经做出了有效的改进。

邮件列表中有一些关于slab的改进（power of n 还是 power of 2）和权衡方案：http://lists.danga.com/pipermail/memcached/2006-May/002163.htmlhttp://lists.danga.com/pipermail/memcached/2007-March/003753.html 。 

如果您想使用malloc/free，看看它们工作地怎么样，您可以在构建过程中定义USE_SYSTEM_MALLOC。这个特性没有经过很好的测试，所以太不可能得到开发者的支持。 

更多信息：http://code.sixapart.com/svn/memcached/trunk/server/doc/memory_management.txt 。 

## 17. memcached是原子的吗？ 
当然！好吧，让我们来明确一下： 
所有的被发送到memcached的单个命令是完全原子的。如果您针对同一份数据同时发送了一个set命令和一个get命令，它们不会影响对方。它们将被串行化、先后执行。即使在多线程模式，所有的命令都是原子的，除非程序有bug:) 
命令序列不是原子的。如果您通过get命令获取了一个item，修改了它，然后想把它set回memcached，我们不保证这个item没有被其他进程（process，未必是操作系统中的进程）操作过。在并发的情况下，您也可能覆写了一个被其他进程set的item。 

memcached 1.2.5以及更高版本，提供了gets和cas命令，它们可以解决上面的问题。如果您使用gets命令查询某个key的item，memcached会给您返回该item当前值的唯一标识。如果您覆写了这个item并想把它写回到memcached中，您可以通过cas命令把那个唯一标识一起发送给 memcached。如果该item存放在memcached中的唯一标识与您提供的一致，您的写操作将会成功。如果另一个进程在这期间也修改了这个 item，那么该item存放在memcached中的唯一标识将会改变，您的写操作就会失败。 

通常，基于memcached中item的值来修改item，是一件棘手的事情。除非您很清楚自己在做什么，否则请不要做这样的事情。

# 四. Redis

## 1. Redis 有哪些类型

string, set, hash, list, zset

## 2. Redis 内部结构

### 2(1) sds

### 2(2) hash

### 2(3) 压缩列表 ziplist

### 2(4) 快速列表 quicklist

### 2(5) 跳跃列表 zskiplist

## 3. 聊聊 Redis 使用场景

## 4. Redis 持久化机制

> 参考地址：[《Redis持久化机制》](https://www.cnblogs.com/justinli/p/10810297.html)

Redis 有两种持久化机制：**快照 (RDB)** 和 **AOF 日志**。其中快照是一次性全量备份，AOF 是增量备份。

### 4.1 快照 (RDB)

Redis 使用操作系统的多进程 COW (Copy On Write) 机制实现快照持久化。在持久化时，由于要一边要持久化，一边又要满足 Redis 的正常使用，所以 Redis 在持久化的时候，使用了 glibc 的 **fork 函数产生了一个子进程**，在子进程中进行快照持久化操作，主进程满足业务的正常使用。  
快照持久化的内存策略是：子进程按照**数据页**进行复制。在持久化过程中，子进程负责持久化过程，它将主进程数据段的数据页复制一份出来，然后对原数据页进行存储；同一时间，主进程对那份复制出来的数据进行操作。通过复制小数据量数据页（通常每个数据页只有 4KB）的方式，保证了主进程修改数据不会影响子进程存储，子进程存储的数据，还是子进程产生一瞬间的数据。

快照触发方式有自动触发与手动触发两种。

- **自动触发**：通过 redis.conf 配置文件进行配置；
- **手动触发**：
	- save: 阻塞式触发，在未完成前，客户端无法进行命令操作；
	- bgsave: 非阻塞式触发，主进程 fork 出子进程进行备份操作；


在恢复文件时，将备份文件 (dump.rdb) 放在 Redis 安装目录，然后启动 Redis，就能把 RDB 中的文件加载到 Redis 服务中。

快照存储的优点缺点：

- **优点**：
	- 数据结构紧凑，保存了 Redis 服务在某个时间点上的数据集，非常适合做备份和灾难恢复；
	- 进行 RDB 快照持久化时，主进程会 fork 出一个子进程进行备份工作，主进程不需要额外的 IO 操作；
	- RDB 恢复大数据集时，速度比 AOF 快；
- **缺点**：
	- 版本兼容问题：Redis 版本更新过程中有多个 RDB 版本，存在老版 RDB 兼容性无法兼容新版的问题；
	- 无法做到实时持久化，因为 bgsave 时的 fork 操作每次都会创建子进程，内存中的数据被克隆了一份，属于重量级操作。

	
### 4.2 AOF

AOF 日志存储的是 **Redis 服务器的顺序指令序列**，它只记录对内存进行修改的指令记录。AOF 使用追加记录的方式，在 Redis 长期运行的过程中，AOF 日志会越来越长，所以一旦宕机重启载入 AOF 日志，将会是一个非常耗时的功能，因此我们需要对 AOF 进行瘦身，即 AOF 重写。  
AOF 重写并不是对原始的 AOF 文件进行重新整理，而是 fork 一个子进程遍历服务器的键值对，转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后，将原来的文件替换为序列化后的文件即可。  
AOF 重写分为两个过程，一个是 fork 子进程重写过程执行的原始数据内容，另一个是在 **fork 过程中主进程修改的指令**。

**AOF 的持久化策略**：AOF 日志是以文件形式存在的，里面记录的是内存的操作记录，它的实现是将**操作系统内核为文件描述符分配的内存缓存，通过异步的方式刷新到数据磁盘中**。这种操作是 glibc 的 fsync 操作，它是一个很慢的操作，与 Redis 的高性能是相反的。  
AOF 提供了三种持久化策略：

- **no**: 无 fsync，由系统保证数据刷新到磁盘，速度最快，但很不安全（通常不使用）；
- **always**: 每次 fsync，每一个修改内存的 Redis 指令都会执行一次 fsync，速度很慢（通常不使用）；
- **everysec**: 每秒进行一次 fsync，有可能丢失一秒的 fsync 的数据。通常选择 everysec 策略，兼顾安全性和效率。

### 4.3 混合持久化

Redis 4.0 之后加入了新的持久化选项：混合持久化。它将 RDB 和 AOF 内容放在一起，其中 AOF 日志记录的不是全量日志，而是**持久化开始到持久化结束**时间内的 AOF 日志（通常该部分日志很小）。

## 6. Redis 集群方案与实现

## 7. Redis 为什么是单线程的

## 8. 缓存奔溃

## 9. 缓存降级

## 10. 使用缓存的合理性问题

## 11. Redis 的回收

### 11(1) Redis 的数据淘汰策略

当 Redis **内存超出物理内存限制**时，为了保持高效的可用性，Redis 需要对内存中部分数据进行淘汰。Redis 早起版本使用的数据淘汰策略是 LRU (Least Recently Used，最近最少使用) 策略，LRU 策略是基于最近访问时间进行排序、淘汰的。后来加入了 LFU (Least Frequency Used，最近最低频率) 策略。  
Redis 主要使用的还是 LRU 策略。

- **noeviction**: 可以继续读请求，不可以进行写请求。
	- 返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但 DEL 和几个例外）；
	- 默认淘汰策略。
- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在**设置了过期时间**的键，使得新添加的数据有空间存放。
- **volatile-random**: 回收**随机的键**使得新添加的数据有空间存放，但仅限于在**设置了过期时间的键**。
- **volatile-ttl**: 回收设置了过期时间的键，淘汰策略是**优先回收剩余时间 (TTL) 较短的键**，使得新添加的数据有空间存放。
- **allkeys-lru**: 对全部集合进行回收，尝试回收最少使用的键 (LRU)，使得新添加的数据有空间存放。
- **allkeys-random**: 对全部集合进行回收，回收随机的键使得新添加的数据有空间存放。
- **volatile-lfu**: 对设置了过期时间的键进行 LFU 策略的过期筛选；
- **allkeys-lfu**: 对全部的键进行 LFU 策略的过期筛选；

### 11(2) LRU 策略

Redis 的数据都是由 key-value 形式构成的，在实现 LRU 的内存淘汰机制时，除了 key-value，LRU 还需要维护一个列表，链表尾部的数据是最少被访问的数据。列表按照最近访问时间进行排序。当内存达到物理内存限制触发 LRU 回收时，对链表尾部的 k-v 进行回收。

但 Redis 的 LRU 并不是这样执行的，Redis 使用了一种近似 LRU 算法。对于所有 Redis 对象，对象头中包含一个 24bit 的信息，作为**对象热度**的标志。在 LRU 淘汰算法中，该标志是一个**时间戳**，记录了最近一次访问该标志位的时间。  
在触发了 LRU 淘汰时，Redis 会随机抽取若干个（默认是 5 个）key，然后删掉最旧的 key。如果这时候内存依旧超出限制，则再次抽选、删除最旧的 Key 值，直到内存低于最大内存限制为止。

Redis Object 的对象头如下所示：

```c
typedef struct redisObject {
    // 对象类型，如 zset, set, hash 等
    unsigned type: 4; 
    // 对象编码如 ziplist, inset, skiplist 等
    unsigned encoding: 4;
    // 对象的热度
    unsigned lru: 24;
    // 引用计数
    int refcount;
    // 对象的 body
    void *ptr;
}
```

其中，lru 值即为表示热度的值。在 LRU 模式下，该字段存储的时间戳是 Redis 服务器的时钟信息 server.lruclock，单位为毫秒。server.lruclock 持续更新，某对象被访问时，对象头中的 LRU 值被更新为当前 server.lruclock 的值，最后当触发 LRU 内存淘汰时，该对象的 LRU 值会与当前 server.lruclock 进行取模等一系列运算，即可得到 LRU 值。

### 11(3) LFU 策略

LFU 策略与 LRU 的计算方式大致相同，都是根据 Redis 对象头的 LRU 值与 server.lruclock 值进行计算的。但是 LFU 策略下，24bit 的 lru 值被分为 16+8 两部分。

- **ldt (last decrement time，)**: 前 16 位，记录上一次更新时间，计算单位是分钟。
	- ldt 不是对象被访问的时候被更新，而是在 Redis 触发淘汰逻辑时进行更新；
- **logc (logistic counter，对数计数)**: 后 8 位记录频率信息，且以**对数形式**储存，计算单位是分钟。
	- logc 有**衰减算法**，在 ldt 更新时触发。当前 logc 值减去对象空闲时间，除以一个衰减系数；
	- 由于 logc 的统计的是对数信息，所以它的 +1 策略是基于概率的 +1；于是当对数值越大时，+1 操作概率越小，就越难被更新。大致流程如下：
		1. 计算差值：<code>当前对数值 - 基值 (5)</code>；
		2. 计算更新 +1 操作概率：<code>p = 1 / 差值</code>；


## 12. 其他问题
### (1) 什么是Redis？

Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个数据库统统加载在内存当中进行操作，定期通过**异步操作**把数据 **flush 到硬盘上**进行保存。  
因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value DB。 Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存**多种数据结构**。  
此外单个 value 的最大限制是 1GB，不像 memcached 只能保存 1MB 的数据，因此 Redis 可以用来实现很多有用的功能（比方说用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性能消息队列服务，用他的 Set 可以做高性能的 tag 系统等等）。另外 Redis 也可以对存入的 Key-Value 设置 expire 时间，因此也可以被当作一个功能加强版的 memcached 来用。  
Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。

### (2) Redis 相比 memcached 有哪些优势？

- memcached 所有的值均是简单的字符串，redis 作为其替代者，支持更为丰富的数据类型
- redis 的速度比 memcached 快很多
- redis 可以**持久化**其数据

### (3) Redis支持哪几种数据类型？

String, List, Set, Sorted Set, hashes

### (5) Redis官方为什么不提供Windows版本？
因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。

### (6) 一个字符串类型的值能存储最大容量是多少？

512M

### (7) 为什么Redis需要把所有数据放到内存中？

Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。

### (8) Redis集群方案应该怎么做？都有哪些方案？

1. twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通redis无任何区别，设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法，将请求转接到具体redis，将结果再返回twemproxy。使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。
2. codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。
3. redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。
4. 在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。

### (9) Redis集群方案什么情况下会导致整个集群不可用？
有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。

### (10) MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？

redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。

### (11) Redis有哪些适合的场景？

- 会话缓存（Session Cache）
	- 最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？
	- 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。
- 全页缓存（FPC）
	- 除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。
	- 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。
	- 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。
- 队列
	- Redis在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。
	- 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。
- 排行榜/计数器
	- Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：
	- 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：
	- ZRANGE user_scores 0 10 WITHSCORES
	- Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。
- 发布/订阅
	- 最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。

### (12) Redis支持的Java客户端都有哪些？官方推荐用哪个？
Redisson、Jedis、lettuce等等，官方推荐使用Redisson。

### (13) Redis和Redisson有什么关系？

Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。

### (14) Jedis与Redisson对比有什么优缺点？
Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。

### (15) Redis如何设置密码及验证密码？

- 设置密码：config set requirepass 123456
- 授权密码：auth 123456

### (16) 说说Redis哈希槽的概念？

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

### (17) Redis集群的主从复制模型是怎样的？
为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.

### (18) Redis集群会有写操作丢失吗？为什么？

Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。

### (19) Redis集群之间是如何复制的？

异步复制

### (20) Redis集群最大节点个数是多少？
16384个。

### (21) Redis集群如何选择数据库？

Redis集群目前无法做数据库选择，默认在0数据库。

### (22) 怎么测试Redis的连通性？
ping

### (23) Redis中的管道有什么用？
一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。

这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多POP3协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。

### (24) 怎么理解Redis事务？
事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。

### (25) Redis事务相关的命令有哪几个？

MULTI、EXEC、DISCARD、WATCH

### (26) Redis key的过期时间和永久有效分别怎么设置？

EXPIRE和PERSIST命令。

### (27) Redis如何做内存优化？

尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面.

### (28) Redis回收进程如何工作的？

一个客户端运行了新的命令，添加了新的数据。  
Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。  
一个新的命令被执行，等等。  
所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。  
如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。

### (29) Redis回收使用的是什么算法？

LRU算法

### (30) Redis如何做大量数据插入？

Redis2.6开始redis-cli支持一种新的被称之为pipe mode的新模式用于执行大量数据插入工作。

### (31) 为什么要做Redis分区？

分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升,Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。

### (32) 你知道有哪些Redis分区实现方案？

客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。

- 代理分区：意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy
- 查询路由 (Query routing): 意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。

### (33) Redis分区有什么缺点？

涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。  
同时操作多个 key，则不能使用Redis事务。  
分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）.  
当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。  
分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。

### (34) Redis持久化数据和缓存怎么做扩容？

如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。  
如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。

### (35) 分布式Redis是前期做还是后期规模上来了再做好？为什么？

既然Redis是如此的轻量（单实例只使用1M内存）,为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。  
一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。  
这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。

### (36) Twemproxy是什么？

Twemproxy是Twitter维护的（缓存）代理系统，代理Memcached的ASCII协议和Redis协议。它是单线程程序，使用c语言编写，运行起来非常快。它是采用Apache 2.0 license的开源软件。 Twemproxy支持自动分区，如果其代理的其中一个Redis节点不可用时，会自动将该节点排除（这将改变原来的keys-instances的映射关系，所以你应该仅在把Redis当缓存时使用Twemproxy)。 Twemproxy本身不存在单点问题，因为你可以启动多个Twemproxy实例，然后让你的客户端去连接任意一个Twemproxy实例。 Twemproxy是Redis客户端和服务器端的一个中间层，由它来处理分区功能应该不算复杂，并且应该算比较可靠的。

### (37) 支持一致性哈希的客户端有哪些？

Redis-rb、Predis等。

### (38) Redis与其他key-value存储有什么不同？
Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。  
Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存。在内存数据库方面的另一个优点是， 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。 同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。

### (39) Redis的内存占用情况怎么样？
给你举个例子： 100万个键值对（键是0到999999值是字符串“hello world”）在我的32位的Mac笔记本上 用了100MB。同样的数据放到一个key里只需要16MB， 这是因为键值有一个很大的开销。 在Memcached上执行也是类似的结果，但是相对Redis的开销要小一点点，因为Redis会记录类型信息引用计数等等。  
当然，大键值对时两者的比例要好很多。  
64位的系统比32位的需要更多的内存开销，尤其是键值对都较小时，这是因为64位的系统里指针占用了8个字节。 但是，当然，64位系统支持更大的内存，所以为了运行大型的Redis服务器或多或少的需要使用64位的系统。

### (40) 都有哪些办法可以降低Redis的内存使用情况呢？

如果你使用的是32位的Redis实例，可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。

### (41) Redis的内存用完了会发生什么？
如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以将Redis当缓存来使用配置淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。

### (42) Redis是单线程的，如何提高多核CPU的利用率？
可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。

### (43) 一个Redis实例最多能存放多少的keys？List、Set、Sorted Set他们最多能存放多少元素？

理论上Redis可以处理多达232的keys，并且在实际中进行了测试，每个实例至少存放了2亿5千万的keys。我们正在测试一些较大的值。  
任何list、set、和sorted set都可以放232个元素。  
换句话说，Redis的存储极限是系统中的可用内存值。

### (44) Redis常见性能问题和解决方案？

1. Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
2. 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
3. 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
4. 尽量避免在压力很大的主库上增加从库
5. 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...

这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。

### (45) Redis提供了哪几种持久化方式？

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.
- AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.

如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。  
你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。  
最重要的事情是了解RDB和AOF持久化方式的不同,让我们以RDB持久化方式开始。

### (46) 如何选择合适的持久化方式？
一般来说， 如果想达到足以媲美PostgreSQL的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。  
有很多用户都只使用AOF持久化，但并不推荐这种方式：因为定时生成RDB快照（snapshot）非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外， 使用RDB还可以避免之前提到的AOF程序的bug。

### (47) 修改配置不重启Redis会实时生效吗？
针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何形式的重启。 从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis。检索 ‘CONFIG GET *’ 命令获取更多信息。

但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前 CONFIG 命令还不支持的配置参数的时候。
