# 一.

# 二. SpringBean创建过程中的设计模式？

Spring中涉及的设计模式总结

## 1.简单工厂(非23种设计模式中的一种)

- 实现方式：BeanFactory。 Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。
- 实质：由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。
- 实现原理： 
	- bean容器的启动阶段： 
		- 读取bean的xml配置文件,将bean元素分别转换成一个BeanDefinition对象。
		- 然后通过BeanDefinitionRegistry将这些bean注册到beanFactory中，保存在它的一个ConcurrentHashMap中。
		- 将BeanDefinition注册到了beanFactory之后，在这里Spring为我们提供了一个扩展的切口，允许我们通过实现接口BeanFactoryPostProcessor 在此处来插入我们定义的代码。典型的例子就是：PropertyPlaceholderConfigurer，我们一般在配置数据库的dataSource时使用到的占位符的值，就是它注入进去的。
	- 容器中bean的实例化阶段： 
		- 实例化阶段主要是通过反射或者CGLIB对bean进行实例化，在这个阶段Spring又给我们暴露了很多的扩展点： 
		- 各种的Aware接口，比如 BeanFactoryAware，对于实现了这些Aware接口的bean，在实例化bean时Spring会帮我们注入对应的BeanFactory的实例。
		- BeanPostProcessor接口，实现了BeanPostProcessor接口的bean，在实例化bean时Spring会帮我们调用接口中的方法。
		- InitializingBean接口，实现了InitializingBean接口的bean，在实例化bean时Spring会帮我们调用接口中的方法。
		- DisposableBean接口，实现了BeanPostProcessor接口的bean，在该bean死亡时Spring会帮我们调用接口中的方法。
- 设计意义： 
	- **松耦合**。可以将原来硬编码的依赖，通过Spring这个beanFactory这个工长来注入依赖，也就是说原来只有依赖方和被依赖方，现在我们引入了第三方——spring这个beanFactory，由它来解决bean之间的依赖问题，达到了松耦合的效果.
	- **bean的额外处理**。通过Spring接口的暴露，在实例化bean的阶段我们可以进行一些额外的处理，这些额外的处理只需要让bean实现对应的接口即可，那么spring就会在bean的生命周期调用我们实现的接口来处理该bean。<font color=red>[非常重要]</font>

## 2. 工厂方法

- 实现方式：FactoryBean接口。
- 实现原理： 
	- 实现了FactoryBean接口的bean是一类叫做factory的bean。其特点是，spring会在使用getBean()调用获得该bean时，会自动调用该bean的getObject()方法，所以返回的不是factory这个bean，而是这个bean.getOjbect()方法的返回值。
- 例子： 
	- 典型的例子有spring与mybatis的结合。
	- 代码示例 

![](https://img-blog.csdn.net/20180422155550286?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Nhb3hpYW9ob25nMTAwNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

	- 说明：我们看上面该bean，因为实现了FactoryBean接口，所以返回的不是 SqlSessionFactoryBean 的实例，而是她的 SqlSessionFactoryBean.getObject() 的返回值。

## 3. 单例模式

- Spring依赖注入Bean实例默认是单例的。
- Spring的依赖注入（包括lazy-init方式）都是发生在AbstractBeanFactory的getBean里。getBean的doGetBean方法调用getSingleton进行bean的创建。
- 分析getSingleton()方法

```java
public Object getSingleton(String beanName){
    //参数true设置标识允许早期依赖
    return getSingleton(beanName,true);
}
protected Object getSingleton(String beanName, boolean allowEarlyReference) {
    //检查缓存中是否存在实例
    Object singletonObject = this.singletonObjects.get(beanName);
    if (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {
        //如果为空，则锁定全局变量并进行处理。
        synchronized (this.singletonObjects) {
            //如果此bean正在加载，则不处理
            singletonObject = this.earlySingletonObjects.get(beanName);
            if (singletonObject == null && allowEarlyReference) {  
                //当某些方法需要提前初始化的时候则会调用addSingleFactory 方法将对应的ObjectFactory初始化策略存储在singletonFactories
                ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);
                if (singletonFactory != null) {
                    //调用预先设定的getObject方法
                    singletonObject = singletonFactory.getObject();
                    //记录在缓存中，earlysingletonObjects和singletonFactories互斥
                    this.earlySingletonObjects.put(beanName, singletonObject);
                    this.singletonFactories.remove(beanName);
                }
            }
        }
    }
    return (singletonObject != NULL_OBJECT ? singletonObject : null);
}
```

- getSingleton()过程图 
	- ps：spring依赖注入时，使用了 双重判断加锁 的单例模式 

![](https://img-blog.csdn.net/20180422155736938?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Nhb3hpYW9ob25nMTAwNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- 总结
	- 单例模式定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。
	- spring对单例的实现：spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是任意的java对象。

## 4. 适配器模式

- 实现方式：SpringMVC中的适配器HandlerAdatper。
- 实现原理：HandlerAdatper根据Handler规则执行不同的Handler。
- 实现过程： 
	- DispatcherServlet根据HandlerMapping返回的handler，向HandlerAdatper发起请求，处理Handler。HandlerAdapter根据规则找到对应的Handler并让其执行，执行完毕后Handler会向HandlerAdapter返回一个ModelAndView，最后由HandlerAdapter向DispatchServelet返回一个ModelAndView。
- 实现意义： 
	- HandlerAdatper使得Handler的扩展变得容易，只需要增加一个新的Handler和一个对应的HandlerAdapter即可。因此Spring定义了一个适配接口，使得每一种Controller有一种对应的适配器实现类，让适配器代替controller执行相应的方法。这样在扩展Controller时，只需要增加一个适配器类就完成了SpringMVC的扩展了。

## 5. 装饰器模式

- 实现方式： 
	- Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。
- 实质： 
	- 动态地给一个对象添加一些额外的职责。
	- 就增加功能来说，Decorator模式相比生成子类更为灵活。

## 6. 代理模式

- 实现方式： AOP底层，就是动态代理模式的实现。 
	- 动态代理：在内存中构建的，不需要手动编写代理类
	- 静态代理：需要手工编写代理类，代理类引用被代理对象。
- 实现原理： 
	- 切面在应用运行的时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象创建动态的创建一个代理对象。SpringAOP就是以这种方式织入切面的。 
	- <font color=red>织入：把切面应用到目标对象并创建新的代理对象的过程。</font>

## 7. 观察者模式

- 实现方式：spring的事件驱动模型使用的是**观察者模式**，Spring中Observer模式常用的地方是listener的实现。 

具体实现如下，<font color=red>事件机制的实现需要三个部分,事件源,事件,事件监听器</font>：

- ApplicationEvent抽象类[事件]
	- 继承自jdk的EventObject,所有的事件都需要继承ApplicationEvent,并且通过构造器参数source得到事件源.
	- 该类的实现类ApplicationContextEvent表示ApplicaitonContext的容器事件.
	- 代码：
		
```java
public abstract class ApplicationEvent extends EventObject {
    private static final long serialVersionUID = 7099057708183571937L;
    private final long timestamp;
    public ApplicationEvent(Object source) {
    super(source);
    this.timestamp = System.currentTimeMillis();
    }
    public final long getTimestamp() {
        return this.timestamp;
    }
}
```

- ApplicationListener接口[事件监听器]
	- 继承自jdk的EventListener,所有的监听器都要实现这个接口。
	- 这个接口只有一个onApplicationEvent()方法,该方法接受一个ApplicationEvent或其子类对象作为参数,在方法体中,可以通过不同对Event类的判断来进行相应的处理。
	- 当事件触发时所有的监听器都会收到消息。
	- 代码：

```java
    public interface ApplicationListener<E extends ApplicationEvent> extends                EventListener {
                 void onApplicationEvent(E event);
} 
```

- ApplicationContext接口[事件源]
	- ApplicationContext是spring中的全局容器,翻译过来是”应用上下文”。
	- 实现了ApplicationEventPublisher接口。
	- 职责：负责读取bean的配置文档,管理bean的加载,维护bean之间的依赖关系,可以说是负责bean的整个生命周期,再通俗一点就是我们平时所说的IOC容器。
	- 代码：

```java
public interface ApplicationEventPublisher {
        void publishEvent(ApplicationEvent event);
}   

public void publishEvent(ApplicationEvent event) {
    Assert.notNull(event, "Event must not be null");
    if (logger.isTraceEnabled()) {
         logger.trace("Publishing event in " + getDisplayName() + ": " + event);
    }
    getApplicationEventMulticaster().multicastEvent(event);
    if (this.parent != null) {
    this.parent.publishEvent(event);
    }
}
```

- ApplicationEventMulticaster抽象类**[事件源中publishEvent方法需要调用其方法getApplicationEventMulticaster]**
	- 属于事件广播器,它的作用是把Applicationcontext发布的Event广播给所有的监听器.
	- 代码：

```java
public abstract class AbstractApplicationContext extends DefaultResourceLoader
    implements ConfigurableApplicationContext, DisposableBean {  
    private ApplicationEventMulticaster applicationEventMulticaster;  
    protected void registerListeners() {  
    // Register statically specified listeners first.  
    for (ApplicationListener<?> listener : getApplicationListeners()) {  
    getApplicationEventMulticaster().addApplicationListener(listener);  
    }  
    // Do not initialize FactoryBeans here: We need to leave all regular beans  
    // uninitialized to let post-processors apply to them!  
    String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false);  
    for (String lisName : listenerBeanNames) {  
    getApplicationEventMulticaster().addApplicationListenerBean(lisName);  
    }  
  }  
}
```

## 8. 策略模式

- 实现方式：Spring框架的**资源访问Resource接口**。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。
- Resource 接口介绍 
	- source 接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。
	- Resource 接口主要提供了如下几个方法: 
		- getInputStream()：定位并打开资源，返回资源对应的输入流。每次调用都返回新的输入流。调用者必须负责关闭输入流。
		- exists()：返回 Resource 所指向的资源是否存在。
		- isOpen()：返回资源文件是否打开，如果资源文件不能多次读取，每次读取结束应该显式关闭，以防止资源泄漏。
		- getDescription()：返回资源的描述信息，通常用于资源处理出错时输出该信息，通常是全限定文件名或实际 URL。
		- getFile：返回资源对应的 File 对象。
		- getURL：返回资源对应的 URL 对象。 
		- <font color=red>最后两个方法通常无须使用，仅在通过简单方式访问无法实现时，Resource 提供传统的资源访问的功能。</font>
	- Resource 接口本身没有提供访问任何底层资源的实现逻辑，**针对不同的底层资源，Spring 将会提供不同的 Resource 实现类，不同的实现类负责不同的资源访问逻辑。**
	- Spring 为 Resource 接口提供了如下实现类： 
		- UrlResource：访问网络资源的实现类。
		- ClassPathResource：访问类加载路径里资源的实现类。
		- FileSystemResource：访问文件系统里资源的实现类。
		- ServletContextResource：访问相对于 ServletContext 路径里的资源的实现类.
		- InputStreamResource：访问输入流资源的实现类。
		- ByteArrayResource：访问字节数组资源的实现类。 
		- <font color=red>这些 Resource 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。</font>

## 9. 模版方法模式

- 经典模板方法定义： 
	- 父类定义了骨架（调用哪些方法及顺序），某些特定方法由子类实现
	- 最大的好处：代码复用，减少重复代码。除了子类要实现的特定方法，其他方法及方法调用顺序都在父类中预先写好了。
	- 所以父类模板方法中有两类方法： 
		- 共同的方法：所有子类都会用到的代码
		- 不同的方法：子类要覆盖的方法，分为两种： 
			- 抽象方法：父类中的是抽象方法，子类必须覆盖
			- 钩子方法：父类中是一个空方法，子类继承了默认也是空的 
			- <font color=red>注：为什么叫钩子，子类可以通过这个钩子（方法），控制父类，因为这个钩子实际是父类的方法（空方法）！</font>
- Spring模板方法模式实质： 
	- <font color=red>是模板方法模式和回调模式的结合</font>，是Template Method不需要继承的另一种实现方式。Spring几乎所有的外接扩展都采用这种模式。
- 具体实现： 
	- JDBC的抽象和对Hibernate的集成，都采用了一种理念或者处理方式，那就是模板方法模式与相应的Callback接口相结合。
- 采用模板方法模式是为了以一种统一而集中的方式来处理资源的获取和释放，以JdbcTempalte为例:

```java
public abstract class JdbcTemplate {  
     public final Object execute（String sql）{  
        Connection con=null;  
        Statement stmt=null;  
        try{  
            con = getConnection();  
            stmt = con.createStatement();  
            Object retValue=executeWithStatement(stmt, sql);  
            return retValue;  
        } catch (SQLException e) {  
             ...  
        } finally {  
            closeStatement(stmt);  
            releaseConnection(con);  
        }  
    }   
    protected abstract Object executeWithStatement(Statement stmt, String sql);
}  
```

- 引入回调原因：
	- JdbcTemplate是抽象类，不能够独立使用，我们每次进行数据访问的时候都要给出一个相应的子类实现,这样肯定不方便，所以就引入了回调 。
- 回调代码

```java
public interface StatementCallback{  
    Object doWithStatement（Statement stmt）;  
}   
```

- 利用回调方法重写JdbcTemplate方法

```java
public class JdbcTemplate {  
    public final Object execute(StatementCallback callback) {  
        Connection con = null;  
        Statement stmt = null;  
        try {  
            con = getConnection();  
            stmt = con.createStatement();  
            Object retValue = callback.doWithStatement(stmt);  
            return retValue;  
        } catch (SQLException e) {  
            ...  
        } finally {  
            closeStatement(stmt);  
            releaseConnection(con);  
        }  
    }  

    ...//其它方法定义  
}   
```

Jdbc使用方法如下：

```java
JdbcTemplate jdbcTemplate = ...;  
    final String sql=...;  
    StatementCallback callback=new StatementCallback(){  
    public Object=doWithStatement(Statement stmt){  
        return ...;  
    }  
}    
jdbcTemplate.execute(callback);  
```

- 为什么JdbcTemplate没有使用继承？ 
	- 因为这个类的方法太多，但是我们还是想用到JdbcTemplate已有的稳定的、公用的数据库连接，那么我们怎么办呢？我们可以把变化的东西抽出来作为一个参数传入JdbcTemplate的方法中。但是变化的东西是一段代码，而且这段代码会用到JdbcTemplate中的变量。怎么办？那我们就用回调对象吧。在这个回调对象中定义一个操纵JdbcTemplate中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。

# 三. 简述三次握手和四次握手的过程？

# 四. 高并发场景下如何防止死锁，保证数据的一致性？

## 1. 什么是死锁

死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等的进程称为死锁进程。

## 2. 死锁产生的四个必要条件

- 互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放
- 请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放
- 不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放
- 环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源

这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。

## 3. 如何处理死锁

### (1) 锁模式

1. 共享锁（S)
	- 由读操作创建的锁，防止在读取数据的过程中，其它事务对数据进行更新；其它事务可以并发读取数据。共享锁可以加在表、页、索引键或者数据行上。在SQL SERVER默认隔离级别下数据读取完毕后就会释放共享锁，但可以通过锁提示或设置更高的事务隔离级别改变共享锁的释放时间。
2. 独占锁(X)
	- 对资源独占的锁，一个进程独占地锁定了请求的数据源，那么别的进程无法在此数据源上获得任何类型的锁。独占锁一致持有到事务结束。
3. 更新锁(U)
	- 更新锁实际上并不是一种独立的锁，而是共享锁与独占锁的混合。当SQL SERVER执行数据修改操作却首先需要搜索表以找到需要修改的资源时，会获得更新锁。
	- 更新锁与共享锁兼容，但只有一个进程可以获取当前数据源上的更新锁，
	- 其它进程无法获取该资源的更新锁或独占锁，更新锁的作用就好像一个序列化阀门 (serialization gate)，将后续申请独占锁的请求压入队列中。持有更新锁的进程能够将其转换成该资源上的独占锁。更新锁不足以用于更新数据—实际的数据修改仍需要用到独占锁。对于独占锁的序列化访问可以避免转换死锁的发生，更新锁会保留到事务结束或者当它们转换成独占锁时为止。
4. 意向锁(IX,IU,IS)	
	- 意向锁并不是独立的锁定模式，而是一种指出哪些资源已经被锁定的机制。
	- 如果一个表页上存在独占锁，那么另一个进程就无法获得该表上的共享表锁，这种层次关系是用意向锁来实现的。进程要获得独占页锁、更新页锁或意向独占页锁，首先必须获得该表上的意向独占锁。同理，进程要获得共享行锁，必须首先获得该表的意向共享锁，以防止别的进程获得独占表锁。
5. 特殊锁模式 (Sch_s,Sch_m,BU)
	- SQL SERVER提供3种额外的锁模式：架构稳定锁、架构修改锁、大容量更新锁。
6. 转换锁(SIX,SIU,UIX)
	- 转换锁不会由SQL SERVER 直接请求，而是从一种模式转换到另一种模式所造成的。SQL SERVER 2008支持3种类型的转换锁：SIX、SIU、UIX.其中最常见的是SIX锁，如果事务持有一个资源上的共享锁（S），然后又需要一个IX锁，此时就会出现SIX。
7. 键范围锁
	- 键范围锁是在可序列化隔离级别中锁定一定范围内数据的锁。保证在查询数据的键范围内不允许插入数据。

### (2) 锁粒度

SQL SERVER 可以在表、页、行等级别锁定用户的数据资源即非系统资源（系统资源是用闩锁来保护的）。此外SQL SERVER 还可以锁定索引键和索引键范围。  
通过sys.dm_tran_locks视图可以查看谁被锁定了（如行，键，页）、锁的模式以及特定资源的标志符。基于sys.dm_tran_locks视图创建如下视图用于查看锁定的资源以及锁模式（通过这个视图可以查看事务锁定的表、页、行以及加在数据资源上的锁类型）。

```sql
CREATE VIEW dblocks AS
SELECT request_session_id AS spid,
DB_NAME(resource_database_id) AS dbname,
CASE WHEN resource_type='object'
THEN OBJECT_NAME(resource_associated_entity_id)
WHEN resource_associated_entity_id=0 THEN'n/a'
ELSE OBJECT_NAME (p.object_id) END AS entity_name,
index_id,
resource_type AS RESOURCE,
resource_description AS DESCRIPTION,
request_mode AS mode,
request_status AS STATUS
FROM sys.dm_tran_locks t LEFTJOIN sys.partitions p 
ON p.partition_id=t.resource_associated_entity_id
WHERE resource_database_id=DB_ID()
```

### (3) 如何跟踪死锁

通过选择sql server profiler 事件中的如下选项就可以跟踪到死锁产生的相关语句。

### (4) 死锁案例分析

在该案例中process65db88, process1d0045948为语句1的进程，process629dc8 为语句2的进程； 语句2获取了1689766页上的更新锁，在等待1686247页上的更新锁；而语句1则获取了1686247页上的更新锁在等待1689766页上的更新锁，两个语句等待的资源形成了一个环路，造成死锁。

### (5) 如何解决死锁

针对如上死锁案例，分析其对应语句执行计划如下：

通过执行计划可以看出，在查找需要更新的数据时使用的是索引扫描，比较耗费性能，这样就造成锁定资源时间过长，增加了语句并发执行时产生死锁的概率。

处理方式：

1. 在表上建立一个聚集索引。
2. 对语句更新的相关字段建立包含索引。

优化后该语句执行计划如下：

- 优化后的执行计划使用了索引查找，将大幅提升该查询语句的性能，降低了锁定资源的时间，同时也减少了锁定资源的范围，这样就降低了锁资源循环等待事件发生的概率，对于预防死锁的发生会有一定的作用。
- 死锁是无法完全避免的，但如果应用程序适当处理死锁，对涉及的任何用户及系统其余部分的影响可降至最低（适当处理是指发生错误1205时，应用程序重新提交批处理，第二次尝试大多能成功。一个进程被杀死，它的事务被取消，它的锁被释放，死锁中涉及到的另一个进程就可以完成它的工作并释放锁，所以就不具备产生另一个死锁的条件了。）

## 4. 如何预防死锁

阻止死锁的途径就是避免满足死锁条件的情况发生，为此我们在开发的过程中需要遵循如下原则：

1. 尽量避免并发的执行涉及到修改数据的语句。
2. 要求每一个事务一次就将所有要使用到的数据全部加锁，否则就不允许执行。
3. 预先规定一个加锁顺序，所有的事务都必须按照这个顺序对数据执行封锁。如不同的过程在事务内部对对象的更新执行顺序应尽量保证一致。
4. 每个事务的执行时间不可太长，对程序段的事务可考虑将其分割为几个事务。在事务中不要求输入，应该在事务之前得到输入，然后快速执行事务。
5. 使用尽可能低的隔离级别。
6. 数据存储空间离散法。该方法是指采用各种手段，将逻辑上在一个表中的数据分散的若干离散的空间上去，以便改善对表的访问性能。主要通过将大表按行或者列分解为若干小表，或者按照不同的用户群两种方法实现。
7. 编写应用程序，让进程持有锁的时间尽可能短，这样其它进程就不必花太长的时间等待锁被释放。

## 5. 补充：

### (1) 死锁的概念：

如果一组进程中的每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么改组进程是死锁的。

### (2) 死锁的常见表现：

死锁不仅会发生多个进程中，也会发生在一个进程中。

- 多进程死锁：有进程A，进程B，进程A拥有资源1，需要请求正在被进程B占有的资源2。而进程B拥有资源2，请求正在被进程A战友的资源1。两个进程都在等待对方释放资源后请求该资源，而相互僵持，陷入死锁。
- 单进程死锁：进程A拥有资源1，而它又在请求资源1，而它所请求的资源1必须等待该资源使用完毕得到释放后才可被请求。这样，就陷入了自己的死锁。

### (3) 产生死锁的原因：

- 进程推进顺序不当造成死锁。
- 竞争不可抢占性资源引起死锁。
- 竞争可消耗性资源引起死锁。

### (4) 死锁的四个必要条件（四个条件四者不可缺一）：

- 互斥条件。某段时间内，一个资源一次只能被一个进程访问。
- 请求和保持条件。进程A已经拥有至少一个资源，此时又去申请其他资源，而该资源又正在被进程使用，此时请求进程阻塞，但对自己已经获得的资源保持不放。
- 不可抢占资源。进程已获得的资源在未使用完不能被抢占，只能在自己使用完时由自己释放。
- 循环等待序列。存在一个循环等待序列P0P1P2……Pn，P0请求正在被进程P1占有的资源，P1请求正在被P2占有的资源……Pn正在请求被进程P0占有的资源。

### (5) 解除死锁的两种方法：

- 终止（或撤销）进程。终止（或撤销）系统中的一个或多个死锁进程，直至打破循环环路，使系统从死锁状态中解除出来。
- 抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以打破死锁状态。

# 五. 集群和负载均衡的算法与实现？

## 1. 负载均衡器

可以是专用设备，也可以是在通用服务器上运行的应用程序。 分散请求到拥有相同内容或提供相同服务的服务器。 专用设备一般只有以太网接口，可以说是多层交换机的一种。 负载均衡器一般会被分配虚拟IP地址，所有来自客户端的请求都是针对虚拟IP地址完成的。负载均衡器通过负载均衡算法将来自客户端的请求转发到服务器的实际IP地址上。

## 2. 负载均衡算法
```java
private Map<String,Integer> serverMap = new HashMap<String,Integer>(){{
        put("192.168.1.100",1);
        put("192.168.1.101",1);
        put("192.168.1.102",4);
        put("192.168.1.103",1);
        put("192.168.1.104",1);
        put("192.168.1.105",3);
        put("192.168.1.106",1);
        put("192.168.1.107",2);
        put("192.168.1.108",1);
        put("192.168.1.109",1);
        put("192.168.1.110",1);
    }};
```

### (1) 随机算法

Random随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。

```java
public void random(){
        List<String> keyList = new ArrayList<String>(serverMap.keySet());
        Random random = new Random();
        int idx = random.nextInt(keyList.size());
        String server = keyList.get(idx);
        System.out.println(server);
    }
```

WeightRandom

```java
public void weightRandom(){
        Set<String> keySet = serverMap.keySet();
        List<String> servers = new ArrayList<String>();
        for(Iterator<String> it = keySet.iterator();it.hasNext();){
            String server = it.next();
            int weithgt = serverMap.get(server);
            for(int i=0;i<weithgt;i++){
                servers.add(server);
            }
        }
        String server = null;
        Random random = new Random();
        int idx = random.nextInt(servers.size());
        server = servers.get(idx);
        System.out.println(server);
    }
```

### (2) 轮询及加权轮询

轮询 (Round Robbin) 当服务器群中各服务器的处理能力相同时，且每笔业务处理量差异不大时，最适合使用这种算法。 轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。

```java
private Integer pos = 0;
public void roundRobin(){
        List<String> keyList = new ArrayList<String>(serverMap.keySet());
        String server = null;
        synchronized (pos){
            if(pos > keyList.size()){
                pos = 0;
            }
            server = keyList.get(pos);
            pos++;
        }
        System.out.println(server);
    }
```

加权轮询 (Weighted Round Robbin) 为轮询中的每台服务器附加一定权重的算法。比如服务器1权重1，服务器2权重2，服务器3权重3，则顺序为1-2-2-3-3-3-1-2-2-3-3-3- ......

```java
public void weightRoundRobin(){
        Set<String> keySet = serverMap.keySet();
        List<String> servers = new ArrayList<String>();
        for(Iterator<String> it = keySet.iterator();it.hasNext();){
            String server = it.next();
            int weithgt = serverMap.get(server);
            for(int i=0;i<weithgt;i++){
               servers.add(server);
            }
        }
        String server = null;
        synchronized (pos){
            if(pos > keySet.size()){
                pos = 0;
            }
            server = servers.get(pos);
            pos++;
        }
        System.out.println(server);
    }
```

### (3) 最小连接及加权最小连接

- 最少连接 (Least Connections) 在多个服务器中，与处理连接数（会话数）最少的服务器进行通信的算法。即使在每台服务器处理能力各不相同，每笔业务处理量也不相同的情况下，也能够在一定程度上降低服务器的负载。
- 加权最少连接 (Weighted Least Connection) 为最少连接算法中的每台服务器附加权重的算法，该算法事先为每台服务器分配处理连接的数量，并将客户端请求转至连接数最少的服务器上。

### (4) 哈希算法

**普通哈希**

```java
public void hash(){
        List<String> keyList = new ArrayList<String>(serverMap.keySet());
        String remoteIp = "192.168.2.215";
        int hashCode = remoteIp.hashCode();
        int idx = hashCode % keyList.size();
        String server = keyList.get(Math.abs(idx));
        System.out.println(server);
    }
```

**一致性哈希一致性Hash**，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。

### (5) IP地址散列

通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处理。

### (6) URL散列

通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。

## 3. 负载均衡算法的手段

负载均衡算法的手段 (DNS->数据链路层->IP层->Http层)

### (1) DNS域名解析负载均衡(延迟)

![](https://images2015.cnblogs.com/blog/821681/201611/821681-20161127212944831-1304074294.png)

利用DNS处理域名解析请求的同时进行负载均衡是另一种常用的方案。在DNS服务器中配置多个A记录，如：www.mysite.com IN A 114.100.80.1、www.mysite.com IN A 114.100.80.2、www.mysite.com IN A 114.100.80.3.

每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。

DNS域名解析负载均衡的优点是将负载均衡工作交给DNS，省略掉了网络管理的麻烦，缺点就是DNS可能缓存A记录，不受网站控制。

事实上，大型网站总是部分使用DNS域名解析，作为第一级负载均衡手段，然后再在内部做第二级负载均衡。

### (2) 数据链路层负载均衡(LVS)

![](https://images2015.cnblogs.com/blog/821681/201611/821681-20161127212959690-1638867074.png)

数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡。

这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一样，从而达到负载均衡，这种负载均衡方式又称为直接路由方式（DR）.

在上图中，用户请求到达负载均衡服务器后，负载均衡服务器将请求数据的目的mac地址修改为真是WEB服务器的mac地址，并不修改数据包目标IP地址，因此数据可以正常到达目标WEB服务器，该服务器在处理完数据后可以经过网管服务器而不是负载均衡服务器直接到达用户浏览器。

使用三角传输模式的链路层负载均衡是目前大型网站所使用的最广的一种负载均衡手段。在linux平台上最好的链路层负载均衡开源产品是LVS(linux virtual server)。

### (3) IP负载均衡(SNAT)

![](https://images2015.cnblogs.com/blog/821681/201611/821681-20161127213024737-1066642602.png)

IP负载均衡：即在网络层通过修改请求目标地址进行负载均衡。

用户请求数据包到达负载均衡服务器后，负载均衡服务器在操作系统内核进行获取网络数据包，根据负载均衡算法计算得到一台真实的WEB服务器地址，然后将数据包的IP地址修改为真实的WEB服务器地址，不需要通过用户进程处理。真实的WEB服务器处理完毕后，相应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的IP地址发送给用户浏览器。

这里的关键在于真实WEB服务器相应数据包如何返回给负载均衡服务器，一种是负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址改为自身的IP，即源地址转换（SNAT），另一种方案是将负载均衡服务器同时作为真实物理服务器的网关服务器，这样所有的数据都会到达负载均衡服务器。

IP负载均衡在内核进程完成数据分发，较反向代理均衡有更好的处理性能。但由于所有请求响应的数据包都需要经过负载均衡服务器，因此负载均衡的网卡带宽成为系统的瓶颈。

### (4) HTTP重定向负载均衡(少见)

![](https://images2015.cnblogs.com/blog/821681/201611/821681-20161127213043143-137664402.png)

HTTP重定向服务器是一台普通的应用服务器，其唯一的功能就是根据用户的HTTP请求计算一台真实的服务器地址，并将真实的服务器地址写入HTTP重定向响应中（响应状态吗302）返回给浏览器，然后浏览器再自动请求真实的服务器。

这种负载均衡方案的优点是比较简单，缺点是浏览器需要每次请求两次服务器才能拿完成一次访问，性能较差；使用HTTP302响应码重定向，可能是搜索引擎判断为SEO作弊，降低搜索排名。重定向服务器自身的处理能力有可能成为瓶颈。因此这种方案在实际使用中并不见多。

### (5) 反向代理负载均衡(nginx)

![](https://images2015.cnblogs.com/blog/821681/201611/821681-20161127213055159-1359413951.png)

传统代理服务器位于浏览器一端，代理浏览器将HTTP请求发送到互联网上。而反向代理服务器则位于网站机房一侧，代理网站web服务器接收http请求。

反向代理的作用是保护网站安全，所有互联网的请求都必须经过代理服务器，相当于在web服务器和可能的网络攻击之间建立了一个屏障。

除此之外，代理服务器也可以配置缓存加速web请求。当用户第一次访问静态内容的时候，静态内存就被缓存在反向代理服务器上，这样当其他用户访问该静态内容时，就可以直接从反向代理服务器返回，加速web请求响应速度，减轻web服务器负载压力。

另外，反向代理服务器也可以实现负载均衡的功能。

![](https://images2015.cnblogs.com/blog/821681/201611/821681-20161127213111362-590626648.png)

由于反向代理服务器转发请求在HTTP协议层面，因此也叫应用层负载均衡。优点是部署简单，缺点是可能成功系统的瓶颈。

# 五. Redis和Setnx命令使如何实现分布式锁的？使用Redis怎么进行异步队列？会有什么缺点？

# 六. 说说对JVM的理解？

# 七. treemap和HashMap的区别？

首先介绍一下什么是Map。在数组中我们是通过数组下标来对其内容索引的，而在Map中我们通过对象来对对象进行索引，用来索引的对象叫做key，其对应的对象叫做value。这就是我们平时说的键值对。

HashMap通过hashcode对其内容进行快速查找，而 TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。

## 1. HashMap 非线程安全 TreeMap 非线程安全

在Java里，线程安全一般体现在两个方面：

1. 多个thread对同一个java实例的访问（read和modify）不会相互干扰，它主要体现在关键字synchronized。如ArrayList和Vector，HashMap和Hashtable
（后者每个方法前都有synchronized关键字）。如果你在interator一个List对象时，其它线程remove一个element，问题就出现了。
2. 每个线程都有自己的字段，而不会在多个线程之间共享。它主要体现在java.lang.ThreadLocal类，而没有Java关键字支持，如像static、transient那样。

## 2. AbstractMap抽象类和SortedMap接口

- AbstractMap 抽象类：(HashMap继承AbstractMap)覆盖了equals()和hashCode()方法以确保两个相等映射返回相同的哈希码。如果两个映射大小相等、包含同样的键且每个键在这两个映射中对应的值都相同，则这两个映射相等。映射的哈希码是映射元素哈希码的总和，其中每个元素是Map.Entry接口的一个实现。因此，不论映射内部顺序如何，两个相等映射会报告相同的哈希码。
- SortedMap 接口：（TreeMap继承自SortedMap）它用来保持键的有序顺序。SortedMap接口为映像的视图(子集)，包括两个端点提供了访问方法。除了排序是作用于映射的键以外，处理SortedMap和处理SortedSet一样。添加到SortedMap实现类的元素必须实现Comparable接口，否则您必须给它的构造函数提供一个Comparator接口的实现。TreeMap类是它的唯一一份实现。

## 3. 两种常规Map实现

### (1) HashMap

HashMap：基于哈希表实现。使用HashMap要求添加的键类明确定义了hashCode()和equals()[可以重写hashCode()和equals()]，为了优化HashMap空间的使用，您可以调优初始容量和负载因子。

(1)HashMap(): 构建一个空的哈希映像
(2)HashMap(Map m): 构建一个哈希映像，并且添加映像m的所有映射
(3)HashMap(int initialCapacity): 构建一个拥有特定容量的空的哈希映像
(4)HashMap(int initialCapacity, float loadFactor): 构建一个拥有特定容量和加载因子的空的哈希映像

### (2) TreeMap

TreeMap：基于红黑树实现。TreeMap没有调优选项，因为该树总处于平衡状态。

(1)TreeMap():构建一个空的映像树
(2)TreeMap(Map m): 构建一个映像树，并且添加映像m中所有元素
(3)TreeMap(Comparator c): 构建一个映像树，并且使用特定的比较器对关键字进行排序
(4)TreeMap(SortedMap s): 构建一个映像树，添加映像树s中所有映射，并且使用与有序映像s相同的比较器排序

### 4. 两种常规 Map 性能

HashMap：适用于在Map中插入、删除和定位元素。
Treemap：适用于按自然顺序或自定义顺序遍历键(key)。

### 5. 总结

HashMap通常比TreeMap快一点(树和哈希表的数据结构使然)，建议多使用HashMap，在需要排序的Map时候才用TreeMap。

```java
import java.util.HashMap;
import java.util.Hashtable;
import java.util.Iterator;
import java.util.Map;
import java.util.TreeMap;
public class HashMaps {
    public static void main(String[] args) {
        Map<String, String> map = new HashMap<String, String>();
        map.put("d", "ddd");
        map.put("b", "bbb");
        map.put("a", "aaa");
        map.put("c", "ccc");
        Iterator<String> iterator = map.keySet().iterator();
        while (iterator.hasNext()) {
            Object key = iterator.next();
            System.out.println("map.get(key) is :" + map.get(key));
        }
        // 定义HashTable,用来测试 
        Hashtable<String, String> tab = new Hashtable<String, String>();
        tab.put("d", "ddd");
        tab.put("b", "bbb");
        tab.put("a", "aaa");
        tab.put("c", "ccc");
        Iterator<String> iterator_1 = tab.keySet().iterator();
        while (iterator_1.hasNext()) {
            Object key = iterator_1.next();
            System.out.println("tab.get(key) is :" + tab.get(key));
        }
        TreeMap<String, String> tmp = new TreeMap<String, String>();
        tmp.put("d", "ddd");
        tmp.put("b", "bbb");
        tmp.put("a", "aaa");
        tmp.put("c", "ccc");
        Iterator<String> iterator_2 = tmp.keySet().iterator();
        while (iterator_2.hasNext()) {
            Object key = iterator_2.next();
            System.out.println("tmp.get(key) is :" + tmp.get(key));
        }
    }
}
```

运行结果如下：

```txt
 map.get(key) is :ddd
 map.get(key) is :bbb
 map.get(key) is :ccc
 map.get(key) is :aaa
 tab.get(key) is :bbb
 tab.get(key) is :aaa
 tab.get(key) is :ddd
 tab.get(key) is :ccc
 tmp.get(key) is :aaa
 tmp.get(key) is :bbb
 tmp.get(key) is :ccc
 tmp.get(key) is :ddd
```

HashMap的结果是没有排序的，而TreeMap输出的结果是排好序的。

下面就要进入本文的主题了。先举个例子说明一下怎样使用HashMap:

```java
import java.util.*;
public class Exp1 {
    public static void main(String[] args){
        HashMap h1=new HashMap();
        Random r1=new Random();
        for (int i=0;i<1000;i++){
            Integer t=new Integer(r1.nextInt(20));
            if (h1.containsKey(t))
                ((Ctime)h1.get(t)).count++;
            else
                h1.put(t, new Ctime());
        }
        System.out.println(h1);
    }
}
class Ctime{
    int count=1;
    public String toString(){
        return Integer.toString(count);
    }
}
```

在HashMap中通过get()来获取value，通过put()来插入value，ContainsKey()则用来检验对象是否已经存在。可以看出，和ArrayList的操作相比，HashMap除了通过key索引其内容之外，别的方面差异并不大。

前面介绍了，HashMap是基于HashCode的，在所有对象的超类Object中有一个HashCode()方法，但是它和equals方法一样，并不能适用于所有的情况，这样我们就需要重写自己的HashCode()方法。下面就举这样一个例子：

```java
import java.util.*;
public class Exp2 {
    public static void main(String[] args){
        HashMap h2=new HashMap();
        for (int i=0;i<10;i++)
            h2.put(new Element(i), new Figureout());
        System.out.println("h2:");
        System.out.println("Get the result for Element:");
        Element test=new Element(5);
        if (h2.containsKey(test))
            System.out.println((Figureout)h2.get(test));
        else
            System.out.println("Not found");
    }
}
class Element{
    int number;
    public Element(int n){
        number=n;
    }
}
class Figureout{
    Random r=new Random();
    boolean possible=r.nextDouble()>0.5;
    public String toString(){
        if (possible)
            return "OK!";
        else
            return "Impossible!";
    }
}
```

在这个例子中，Element用来索引对象Figureout,也即Element为key，Figureout为value。在Figureout中随机生成一个浮点数，如果它比0.5大，打印”OK!”，否则打印”Impossible!”。之后查看Element(3)对应的Figureout结果如何。

结果却发现，无论你运行多少次，得到的结果都是”Not found”。也就是说索引Element(3)并不在HashMap中。这怎么可能呢？

原因得慢慢来说：Element的HashCode方法继承自Object，而Object中的HashCode方法返回的HashCode对应于当前的地址，也就是说对于不同的对象，即使它们的内容完全相同，用HashCode（）返回的值也会不同。这样实际上违背了我们的意图。因为我们在使用 HashMap时，希望利用相同内容的对象索引得到相同的目标对象，这就需要HashCode()在此时能够返回相同的值。在上面的例子中，我们期望 new Element(i) (i=5)与 Elementtest=newElement(5)是相同的，而实际上这是两个不同的对象，尽管它们的内容相同，但它们在内存中的地址不同。因此很自然的，上面的程序得不到我们设想的结果。下面对Element类更改如下：

```java
class Element{
    int number;
    public Element(int n){
        number=n;
    }
    public int hashCode(){
        return number;
    }
    public boolean equals(Object o){
        return (o instanceof Element) && (number==((Element)o).number);
    }
}
```

在这里Element覆盖了Object中的hashCode()和equals()方法。覆盖hashCode()使其以number的值作为 hashcode返回，这样对于相同内容的对象来说它们的hashcode也就相同了。而覆盖equals()是为了在HashMap判断两个key是否相等时使结果有意义（有关重写equals()的内容可以参考我的另一篇文章《重新编写Object类中的方法》）。修改后的程序运行结果如下：

```txt
h2:
Get the result for Element:
Impossible!
```

请记住：如果你想有效的使用HashMap，你就必须重写在其的HashCode()。

还有两条重写HashCode()的原则：
[list=1]

不必对每个不同的对象都产生一个唯一的hashcode，只要你的HashCode方法使get()能够得到put()放进去的内容就可以了。即”不为一原则”。

生成hashcode的算法尽量使hashcode的值分散一些，不要很多hashcode都集中在一个范围内，这样有利于提高HashMap的性能。即”分散原则”。至于第二条原则的具体原因，有兴趣者可以参考Bruce Eckel的《Thinking in Java》，在那里有对HashMap内部实现原理的介绍，这里就不赘述了。

掌握了这两条原则，你就能够用好HashMap编写自己的程序了。不知道大家注意没有，java.lang.Object中提供的三个方法：clone()，equals()和hashCode()虽然很典型，但在很多情况下都不能够适用，它们只是简单的由对象的地址得出结果。这就需要我们在自己的程序中重写它们，其实java类库中也重写了千千万万个这样的方法。利用面向对象的多态性——覆盖，Java的设计者很优雅的构建了Java的结构，也更加体现了Java是一门纯OOP语言的特性。

# 八. 多线程的五大状态？

# 九. 如何实现session共享？用Redis该如何实现？

# 十. 聊聊微服务，以及微服务之间是如何进行管理的

# 十一. 缓存和数据库双写问题

首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。

![](https://img-blog.csdn.net/20180531090217582)

但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。目前没有一篇全面的博客，对这几种方案进行解析。于是博主战战兢兢，顶着被大家喷的风险，写了这篇文章。

文章结构

本文由以下三个部分组成

1. 讲解缓存更新策略
2. 对每种策略进行缺点分析
3. 针对缺点给出改进方案

先做一个说明，从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案。

在这里，我们讨论三种更新策略：

1. 先更新数据库，再更新缓存
2. 先删除缓存，再更新数据库
3. 先更新数据库，再删除缓存

应该没人问我，为什么没有先更新缓存，再更新数据库这种策略。

(1) 先更新数据库，再更新缓存


这套方案，大家是普遍反对的。为什么呢？有如下两点原因。


- 原因一（线程安全角度）
	- 同时有请求A和请求B进行更新操作，那么会出现
		- 线程A更新了数据库
		- 线程B更新了数据库
		- 线程B更新了缓存
		- 线程A更新了缓存
	- 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
- 原因二（业务场景角度）：
	- 有如下两点：
		- 如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
		- 如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。	- 接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。

(2)先删缓存，再更新数据库

该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

那么，如何解决呢？**采用延时双删策略**。伪代码如下：

```
    public void write(String key,Object data){
        redis.delKey(key);
        db.updateData(data);
        Thread.sleep(1000);
        redis.delKey(key);
    }
```

转化为中文描述就是

1. 先淘汰缓存
2. 再写数据库（这两步和原来一样）
3. 休眠1秒，再次淘汰缓存


这么做，可以将1秒内所造成的缓存脏数据，再次删除。那么，**这个1秒怎么确定的，具体该休眠多久呢？**

针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

**如果你用了mysql的读写分离架构怎么办？**

ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。


1. 请求A进行写操作，删除缓存
2. 请求A将数据写入数据库了，
3. 请求B查询缓存发现，缓存没有值
4. 请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
5. 请求B将旧值写入缓存
6. 数据库完成主从同步，从库变为新值

上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。

**采用这种同步淘汰策略，吞吐量降低怎么办？**

ok，那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。

**第二次删除,如果删除失败怎么办？**

这是个非常好的问题，因为第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库：

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库
6. 请求A试图去删除请求B写入对缓存值，结果失败了。


ok,这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。

**如何解决呢？**具体解决方案，且看博主对第(3)种更新策略的解析。

(3) 先更新数据库，再删缓存

首先，先说一下。老外提出了一个缓存更新套路，名为《Cache-Aside pattern》。其中就指出

- 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- 命中：应用程序从cache中取数据，取到后返回。
- 更新：先把数据存到数据库中，成功后，再让缓存失效。

另外，知名社交网站facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。

**这种情况不存在并发问题么？**

不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：

1. 缓存刚好失效
2. 请求A查询数据库，得一个旧值
3. 请求B将新值写入数据库
4. 请求B删除缓存
5. 请求A将查到的旧值写入缓存


ok，如果发生上述情况，确实是会发生脏数据。

**然而，发生这种情况的概率又有多少呢？**

发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。

假设，有人非要抬杠，有强迫症，一定要解决怎么办？

**如何解决上述并发问题？**

首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。

**还有其他造成不一致的原因么？**

有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。

**如何解决？**

提供一个保障的重试机制即可，这里给出两套方案。

方案一：如下图所示

![](https://img-blog.csdn.net/20180531090248883)

流程如下所示：

1. 更新数据库数据；
2. 缓存因为种种问题删除失败
3. 将需要删除的key发送至消息队列
4. 自己消费消息，获得需要删除的key
5. 继续重试删除操作，直到成功

然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。

方案二：流程如下图所示：

![](https://img-blog.csdn.net/20180531090256490)

1. 更新数据库数据
2. 数据库会将操作信息写入binlog日志当中
3. 订阅程序提取出所需要的数据以及key
4. 另起一段非业务代码，获得该信息
5. 尝试删除缓存操作，发现删除失败
6. 将这些信息发送至消息队列
7. 重新从消息队列中获得该数据，重试操作。

备注说明：上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。至于oracle中，博主目前不知道有没有现成中间件可以使用。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。

总结：本文其实是对目前互联网中已有的一致性方案，进行了一个总结。对于先删缓存，再更新数据库的更新策略，还有方案提出维护一个内存队列的方式，博主看了一下，觉得实现异常复杂，没有必要，因此没有必要在文中给出。最后，希望大家有所收获。

# 十二. Java中nio和io的区别？常用的类有哪些？

# 十三. Java里面的同步锁了解吗？ CountDownLatch和Cyclicbarrier的区别，分别在什么场景下使用？

在java 1.5中，提供了一些非常有用的辅助类来帮助我们进行并发编程，比如CountDownLatch，CyclicBarrier和Semaphore，今天我们就来学习一下这三个辅助类的用法。

## 1. CountDownLatch用法

CountDownLatch类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。

CountDownLatch类只提供了一个构造器：

```java
//参数count为计数值
public CountDownLatch(int count) {  }
```
然后下面这3个方法是CountDownLatch类中最重要的方法：

```java
public void await() throws InterruptedException { };   //调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行
public boolean await(long timeout, TimeUnit unit) throws InterruptedException { };  //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行
public void countDown() { };  //将count值减1
```

下面看一个例子大家就清楚CountDownLatch的用法了：

```java
public class Test {
     public static void main(String[] args) {   
         final CountDownLatch latch = new CountDownLatch(2);
 
         new Thread(){
             public void run() {
                 try {
                     System.out.println("子线程"+Thread.currentThread().getName()+"正在执行");
                    Thread.sleep(3000);
                    System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕");
                    latch.countDown();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
             };
         }.start();
 
         new Thread(){
             public void run() {
                 try {
                     System.out.println("子线程"+Thread.currentThread().getName()+"正在执行");
                     Thread.sleep(3000);
                     System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕");
                     latch.countDown();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
             };
         }.start();
 
         try {
             System.out.println("等待2个子线程执行完毕...");
            latch.await();
            System.out.println("2个子线程已经执行完毕");
            System.out.println("继续执行主线程");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
     }
}
```

执行结果：

```txt
线程Thread-0正在执行
线程Thread-1正在执行
等待2个子线程执行完毕...
线程Thread-0执行完毕
线程Thread-1执行完毕
2个子线程已经执行完毕
继续执行主线程
```

## 2. CyclicBarrier用法

字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。我们暂且把这个状态就叫做barrier，当调用await()方法之后，线程就处于barrier了。

CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器：

```java
public CyclicBarrier(int parties, Runnable barrierAction) {
}
 
public CyclicBarrier(int parties) {
}
```

参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容。

然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本：

```java
public int await() throws InterruptedException, BrokenBarrierException { };
public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException { };
```

第一个版本比较常用，用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务；  
第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。  
下面举几个例子就明白了：假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情，此时就可以利用CyclicBarrier了：

```java
public class Test {
    public static void main(String[] args) {
        int N = 4;
        CyclicBarrier barrier  = new CyclicBarrier(N);
        for(int i=0;i<N;i++)
            new Writer(barrier).start();
    }
    static class Writer extends Thread{
        private CyclicBarrier cyclicBarrier;
        public Writer(CyclicBarrier cyclicBarrier) {
            this.cyclicBarrier = cyclicBarrier;
        }
 
        @Override
        public void run() {
            System.out.println("线程"+Thread.currentThread().getName()+"正在写入数据...");
            try {
                Thread.sleep(5000);      //以睡眠来模拟写入数据操作
                System.out.println("线程"+Thread.currentThread().getName()+"写入数据完毕，等待其他线程写入完毕");
                cyclicBarrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }catch(BrokenBarrierException e){
                e.printStackTrace();
            }
            System.out.println("所有线程写入完毕，继续处理其他任务...");
        }
    }
}
```

执行结果：

```
线程Thread-0正在写入数据...
线程Thread-3正在写入数据...
线程Thread-2正在写入数据...
线程Thread-1正在写入数据...
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-0写入数据完毕，等待其他线程写入完毕
线程Thread-3写入数据完毕，等待其他线程写入完毕
线程Thread-1写入数据完毕，等待其他线程写入完毕
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
```

从上面输出结果可以看出，每个写入线程执行完写数据操作之后，就在等待其他线程写入操作完毕。  
当所有线程线程写入操作完毕之后，所有线程就继续进行后续的操作了。  
如果说想在所有线程写入操作完之后，进行额外的其他操作可以为CyclicBarrier提供Runnable参数：

```java
public class Test {
    public static void main(String[] args) {
        int N = 4;
        CyclicBarrier barrier  = new CyclicBarrier(N,new Runnable() {
            @Override
            public void run() {
                System.out.println("当前线程"+Thread.currentThread().getName());   
            }
        });
 
        for(int i=0;i<N;i++)
            new Writer(barrier).start();
    }
    static class Writer extends Thread{
        private CyclicBarrier cyclicBarrier;
        public Writer(CyclicBarrier cyclicBarrier) {
            this.cyclicBarrier = cyclicBarrier;
        }
 
        @Override
        public void run() {
            System.out.println("线程"+Thread.currentThread().getName()+"正在写入数据...");
            try {
                Thread.sleep(5000);      //以睡眠来模拟写入数据操作
                System.out.println("线程"+Thread.currentThread().getName()+"写入数据完毕，等待其他线程写入完毕");
                cyclicBarrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }catch(BrokenBarrierException e){
                e.printStackTrace();
            }
            System.out.println("所有线程写入完毕，继续处理其他任务...");
        }
    }
}
```

运行结果：

```txt
线程Thread-0正在写入数据...
线程Thread-1正在写入数据...
线程Thread-2正在写入数据...
线程Thread-3正在写入数据...
线程Thread-0写入数据完毕，等待其他线程写入完毕
线程Thread-1写入数据完毕，等待其他线程写入完毕
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-3写入数据完毕，等待其他线程写入完毕
当前线程Thread-3
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
```

从结果可以看出，当四个线程都到达barrier状态后，会从四个线程中选择一个线程去执行Runnable。

下面看一下为await指定时间的效果：

```java
public class Test {
    public static void main(String[] args) {
        int N = 4;
        CyclicBarrier barrier  = new CyclicBarrier(N);
 
        for(int i=0;i<N;i++) {
            if(i<N-1)
                new Writer(barrier).start();
            else {
                try {
                    Thread.sleep(5000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                new Writer(barrier).start();
            }
        }
    }
    static class Writer extends Thread{
        private CyclicBarrier cyclicBarrier;
        public Writer(CyclicBarrier cyclicBarrier) {
            this.cyclicBarrier = cyclicBarrier;
        }
 
        @Override
        public void run() {
            System.out.println("线程"+Thread.currentThread().getName()+"正在写入数据...");
            try {
                Thread.sleep(5000);      //以睡眠来模拟写入数据操作
                System.out.println("线程"+Thread.currentThread().getName()+"写入数据完毕，等待其他线程写入完毕");
                try {
                    cyclicBarrier.await(2000, TimeUnit.MILLISECONDS);
                } catch (TimeoutException e) {
                    // TODO Auto-generated catch block
                    e.printStackTrace();
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            }catch(BrokenBarrierException e){
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName()+"所有线程写入完毕，继续处理其他任务...");
        }
    }
}
```

执行结果：

```txt
线程Thread-0正在写入数据...
线程Thread-2正在写入数据...
线程Thread-1正在写入数据...
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-0写入数据完毕，等待其他线程写入完毕
线程Thread-1写入数据完毕，等待其他线程写入完毕
线程Thread-3正在写入数据...
java.util.concurrent.TimeoutException
Thread-1所有线程写入完毕，继续处理其他任务...
Thread-0所有线程写入完毕，继续处理其他任务...
    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)
    at java.util.concurrent.CyclicBarrier.await(Unknown Source)
    at com.cxh.test1.Test$Writer.run(Test.java:58)
java.util.concurrent.BrokenBarrierException
    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)
    at java.util.concurrent.CyclicBarrier.await(Unknown Source)
    at com.cxh.test1.Test$Writer.run(Test.java:58)
java.util.concurrent.BrokenBarrierException
    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)
    at java.util.concurrent.CyclicBarrier.await(Unknown Source)
    at com.cxh.test1.Test$Writer.run(Test.java:58)
Thread-2所有线程写入完毕，继续处理其他任务...
java.util.concurrent.BrokenBarrierException
线程Thread-3写入数据完毕，等待其他线程写入完毕
    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)
    at java.util.concurrent.CyclicBarrier.await(Unknown Source)
    at com.cxh.test1.Test$Writer.run(Test.java:58)
Thread-3所有线程写入完毕，继续处理其他任务...
```

上面的代码在main方法的for循环中，故意让最后一个线程启动延迟，因为在前面三个线程都达到barrier之后，等待了指定的时间发现第四个线程还没有达到barrier，就抛出异常并继续执行后面的任务。

另外CyclicBarrier是可以重用的，看下面这个例子：

```java
public class Test {
    public static void main(String[] args) {
        int N = 4;
        CyclicBarrier barrier  = new CyclicBarrier(N);
 
        for(int i=0;i<N;i++) {
            new Writer(barrier).start();
        }
 
        try {
            Thread.sleep(25000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
 
        System.out.println("CyclicBarrier重用");
 
        for(int i=0;i<N;i++) {
            new Writer(barrier).start();
        }
    }
    static class Writer extends Thread{
        private CyclicBarrier cyclicBarrier;
        public Writer(CyclicBarrier cyclicBarrier) {
            this.cyclicBarrier = cyclicBarrier;
        }
 
        @Override
        public void run() {
            System.out.println("线程"+Thread.currentThread().getName()+"正在写入数据...");
            try {
                Thread.sleep(5000);      //以睡眠来模拟写入数据操作
                System.out.println("线程"+Thread.currentThread().getName()+"写入数据完毕，等待其他线程写入完毕");
 
                cyclicBarrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }catch(BrokenBarrierException e){
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName()+"所有线程写入完毕，继续处理其他任务...");
        }
    }
}
```

执行结果：

```txt
线程Thread-0正在写入数据...
线程Thread-1正在写入数据...
线程Thread-3正在写入数据...
线程Thread-2正在写入数据...
线程Thread-1写入数据完毕，等待其他线程写入完毕
线程Thread-3写入数据完毕，等待其他线程写入完毕
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-0写入数据完毕，等待其他线程写入完毕
Thread-0所有线程写入完毕，继续处理其他任务...
Thread-3所有线程写入完毕，继续处理其他任务...
Thread-1所有线程写入完毕，继续处理其他任务...
Thread-2所有线程写入完毕，继续处理其他任务...
CyclicBarrier重用
线程Thread-4正在写入数据...
线程Thread-5正在写入数据...
线程Thread-6正在写入数据...
线程Thread-7正在写入数据...
线程Thread-7写入数据完毕，等待其他线程写入完毕
线程Thread-5写入数据完毕，等待其他线程写入完毕
线程Thread-6写入数据完毕，等待其他线程写入完毕
线程Thread-4写入数据完毕，等待其他线程写入完毕
Thread-4所有线程写入完毕，继续处理其他任务...
Thread-5所有线程写入完毕，继续处理其他任务...
Thread-6所有线程写入完毕，继续处理其他任务...
Thread-7所有线程写入完毕，继续处理其他任务...
```

从执行结果可以看出，在初次的4个线程越过barrier状态后，又可以用来进行新一轮的使用。而CountDownLatch无法进行重复使用。

## 3. Semaphore用法

Semaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。  
Semaphore类位于java.util.concurrent包下，它提供了2个构造器：

```java
//参数permits表示许可数目，即同时可以允许多少线程进行访问
public Semaphore(int permits) {
    sync = new NonfairSync(permits);
}
public Semaphore(int permits, boolean fair) {    //这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可
    sync = (fair)? new FairSync(permits) : new NonfairSync(permits);
}
```

下面说一下Semaphore类中比较重要的几个方法，首先是acquire()、release()方法：

```java
//获取一个许可
public void acquire() throws InterruptedException {  }     
//获取permits个许可
public void acquire(int permits) throws InterruptedException { }    
//释放一个许可
public void release() { }          
//释放permits个许可
public void release(int permits) { }    
```

acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。  
release()用来释放许可。注意，在释放许可之前，必须先获获得许可。

这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法：

```java
//尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回false
public boolean tryAcquire() { };    
//尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false
public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException { };  
//尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回false
public boolean tryAcquire(int permits) { }; 
//尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false
public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException { }; 
```

另外还可以通过availablePermits()方法得到可用的许可数目。  
下面通过一个例子来看一下Semaphore的具体使用：假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现：

```java
public class Test {
    public static void main(String[] args) {
        int N = 8;            //工人数
        Semaphore semaphore = new Semaphore(5); //机器数目
        for(int i=0;i<N;i++)
            new Worker(i,semaphore).start();
    }
 
    static class Worker extends Thread{
        private int num;
        private Semaphore semaphore;
        public Worker(int num,Semaphore semaphore){
            this.num = num;
            this.semaphore = semaphore;
        }
 
        @Override
        public void run() {
            try {
                semaphore.acquire();
                System.out.println("工人"+this.num+"占用一个机器在生产...");
                Thread.sleep(2000);
                System.out.println("工人"+this.num+"释放出机器");
                semaphore.release();           
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
```

执行结果：

```txt
工人0占用一个机器在生产...
工人1占用一个机器在生产...
工人2占用一个机器在生产...
工人4占用一个机器在生产...
工人5占用一个机器在生产...
工人0释放出机器
工人2释放出机器
工人3占用一个机器在生产...
工人7占用一个机器在生产...
工人4释放出机器
工人5释放出机器
工人1释放出机器
工人6占用一个机器在生产...
工人3释放出机器
工人7释放出机器
工人6释放出机器
```

下面对上面说的三个辅助类进行一个总结：

1. CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：
	- CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；
	- 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；
	- 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。
2. Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。

# 十四. JVM的内存结构，哪些是共享的，哪些是线程私有的？ Java虚拟机里堆栈分别存放什么？


# 十五. 手写代码：快速排序，单利模式， 画一个工厂模式和装饰者模式的 UML 类图

# 十六. 手写SpringMVC DispatcherServlet的大致实现？

# 十七. Java 的代理

# 十八. 聊一聊平时的项目并发经验

# 十九. Redis的数据结构？ 线程模型？ Redis的数据淘汰机制？

# 二十. 读过Redis的源码吗？

# 二十一. MySQL实现事务的原理

# 二十二. MQ底层原理的实现？

# 二十三. 数据库事务acid，事务操作，怎么加锁？分布式系统锁？

# 二十四. 什么情况下会发生雪崩？如何解决？

# 二十五. 技术含量较高的项目，从架构设计到部署问了一遍

# 二十六. 高并发架构的设计思路

## 1. 前言

随着互联网的快速发展，很多传统行业都开始将原有的产品互联网化移动化，这其中就涉及到对原有系统的改造，因为之前大部分时间都是在传统银行工作所以对于原先的系统设计我们也有一个套路，类似传统的SSH、LAMP这种，但是随着技术的不断快速发展，互联网高并发的架构设计也有了新的模式，本文就介绍下基本的高并发设计模式。互联网大部分系统的设计采用本文的设计模式都是可以的，但是对于一些超高并发的特殊场景的系统还是需要根据具体业务场景单独去设计的，下面我们就对高并发设计模式进行讲解。

## 2. 分层

分层设计是企业应用系统中常见的设计模式，为了保证后续系统的可拆分和可复用，一般会将系统拆分为应用层、服务层、数据层，这也是传统的系统分层拆分模式。通过分层，可以更好的将一个庞大的软件系统切分为不同的部分，便于分工合作并行开发和维护。每层都是独立的，互相通过接口进行调用，各层可以根据业务情况的变化独立作出调整，只需要保证接口一致性即可。  
分层比较大的挑战就是合理规划和划分每一层的边界和接口，在实施过程中禁止跃层调用。对于分层架构不是一成不变的，一般来说在实际过程中，会根据具体的情况再细化分层，应用层可以分为视图层、业务逻辑层等，服务层也可以细分为数据接口适配层、逻辑处理层等。  
分层架构对网站支持高并发分布式的发展方向至关重要，所以在系统刚开始建的时候最好就要采取分层架构，这样后续分层会比较容易。

## 3. 分割

分层是对系统的横向的切分，分割则是对系统纵向的切分。系统越大，分割的就会越细，例如银行系统我们会切分为核心系统、账户系统、支付系统、现金管理系统、营销系统等等，基本上你在网银或者手机银行上看到的每个功能背后基本都是一个系统去支撑，例如我们常见的手机银行里的账户交易查询，就这么一个简单的交易查询功能，对于有一定规模的银行来说，都会单建一个交易查询系统提供全渠道的查询服务。  
按照这样将功能从业务层面分割以后，各个系统承载的压力自然也就下降下来，而且扩展性也会比较好。不过功能分割对于大型网站的分割粒度一般会比较小，对于小规模的公司来说一般没必要上来就分割成很多子系统，随着业务的发展再进行分割就可以。

## 4. 分布式

分布式由来已久，分布式意味着可以通过增加机器完成同样的功能，机器越多，cpu资源、内存、磁盘都是随着机器的增加而线性增加，机器越多能够处理的并发访问和数据量就越大，从而能为更多的用户提供服务。  
分布式架构需要考虑很多问题，并不是简单的加机器就可以了。实施分布式以后需要考虑用户会话如何管理，数据在分布式环境中如何保持数据一致性，分布式事务如何保证一致性，分布式的日志维护等都是需要考虑的问题，所以分布式设计要根据具体情况而来，不要为了分布式而分布式。
分布式方案有以下几种：  

1. 分布式应用和服务：将分层和分割后的应用分布式部署，这样可以提高网站性能和并发，加快开发和发布速度，还可以让不同应用交叉复用共同的应用，便于功能扩展。
2. 分布式静态资源：网站的静态资源独立分布式部署，并采用独立的域名，这就是动静分离。静态资源的分布式部署可以减少应用服务器的压力，使用独立域名可以加快加载速度，也可以降低静态资源服务器的压力。
3. 分布式数据和存储：大型网站处理的数据都是P级的，单台服务器无法提供这么大的存储空间，这么大的数据需要分布式存储。除了分布式文件存储，还有关系型数据库和Nosql都有分布式的部署方案。通过分布式能够提供海量的数据存储空间。
4. 分布式计算：对于很多后台批量处理的任务都是采用分布式计算方案，常用的有Hadoop和MapReduce分布式计算框架。分布式计算框架内容比较多。

## 5. 集群

分布式部署的应用和服务部署了很多机器后还需要将其集群化才能对外提供服务，多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务。  
当业务量不断增大以后，可以在集群中不断增加服务器就可以满足业务增长了，当一台服务器坏了也不会影响对外的服务提供，只是性能有所下降。

## 6. 缓存

缓存是高并发系统的杀手锏，在真正有高并发需求的系统一般会设计多级缓存来减少真正的服务计算，而是直接通过缓存提供服务。像微博、朋友圈这些高QPS的系统都是采用了多级缓存的架构方案。

1. CDN：CDN供应商一般都部署在距离用户最近的网络服务商，用户的请求总是先到网络服务商，在这里缓存网站的静态资源，可以就近将静态数据返回给用户。一般来说对于电商、社交应用、新闻门户或者视频网站这些高QPS网站，都建议使用CDN来环节源系统的压力。
2. 反向代理：反向代理属于网站前端架构的一部分，部署在网站的前端，当用户请求到达网站的数据中心时，最先访问到的就是反向代理服务器，这里将网站的静态资源缓存起来，这样不需要继续转发应用服务器，直接从反向代理缓存中返回就可以了。
3. 本地缓存：对于应用服务器被访问的高热点数据，应用程序可以在服务器内存中缓存这些热点数据，这样就不需要访问服务器磁盘或者数据库了，能够将内存中的热点数据直接返回。
4. 分布式缓存：很多系统数据量非常大，光靠本地缓存可能内存空间不够，这时候就可以考虑使用分布式缓存了，常用的分布式缓存有redis、memcache这些key-value分布式缓存，这些分布式缓存一般也都提供了集群版本，能够做到很好的高可用和高性能。

## 7. 异步

异步也是处理高并发的一把利器，也是处理解耦的手段之一，业务系统之间的消息传递不是同步调用，而是将一个业务操作分为多个阶段，每个阶段之间通过共享数据的方式异步执行。  
在单一服务器内部可通过多线程共享队列的方式实现异步，处在业务操作前面的线程将输出的内容写入队列，后面的处理线程从队列中取出数据进行处理；在分布式系统中，多个服务器集群通过分布式消息队列实现异步。  
对于简单的异步实现可以通过内存队列来实现，对于需要高可用和高并发的系统一般来说都依靠商用的消息队列中间件产品，Websphere MQ、Rabbit MQ、Rocket MQ等都是比较好的消息中间件产品。

## 8. 冗余

为了保证系统的高可用，我们一般会对服务器和数据都进行冗余备份，这样可以保证在服务器宕机的情况下系统依然可以保证提供服务。  
访问和负载很小的应用服务也必须部署至少两台服务器组成一个集群，就是为了通过冗余来实现高可用。数据库要定期进行全量备份，每天还要进行增量备份，防止数据库服务器出现异常导致数据丢失，对于实时的数据备份可以通过数据库自带的日志来进行恢复。

## 9. 总结

上面介绍的这些就是常用的一些高并发的设计模式，其中每一条都值得深入的研究，本文只是介绍了高并发设计时需要考虑的设计方案简介，可以通过这些方案缓解压力提高并发性能和高可用，每一点都可以单独去详细介绍下，后面我会再写几篇分别介绍下这些模式的具体应用方式。

# 二十七. 谈一谈Hash的一致算法

## 1. 一致性Hash算法背景

一致性哈希算法在1997年由麻省理工学院的Karger等人在解决分布式Cache中提出的，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得DHT可以在P2P环境中真正得到应用。  
但现在一致性hash算法在分布式系统中也得到了广泛应用，研究过memcached缓存数据库的人都知道，memcached服务器端本身不提供分布式cache的一致性，而是由客户端来提供，具体在计算一致性hash时采用如下步骤：

1. 首先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
2. 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
3. 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172408386-366341651.png)

从上图的状态中添加一台memcached服务器。余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在园（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，如下图所示：

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172431933-546286787.png)
 
## 2. 一致性Hash性质

考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其实在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要，良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面：

- **平衡性 (Balance)**: 平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。
- **单调性 (Monotonicity)**: 单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希：x = (ax + b) mod (P)，在上式中，P表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从P1到P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要求。哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更新。而在P2P系统内，缓冲的变化等价于Peer加入或退出系统，这一情况在P2P系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。
- **分散性 (Spread)**: 在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。
- **负载 (Load)**: 负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。
- **平滑性 (Smoothness)**: 平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。

## 3. 原理
### (1) 基本概念

一致性哈希算法（Consistent Hashing）最早在论文《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》中被提出。简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希空间环如下：

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172453355-790656043.png)

整个空间按顺时针方向组织。0 和 2^32-1 在零点中方向重合。  
下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用ip地址哈希后在环空间的位置如下：

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172523808-1567363338.png)

接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。  
例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172807745-742859090.png)

根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。  
下面分析一致性哈希算法的容错性和可扩展性。现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。  
下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172901526-169091807.png)

此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。  
综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。  
另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下，

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172922917-1331181630.png)

此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：

![](https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172943917-133540408.png)

同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。

# 二十八. 事务的二段提交机制？

# 二十九. 举例说一下索引的应用场景和注意事项？

# 三十. 当前读和快照读

# 三十一. 聊一聊类加载的过程？

# 三十二. Http和Https的区别？ 以及Https加密的方式

超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。

　　为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。

## 1. HTTP和HTTPS的基本概念

- HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。
- HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。
- HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

## 2. HTTP与HTTPS有什么区别？

- HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。
- HTTPS和HTTP的区别主要如下：
	1. https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
	2. http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
	3. http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
	4. http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

## 3. HTTPS的工作原理

我们都知道HTTPS能够加密信息，以免敏感信息被第三方获取，所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。

![](http://www.mahaixiang.cn/uploads/allimg/1507/1-150H120343I41.jpg)

客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。

1. 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。
2. Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。
3. 客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。
4. 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
5. Web服务器利用自己的私钥解密出会话密钥。
6. Web服务器利用会话密钥加密与客户端之间的通信。

![](https://pic002.cnblogs.com/images/2012/339704/2012071410212142.gif)

## 4. HTTPS的优点

尽管HTTPS并非绝对安全，掌握根证书的机构、掌握加密算法的组织同样可以进行中间人形式的攻击，但HTTPS仍是现行架构下最安全的解决方案，主要有以下几个好处：

1. 使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；
2. HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。
3. HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。
4. 谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。

## 5. HTTPS的缺点

虽然说HTTPS有很大的优势，但其相对来说，还是存在不足之处的：

1. HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电；
2. HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；
3. SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。
4. SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。
5. HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。

## 6. http切换到HTTPS

如果需要将网站从http切换到https到底该如何实现呢？  
这里需要将页面中所有的链接，例如js，css，图片等等链接都由http改为https。例如：http://www.baidu.com改为https://www.baidu.com  
BTW，这里虽然将http切换为了https，还是建议保留http。所以我们在切换的时候可以做http和https的兼容，具体实现方式是，去掉页面链接中的http头部，这样可以自动匹配http头和https头。例如：将http://www.baidu.com改为//www.baidu.com。然后当用户从http的入口进入访问页面时，页面就是http，如果用户是从https的入口进入访问页面，页面即使https的。

# 三十三. 线程池的核心参数和基本原理？线程池的调优策略

# 三十四. 谈谈个人的职业规划

# 三十五. Collections.sort底层的排序方式？

# 三十六. 排序的稳定性,以及不同场景下的排序策略

# 三十七. Http请求过程，DNS解析的过程

# 三十八. 简述线程池和并发工具有哪些？

# 三十九. 频繁老年代回收怎么分析和解决？

帖子回复：

1. full GC 频繁回收 是不是 你分配的 年轻代  内存空间不够 导致要回收老年的堆来释放内存
2. 你说的是其中的一个原因，不过后来多调试了几次，发现了永久代空间太小导致了full gc的执行更频繁。在网上找到了导致full gc的执行的因素：
	- 年轻代空间不足
	- per Gen（永久代）空间满
	- CMS GC时出现promotion failed和concurrent mode failure
	- 统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间等
3. 个人觉得，优化手段已经可以了，如果效果不明显，不妨看看业务代码是不是有自己的问题。使用工具抓一下内存，分析一下，哪些对象是最多的，是否合理。jvm优化也有极限，核心问题还是代码质量。
4. JVM调优肯定得看gc log，然后针对性分析、调优。没有通用的、一劳永逸的方案。
5. 我个人认为在项目基本完成后先监控jvm，进行内存和cpu占用率等等的分析会更快发现优化的地方
	- 在开发中为了及时交付不能不在代码质量上做一些牺牲；
	- 团队开发，难免会有良莠不齐的状况导致了整体质量的下降；
	- 在开发一段时间后，囿于个人代码的习惯等等原因很难发现优化的地方
6. Full GC本身是好的，可以清除老年代的垃圾，但是如果Full GC发生的频率高了，就会影响性能，同时意味着系统内存分配机制出现问题。
	- 因为Full GC本身执行时间较长（甚至超过1秒），而且除非采用G1 GC，否则其它的GC方式都会或多或少挂起所有线程执行（Stop-the-world），如果Full GC频繁发生，系统被挂起的次数就会增加，响应时间就会变慢。
	- 同时，Full GC频繁发生，意味着你的内存分配机制存在问题，也许是内存泄露，有大量内存垃圾不断在老年代产生；也许是你的大对象（缓存）过多；也有可能是你的参数设置不好，minor GC清理不掉内存，导致每次minor GC都会触发Full GC；还有可能是你的老年代大小参数设置错误，老年代过小等等原因

# 四十. 讲讲SpringBoot和SpringCloud的一些应用？

# 四十一. 阻塞队列不用Java提供的该怎么实现？

# 四十二. 讲讲Docker容器

# 四十三. 如何实现高并发环境下的削峰、限流？

流量削峰的由来主要是还是来自于互联网的业务场景，例如，马上即将开始的春节火车票抢购，大量的用户需要同一时间去抢购；以及大家熟知的阿里双11秒杀，短时间上亿的用户涌入，瞬间流量巨大（高并发），比如：200万人准备在凌晨12:00准备抢购一件商品，但是商品的数量缺是有限的100-500件左右。  
这样真实能购买到该件商品的用户也只有几百人左右，但是从业务上来说，秒杀活动是希望更多的人来参与，也就是抢购之前希望有越来越多的人来看购买商品。  
但是，在抢购时间达到后，用户开始真正下单时，秒杀的服务器后端缺不希望同时有几百万人同时发起抢购请求。  
我们都知道服务器的处理资源是有限的，所以出现峰值的时候，很容易导致服务器宕机，用户无法访问的情况出现。  
这就好比出行的时候存在早高峰和晚高峰的问题，为了解决这个问题，出行就有了错峰限行的解决方案。同理，在线上的秒杀等业务场景，也需要类似的解决方案，需要平安度过同时抢购带来的流量峰值的问题，这就是流量削峰的由来。

## 1. 怎样来实现流量削峰方案

削峰从本质上来说就是更多地延缓用户请求，以及层层过滤用户的访问需求，遵从“最后落地到数据库的请求数要尽量少”的原则。

### (1) 消息队列解决削峰

要对流量进行削峰，最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。  
消息队列中间件主要解决应用耦合，异步消息，流量削锋等问题。常用消息队列系统：目前在生产环境，使用较多的消息队列有 ActiveMQ、RabbitMQ、ZeroMQ、Kafka、MetaMQ、RocketMQ 等。  
在这里，消息队列就像“水库”一样，拦蓄上游的洪水，削减进入下游河道的洪峰流量，从而达到减免洪水灾害的目的。具体的消息队列MQ选型和应用场景可以参考我的往期文章：《高并发架构系列：详解分布式之消息队列的特点、选型、及应用场景》

## 2. 流量削峰漏斗：层层削峰

针对秒杀场景还有一种方法，就是对请求进行分层过滤，从而过滤掉一些无效的请求。分层过滤其实就是采用“漏斗”式设计来处理请求的，如下图所示：

![](https://upload-images.jianshu.io/upload_images/15069341-4275977ca5551477)

这样就像漏斗一样，尽量把数据量和请求量一层一层地过滤和减少了。

1. 分层过滤的核心思想通
	- 过在不同的层次尽可能地过滤掉无效请求；
	- 通过CDN过滤掉大量的图片，静态资源的请求。
	- 再通过类似Redis这样的分布式缓存，过滤请求等就是典型的在上游拦截读请求。
2. 分层过滤的基本原则
	- 对写数据进行基于时间的合理分片，过滤掉过期的失效请求。
	- 对写请求做限流保护，将超出系统承载能力的请求过滤掉。
	- 涉及到的读数据不做强一致性校验，减少因为一致性校验产生瓶颈的问题。
	- 对写数据进行强一致性校验，只保留最后有效的数据。
	- 最终，让“漏斗”最末端(数据库)的才是有效请求。例如：当用户真实达到订单和支付的流程，这个是需要数据强一致性的。

## 3. 总结

1. 对于秒杀这样的高并发场景业务，最基本的原则就是将请求拦截在系统上游，降低下游压力。如果不在前端拦截很可能造成数据库(mysql、oracle等)读写锁冲突，甚至导致死锁，最终还有可能出现雪崩等场景。
2. 划分好动静资源，静态资源使用CDN进行服务分发。
3. 充分利用缓存(redis等)：增加QPS，从而加大整个集群的吞吐量。
4. 高峰值流量是压垮系统很重要的原因，所以需要Kafka等消息队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。以上是就是流量削峰的详解。

# 四十四. 聊一聊项目中用到的中间件(Dubbo/MQ/Zookeeper/Redis/Kafka)

# 四十五. 什么情况下会造成雪崩？该怎么避免这种情况

